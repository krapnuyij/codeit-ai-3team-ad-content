{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline,\n",
    "    StableDiffusionControlNetPipeline,\n",
    "    ControlNetModel,\n",
    "    StableDiffusionXLPipeline\n",
    ")\n",
    "\n",
    "\n",
    "# 기본 설정\n",
    "\n",
    "MODE = \"sd15_controlnet\"      # 원하는 모델 선택: \"sd15_controlnet\" | \"sdxl\"\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "INPUT_DIR = Path(\"inputs\")\n",
    "\n",
    "RUN_NAME = f\"run_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
    "SAVE_DIR = os.path.join(OUTPUT_DIR, RUN_NAME)\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, \"candidates\"), exist_ok=True)\n",
    "\n",
    "\n",
    "# 공용 모델 ID 정의\n",
    "\n",
    "MODEL_IDS = {\n",
    "    \"sd15\": \"runwayml/stable-diffusion-v1-5\",\n",
    "    \"sdxl\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    \"controlnet\": \"lllyasviel/control_v11p_sd15_canny\",\n",
    "}\n",
    "\n",
    "\n",
    "pipe = None\n",
    "controlnet = None\n",
    "\n",
    "\n",
    "# 파이프라인 언로드 (모델 변경 시 메모리 회수)\n",
    "\n",
    "def unload_pipeline():\n",
    "    \"\"\"모델 파이프라인을 안전하게 언로드\"\"\"\n",
    "    global pipe, controlnet\n",
    "\n",
    "    pipe = None\n",
    "    controlnet = None\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "# 파이프라인 로더 (MODE 기반)\n",
    "\n",
    "\n",
    "def load_pipeline(mode: str, use_controlnet: bool, canny_image=None):\n",
    "    \"\"\"모델 모드를 기준으로 파이프라인을 로드\"\"\"\n",
    "    global pipe, controlnet\n",
    "\n",
    "    unload_pipeline()\n",
    "\n",
    "    if mode == \"sd15_controlnet\" and use_controlnet:\n",
    "        print(\"▶ Loading SD1.5 + ControlNet pipeline\")\n",
    "\n",
    "        controlnet = ControlNetModel.from_pretrained(\n",
    "            MODEL_IDS[\"controlnet\"],\n",
    "            torch_dtype=torch.float16\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "            MODEL_IDS[\"sd15\"],\n",
    "            controlnet=controlnet,\n",
    "            torch_dtype=torch.float16\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "    elif mode == \"sdxl\":\n",
    "        print(\"▶ Loading SDXL pipeline\")\n",
    "\n",
    "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "            MODEL_IDS[\"sdxl\"],\n",
    "            torch_dtype=torch.float16\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "    else:\n",
    "        print(\"▶ Loading SD1.5 base pipeline\")\n",
    "\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            MODEL_IDS[\"sd15\"],\n",
    "            torch_dtype=torch.float16\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# ControlNet 입력 이미지 탐색 및 Canny 변환\n",
    "\n",
    "def get_controlnet_image():\n",
    "    \"\"\"입력 디렉터리에서 첫 번째 이미지 파일을 찾아 Canny 변환\"\"\"\n",
    "    image_files = sorted([\n",
    "        *INPUT_DIR.glob(\"*.jpg\"),\n",
    "        *INPUT_DIR.glob(\"*.jpeg\"),\n",
    "        *INPUT_DIR.glob(\"*.png\"),\n",
    "        *INPUT_DIR.glob(\"*.webp\"),\n",
    "    ])\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        print(\"ℹ 입력 이미지 없음 — ControlNet 비활성화\")\n",
    "        return None, False\n",
    "\n",
    "    path = image_files[0]\n",
    "    print(f\"✔ 참조 이미지 사용: {path}\")\n",
    "\n",
    "    img = cv2.imread(str(path))\n",
    "\n",
    "    if img is None:\n",
    "        print(\"이미지를 읽지 못했습니다 — ControlNet 비활성화\")\n",
    "        return None, False\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    canny = Image.fromarray(edges)\n",
    "\n",
    "    print(\"✔ ControlNet Canny 적용 완료\")\n",
    "    return path, canny\n",
    "\n",
    "\n",
    "# 프롬프트 정의\n",
    "\n",
    "prompt = (\n",
    "    \"illustration style, clean poster layout, warm cozy color tone, \"\n",
    "    \"korean traditional market dried seafood poster, \"\n",
    "    \"korean hangul signage only, authentic korean market mood, \"\n",
    "    \"wooden baskets and display table, dried anchovies, dried squid, pollack strips, seaweed, \"\n",
    "    \"neatly arranged products, soft textured illustration shading, \"\n",
    "    \"natural warm lighting, product-focused composition\"\n",
    ")\n",
    "\n",
    "negative_prompt = (\n",
    "    \"japanese text, chinese text, kanji, latin letters, english text, \"\n",
    "    \"blurry, noisy, messy layout, distorted shapes, watermark, logo\"\n",
    ")\n",
    "\n",
    "\n",
    "# 생성 파라미터\n",
    "\n",
    "num_steps = 30\n",
    "guidance = 5.5\n",
    "num_images = 3\n",
    "seed = 42\n",
    "control_scale = 0.45\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "\n",
    "\n",
    "# 이미지 생성 + 벤치마킹 계측\n",
    "\n",
    "input_image_path, canny_img = get_controlnet_image()\n",
    "use_controlnet = (MODE == \"sd15_controlnet\" and canny_img is not None)\n",
    "\n",
    "pipe = load_pipeline(MODE, use_controlnet, canny_img)\n",
    "\n",
    "print(\"▶ Generating candidate images...\")\n",
    "\n",
    "start_time = time.time()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "if use_controlnet:\n",
    "    images = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        image=canny_img,\n",
    "        controlnet_conditioning_scale=control_scale,\n",
    "        num_inference_steps=num_steps,\n",
    "        guidance_scale=guidance,\n",
    "        num_images_per_prompt=num_images,\n",
    "        generator=generator\n",
    "    ).images\n",
    "else:\n",
    "    images = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=num_steps,\n",
    "        guidance_scale=guidance,\n",
    "        num_images_per_prompt=num_images,\n",
    "        generator=generator\n",
    "    ).images\n",
    "\n",
    "latency_ms = int((time.time() - start_time) * 1000)\n",
    "vram_peak = round(torch.cuda.max_memory_allocated() / 1024 / 1024, 2)\n",
    "\n",
    "\n",
    "# 결과 저장\n",
    "\n",
    "paths = []\n",
    "for i, img in enumerate(images, start=1):\n",
    "    path = os.path.join(SAVE_DIR, \"candidates\", f\"candidate_v{i}.png\")\n",
    "    img.save(path)\n",
    "    paths.append(path)\n",
    "\n",
    "print(\"✔ Saved candidates:\")\n",
    "print(\"\\n\".join(paths))\n",
    "\n",
    "\n",
    "# params.json (벤치마킹 로그)\n",
    "\n",
    "params = {\n",
    "    \"mode\": MODE,\n",
    "    \"seed\": seed,\n",
    "    \"steps\": num_steps,\n",
    "    \"guidance_scale\": guidance,\n",
    "    \"controlnet_scale\": control_scale if use_controlnet else None,\n",
    "    \"latency_ms\": latency_ms,\n",
    "    \"vram_used_mb\": vram_peak,\n",
    "    \"input_image\": str(input_image_path) if use_controlnet else None,\n",
    "    \"output_path\": str(SAVE_DIR),\n",
    "}\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"params.json\"), \"w\") as f:\n",
    "    json.dump(params, f, indent=2)\n",
    "\n",
    "print(\"\\n✔ params.json saved\")\n",
    "print(\"Run folder:\", SAVE_DIR)\n",
    "print(f\"▶ latency: {latency_ms} ms   |   vram_peak: {vram_peak} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

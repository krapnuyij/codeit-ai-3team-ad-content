---
layout: default
title: "AI ê´‘ê³  ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ"
description: "AI ê´‘ê³  ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ"
date: 2026-01-02
author: "ê¹€ëª…í™˜"
cache-control: no-cache
expires: 0
pragma: no-cache
---

# AI ê´‘ê³  ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ

**ì‘ì„±ì¼**: 2026.01.01<br/>
**ì‘ì„±ì**: ê¹€ëª…í™˜<br/>
**ë²„ì „**: v1.0<br/>
**í”„ë¡œì íŠ¸**: ìƒì„±í˜• AI ê¸°ë°˜ ì†Œìƒê³µì¸ ê´‘ê³  ì½˜í…ì¸  ì œì‘ ì§€ì› ì„œë¹„ìŠ¤<br/>

---

## 1. ê°œìš” (Overview)

### 1.1. ë¬¸ì„œ ëª©ì 

ë³¸ ë¬¸ì„œëŠ” ìƒì„±í˜• AI ê¸°ë°˜ ê´‘ê³  ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œì˜ ì „ì²´ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì‚¬ìš©ì-í”„ë¡ íŠ¸ì—”ë“œ-ë°±ì—”ë“œ-ëª¨ë¸ì„œë¹™ì˜ 4ê³„ì¸µ êµ¬ì¡°ì™€ ê° ì»´í¬ë„ŒíŠ¸ ê°„ í†µì‹  ë°©ì‹, ë°ì´í„° íë¦„, ë°°í¬ ì „ëµì„ ê¸°ìˆ í•©ë‹ˆë‹¤.

### 1.2. ì‹œìŠ¤í…œ ëª©í‘œ

- **ì‚¬ìš©ì ì¹œí™”ì„±**: FastAPI ê¸°ë°˜ì˜ ì§ê´€ì ì¸ UIë¡œ ë””ìì¸ ì—­ëŸ‰ì´ ë¶€ì¡±í•œ ì†Œìƒê³µì¸ë„ ì‰½ê²Œ ì‚¬ìš©
- **ê³ ì„±ëŠ¥ AI ì¶”ë¡ **: NVIDIA L4 GPUë¥¼ í™œìš©í•œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
- **í™•ì¥ ê°€ëŠ¥ì„±**: Docker ê¸°ë°˜ ì»¨í…Œì´ë„ˆí™”ë¡œ ê° ê³„ì¸µì˜ ë…ë¦½ì ì¸ í™•ì¥ ë° ë°°í¬
- **ì•ˆì •ì„±**: ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§ì„ í†µí•œ ì„œë¹„ìŠ¤ ì•ˆì •ì„± í™•ë³´

### 1.3. ê¸°ìˆ  ìŠ¤íƒ

| ê³„ì¸µ | ê¸°ìˆ  ìŠ¤íƒ | ë¹„ê³  |
|-----|----------|------|
| **í”„ë¡ íŠ¸ì—”ë“œ** | FastAPI, Python 3.11+ | ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ |
| **ë°±ì—”ë“œ** | FastAPI, Python 3.11+ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, LLM ì—°ë™ |
| **ëª¨ë¸ì„œë¹™** | FastAPI, PyTorch, Diffusers | AI ëª¨ë¸ ì¶”ë¡  ì„œë²„ |
| **AI ëª¨ë¸** | FLUX.1-dev, BiRefNet, Qwen2-VL, LLM (HTML) | ì´ë¯¸ì§€ ìƒì„±, ì²˜ë¦¬, ë¶„ì„, í…ìŠ¤íŠ¸ ë Œë”ë§ |
| **ê´‘ê³ í˜ì´ì§€ ìƒì„±** | LangGraph, OpenAI, Playwright | ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—…, HTML ìƒì„± |
| **ë°°í¬** | Docker, Docker Compose | ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë°°í¬ |
| **ì¸í”„ë¼** | GCP VM (L4 GPU) | NVIDIA L4 24GB VRAM |

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (System Architecture)

### 2.1. ì „ì²´ êµ¬ì¡°ë„ (High-Level Architecture)

```mermaid
graph TB
    subgraph "ì‚¬ìš©ì í™˜ê²½"
        User["ì‚¬ìš©ì (ì†Œìƒê³µì¸)"]
        LLMClient["LLM / GPT
(MCP í´ë¼ì´ì–¸íŠ¸)"]
    end

    subgraph "Docker Network: nanococoa-network"
        subgraph "ë°±ì—”ë“œ ê³„ì¸µ (backend)"
            Backend["FastAPI ì„œë²„
ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
Port: 8080"]
            HPGen["Homepage Generator
LangGraph + Multi-Agent
Port: 8081"]
            DB[("PostgreSQL
ê³ ê° ë°ì´í„°")]
        end

        subgraph "MCP ì„œë²„ (nanoCocoa_mcpserver)"
            MCPServer["MCP ì„œë²„
MCP Protocol Bridge
Port: 3000"]
        end

        subgraph "ëª¨ë¸ì„œë¹™ ê³„ì¸µ (nanoCocoa_aiserver)"
            ModelServer["FastAPI ëª¨ë¸ ì„œë²„
Port: 8000"]

            subgraph "AI ëª¨ë¸ íŒŒì´í”„ë¼ì¸"
                BiRefNet["BiRefNet
(ì´ë¯¸ì§€ ëˆ„ë¼)"]
                FLUX["FLUX.1-dev
(ë°°ê²½ ìƒì„±)"]
                Qwen["Qwen2-VL
(ì´ë¯¸ì§€ ë¶„ì„)"]
            end

            LLMText["OpenAI API
(HTML/CSS ìƒì„±)"]
            GPU["NVIDIA L4 GPU
24GB VRAM"]
        end
    end

    User -->|HTTP/ì›¹| Backend
    Backend --> DB
    Backend --> HPGen
    HPGen -->|HTTP| MCPServer
    Backend -->|"REST API
Port 8000"| ModelServer
    
    LLMClient -.->|"MCP Protocol
(SSE)"| MCPServer
    MCPServer -->|"REST API
Internal Network"| ModelServer
    
    ModelServer --> BiRefNet
    ModelServer --> FLUX
    ModelServer --> Qwen
    ModelServer --> LLMText
    
    BiRefNet -.->|JIT ë¡œë”©| GPU
    FLUX -.->|JIT ë¡œë”©| GPU
    Qwen -.->|JIT ë¡œë”©| GPU
```

### 2.2. ê³„ì¸µë³„ ì—­í•  (Layer Responsibilities)

#### 2.2.1. í”„ë¡ íŠ¸ì—”ë“œ ê³„ì¸µ

**ì—­í• **: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì œê³µ ë° ì…ë ¥ ë°ì´í„° ìˆ˜ì§‘

- FastAPI ê¸°ë°˜ ì›¹ UI
- ì´ë¯¸ì§€ ì—…ë¡œë“œ (ìƒí’ˆ ì´ë¯¸ì§€)
- ê´‘ê³  ë¬¸êµ¬ ì…ë ¥ (í…ìŠ¤íŠ¸)
- ìƒì„± ì˜µì…˜ ì„¤ì • (ë°°ê²½ ìŠ¤íƒ€ì¼, í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ë“±)
- ìƒì„± ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ

**í†µì‹  ë°©ì‹**: HTTP/REST API (â†’ ë°±ì—”ë“œ 8080 í¬íŠ¸)

#### 2.2.2. ë°±ì—”ë“œ ê³„ì¸µ

**ì—­í• **: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ ë° ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™

- ì‚¬ìš©ì ìš”ì²­ ê²€ì¦ ë° ì „ì²˜ë¦¬
- LLM(GPT-5-mini) ì—°ë™ì„ í†µí•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
  - ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ AI ëª¨ë¸ì— ì í•©í•œ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±
  - ì˜ˆ: "ê±´ì–´ë¬¼ ëŒ€ë°• ì„¸ì¼" â†’ "Dried seafood products on a rustic wooden table, traditional Korean market atmosphere, vibrant colors, photorealistic"
- ëª¨ë¸ ì„œë²„ í˜¸ì¶œ ë° ì‘ë‹µ ê´€ë¦¬
- ì‘ì—… ìƒíƒœ ì¶”ì  ë° í´ë§ ì²˜ë¦¬
- ì—ëŸ¬ í•¸ë“¤ë§ ë° ì‚¬ìš©ì í”¼ë“œë°±

**í†µì‹  ë°©ì‹**:
- í”„ë¡ íŠ¸ì—”ë“œ â† HTTP/REST API (8080 í¬íŠ¸ ìˆ˜ì‹ )
- ëª¨ë¸ì„œë¹™ â†’ HTTP/REST API (8000 í¬íŠ¸ í˜¸ì¶œ)
- OpenAI API â†’ HTTPS

#### 2.2.3. ëª¨ë¸ì„œë¹™ ê³„ì¸µ (nanoCocoa_aiserver)

**ì—­í• **: AI ëª¨ë¸ ì¶”ë¡  ë° ì´ë¯¸ì§€ ìƒì„±

- FastAPI ê¸°ë°˜ REST API ì„œë²„
- GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ (JIT ë¡œë”©/ì–¸ë¡œë”©)
- ë¹„ë™ê¸° ì¶”ë¡  ì‘ì—… ì²˜ë¦¬ (ë©€í‹°í”„ë¡œì„¸ì‹±)
- 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  - **Stage 1 (ë°°ê²½ ìƒì„±)**: BiRefNet ëˆ„ë¼ â†’ FLUX.1-dev ë°°ê²½ ìƒì„± â†’ í•©ì„± ë° ë¦¬í„°ì¹­
  - **Stage 2 (í…ìŠ¤íŠ¸ ë Œë”ë§)**: Qwen2-VL ì´ë¯¸ì§€ ë¶„ì„ (ì„ íƒ) â†’ LLM HTML/CSS ìƒì„± â†’ HTML ë Œë”ë§ â†’ í…ìŠ¤íŠ¸ ë ˆì´ì–´ í•©ì„±

**Docker ë°°í¬**:
- ì»¨í…Œì´ë„ˆëª…: `nanococoa-aiserver`
- í¬íŠ¸: 8000 (ì™¸ë¶€ ë…¸ì¶œ)
- GPU ì ‘ê·¼: NVIDIA Driver, ëª¨ë“  GPU ì‚¬ìš© ê°€ëŠ¥
- ë³¼ë¥¨:
  - `/opt/huggingface` â†’ HuggingFace ëª¨ë¸ ìºì‹œ
  - `./nanoCocoa_aiserver/static/uploads` â†’ ì—…ë¡œë“œ íŒŒì¼
  - `./nanoCocoa_aiserver/static/results` â†’ ê²°ê³¼ íŒŒì¼
  - `./nanoCocoa_aiserver/logs` â†’ ë¡œê·¸

**í†µì‹  ë°©ì‹**:
- ë°±ì—”ë“œ â† HTTP/REST API (8000 í¬íŠ¸ ìˆ˜ì‹ )
- MCP ì„œë²„ â† HTTP/REST API (ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬, nanococoa-network)

**ìƒì„¸ ì•„í‚¤í…ì²˜**: [nanoCocoa_AI_Server_ì•„í‚¤í…ì²˜ì„¤ê³„.md](./nanoCocoa_AI_Server_ì•„í‚¤í…ì²˜ì„¤ê³„.md) ì°¸ì¡°

#### 2.2.4. MCP ì„œë²„ ê³„ì¸µ (nanoCocoa_mcpserver)

**ì—­í• **: MCP í”„ë¡œí† ì½œ ë¸Œë¦¿ì§€ ì„œë²„

- nanoCocoa_aiserver REST APIë¥¼ MCP í”„ë¡œí† ì½œë¡œ ë³€í™˜
- LLM Desktop/Codeì™€ ì—°ë™í•˜ì—¬ ìì—°ì–´ë¡œ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥
- 8ê°œì˜ MCP ë„êµ¬ ì œê³µ (generate_ad_image, check_generation_status ë“±)
- SSE (Server-Sent Events) ì „ì†¡ ë°©ì‹

**Docker ë°°í¬**:
- ì»¨í…Œì´ë„ˆëª…: `nanococoa-mcpserver`
- í¬íŠ¸: 3000 (ì™¸ë¶€ ë…¸ì¶œ)
- ì˜ì¡´ì„±: nanoCocoa-aiserver (health check ëŒ€ê¸°)
- í™˜ê²½ë³€ìˆ˜:
  - `MCP_TRANSPORT=sse`
  - `MCP_PORT=3000`
  - `AISERVER_BASE_URL=http://nanococoa-aiserver:8000` (ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬)

**í†µì‹  ë°©ì‹**:
- LLM Desktop/Code â† MCP Protocol (SSE, 3000 í¬íŠ¸)
- nanoCocoa_aiserver â†’ HTTP/REST API (ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬)

---

## 3. ë°ì´í„° íë¦„ (Data Flow)

### 3.1. ì „ì²´ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant FE as í”„ë¡ íŠ¸ì—”ë“œ (FastAPI)
    participant BE as ë°±ì—”ë“œ (FastAPI)
    participant LLM as OpenAI GPT-5-mini
    participant MS as ëª¨ë¸ì„œë¹™ (FastAPI)
    participant GPU as L4 GPU

    User->>FE: 1. ì´ë¯¸ì§€ ì—…ë¡œë“œ + ê´‘ê³  ë¬¸êµ¬ ì…ë ¥
    FE->>FE: 2. ì…ë ¥ ê²€ì¦
    FE->>BE: 3. POST /api/generate {image, text, options}

    BE->>BE: 4. ìš”ì²­ ê²€ì¦
    BE->>LLM: 5. í”„ë¡¬í”„íŠ¸ ìƒì„± ìš”ì²­ "ê±´ì–´ë¬¼ ëŒ€ë°• ì„¸ì¼"
    LLM-->>BE: 6. ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ "Dried seafood..."

    BE->>MS: 7. POST /generate {product_image, bg_prompt, text_content}
    MS->>MS: 8. Job ID ìƒì„± Worker Process ìƒì„±
    MS-->>BE: 9. {job_id, status: "started"}
    BE-->>FE: 10. {job_id}
    FE-->>User: 11. "ìƒì„± ì¤‘..." í‘œì‹œ

    loop ì§„í–‰ ìƒí™© í´ë§ (Polling)
        FE->>BE: 12. GET /api/status/{job_id}
        BE->>MS: 13. GET /status/{job_id}

        MS->>MS: Stage 1 ì‹¤í–‰
        MS->>GPU: BiRefNet ë¡œë“œ
        GPU-->>MS: ëˆ„ë¼ ì´ë¯¸ì§€
        MS->>GPU: FLUX.1-dev ë¡œë“œ
        GPU-->>MS: ë°°ê²½ ì´ë¯¸ì§€
        MS->>MS: í•©ì„± ë° ë¦¬í„°ì¹­

        MS-->>BE: 14. {status: "running", progress: 50%, step1_result}
        BE-->>FE: 15. {progress, step1_preview}
        FE-->>User: 16. ì§„í–‰ë¥  + ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ

        MS->>MS: Stage 2 ì‹¤í–‰
        
        alt use_qwen_analysis=true
            MS->>GPU: Qwen2-VL ë¡œë“œ
            GPU-->>MS: ì´ë¯¸ì§€ ë¶„ì„ í…ìŠ¤íŠ¸
            MS->>GPU: Qwen2-VL ì–¸ë¡œë“œ
        end
        
        MS->>LLM: HTML/CSS ìƒì„± ìš”ì²­ (Qwen ë¶„ì„ í¬í•¨)
        LLM-->>MS: HTML/CSS ì½”ë“œ
        MS->>MS: HTML ë Œë”ë§ (Headless Browser)
        MS->>MS: í…ìŠ¤íŠ¸ ë ˆì´ì–´ í•©ì„±

        MS-->>BE: 17. {status: "completed", final_result}
        BE-->>FE: 18. {status: "done", final_image}
    end

    FE-->>User: 19. ìµœì¢… ê²°ê³¼ í‘œì‹œ + ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
```

### 3.2. API ì—”ë“œí¬ì¸íŠ¸ ëª…ì„¸

#### 3.2.1. ë°±ì—”ë“œ API (Port 8080)

| ë©”ì„œë“œ | ê²½ë¡œ | ì„¤ëª… | ìš”ì²­ | ì‘ë‹µ |
|--------|------|------|------|------|
| POST | `/api/generate` | ê´‘ê³  ìƒì„± ì‹œì‘ | `{image, text, style}` | `{job_id}` |
| GET | `/api/status/{job_id}` | ì‘ì—… ìƒíƒœ ì¡°íšŒ | - | `{status, progress, result}` |
| POST | `/api/stop/{job_id}` | ì‘ì—… ì¤‘ë‹¨ | - | `{status: "stopped"}` |

**ìš”ì²­ ì˜ˆì‹œ (ë°±ì—”ë“œ)**:
```json
{
  "product_image": "base64_encoded_image...",
  "ad_text": "ê±´ì–´ë¬¼ ëŒ€ë°• ì„¸ì¼",
  "background_style": "ì „í†µì‹œì¥ ë¶„ìœ„ê¸°",
  "text_style": "ê³¨ë“œ í’ì„  í…ìŠ¤íŠ¸"
}
```

**ì‘ë‹µ ì˜ˆì‹œ (ë°±ì—”ë“œ)**:
```json
{
  "job_id": "uuid-v4",
  "status": "processing"
}
```

#### 3.2.2. ëª¨ë¸ì„œë¹™ API (Port 8000)

| ë©”ì„œë“œ | ê²½ë¡œ | ì„¤ëª… | ìš”ì²­ | ì‘ë‹µ |
|--------|------|------|------|------|
| POST | `/generate` | AI ìƒì„± ì‘ì—… ì‹œì‘ | `{product_image, bg_prompt, text_content, ...}` | `{job_id, status}` |
| GET | `/status/{job_id}` | ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ | - | `{status, progress, images, metrics}` |
| POST | `/stop/{job_id}` | ì‘ì—… ê°•ì œ ì¤‘ë‹¨ | - | `{job_id, status}` |
| GET | `/health` | ì„œë²„ ìƒíƒœ í™•ì¸ | - | `{status, gpu_available}` |
| GET | `/fonts` | ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ëª©ë¡ | - | `[{name, path}]` |

**ìš”ì²­ ì˜ˆì‹œ (ëª¨ë¸ì„œë¹™)**:
```json
{
  "start_step": 1,
  "product_image": "base64_string...",
  "text_content": "Super Sale",
  "bg_prompt": "Wooden table in a cozy cafe, sunlight, realistic",
  "html_style_prompt": "Gold gradient with shadow, modern bold",
  "use_qwen_analysis": true,
  "use_llm_html": true,
  "text_position": "top",
  "strength": 0.6,
  "guidance_scale": 3.5,
  "test_mode": false
}
```

**ì‘ë‹µ ì˜ˆì‹œ (ëª¨ë¸ì„œë¹™)**:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "running",
  "progress_percent": 45,
  "current_step": "step2_html_rendering",
  "sub_step": "llm_html_generation",
  "message": "Generating HTML text layout...",
  "elapsed_sec": 67.3,
  "eta_seconds": 85,
  "step_eta_seconds": 42,
  "system_metrics": {
    "cpu_percent": 45.2,
    "ram_used_gb": 12.5,
    "ram_total_gb": 32.0,
    "ram_percent": 39.1,
    "gpu_info": [
      {
        "index": 0,
        "name": "NVIDIA L4",
        "vram_used_mb": 15234,
        "vram_total_mb": 24576,
        "vram_percent": 62.0,
        "utilization": 98
      }
    ]
  },
  "parameters": {
    "start_step": 1,
    "text_content": "Super Sale",
    "bg_prompt": "Wooden table in a cozy cafe..."
  },
  "step1_result": "base64_image_step1...",
  "final_result": null
}
```

---

## 4. ë°°í¬ ì•„í‚¤í…ì²˜ (Deployment Architecture)

### 4.1. Docker ì»¨í…Œì´ë„ˆ êµ¬ì„±

```mermaid
graph TB
    subgraph "GCP VM Instance (L4 GPU)"
        subgraph "Docker Network: nanococoa-network"
            Container1["Container 1
Frontend
FastAPI + FastAPI
Port: ì™¸ë¶€ ë…¸ì¶œ"]
            Container2["Container 2
Backend
FastAPI
Port: 8080 (ë‚´ë¶€)"]
            Container3["Container 3
nanoCocoa_aiserver
FastAPI + AI Models
Port: 8000 (ì™¸ë¶€)"]
            Container4["Container 4
nanoCocoa_mcpserver
MCP Bridge
Port: 3000 (ì™¸ë¶€)"]
        end

        GPU_Device["NVIDIA L4 GPU
Device: /dev/nvidia0"]
    end

    Internet["Internet"] -->|HTTPS| Container1
    LLM["LLM Desktop/Code"] -.->|MCP Protocol| Container4
    Container1 -->|Internal Network| Container2
    Container2 -->|Internal Network| Container3
    Container4 -->|Internal Network| Container3
    Container3 -.->|GPU Access| GPU_Device
```

### 4.2. Docker Compose êµ¬ì„±

ì‹¤ì œ ë°°í¬ ì¤‘ì¸ êµ¬ì„± (`src/docker-compose.yml`):

```yaml
version: '3.8'

services:
  nanococoa-aiserver:
    build:
      context: ./nanoCocoa_aiserver
      dockerfile: Dockerfile
    image: nanococoa-aiserver:latest
    container_name: nanococoa-aiserver

    # GPU ì„¤ì •
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # í¬íŠ¸ ë§¤í•‘
    ports:
      - "8000:8000"

    # ë³¼ë¥¨ ë§ˆìš´íŠ¸
    volumes:
      # HuggingFace ìºì‹œ (ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€)
      - /opt/huggingface:/root/.cache/huggingface
      # ì—…ë¡œë“œ/ê²°ê³¼ íŒŒì¼ (ì˜êµ¬ ì €ì¥)
      - ./nanoCocoa_aiserver/static/uploads:/app/static/uploads
      - ./nanoCocoa_aiserver/static/results:/app/static/results
      # ë¡œê·¸ (ì˜êµ¬ ì €ì¥)
      - ./nanoCocoa_aiserver/logs:/app/logs

    # í™˜ê²½ ë³€ìˆ˜
    env_file:
      - .env
    environment:
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - HF_HOME=/root/.cache/huggingface
      - DEVICE=cuda
      - AUTO_UNLOAD_DEFAULT=true

    # ì¬ì‹œì‘ ì •ì±…
    restart: unless-stopped

    # í—¬ìŠ¤ì²´í¬
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    networks:
      - nanococoa-network

  nanococoa-mcpserver:
    build:
      context: ./nanoCocoa_mcpserver
      dockerfile: Dockerfile
    image: nanococoa-mcpserver:latest
    container_name: nanococoa-mcpserver

    # í¬íŠ¸ ë§¤í•‘
    ports:
      - "3000:3000"

    # ë³¼ë¥¨ ë§ˆìš´íŠ¸ (ì´ë¯¸ì§€ íŒŒì¼ ê³µìœ )
    volumes:
      - ./nanoCocoa_aiserver/static/uploads:/app/static/uploads
      - ./nanoCocoa_aiserver/static/results:/app/static/results

    # í™˜ê²½ ë³€ìˆ˜
    environment:
      - MCP_TRANSPORT=sse
      - MCP_PORT=3000
      - MCP_HOST=0.0.0.0
      - AISERVER_BASE_URL=http://nanococoa-aiserver:8000
      - LOG_LEVEL=INFO

    # ì˜ì¡´ì„± (AI ì„œë²„ê°€ healthy ìƒíƒœì¼ ë•Œë§Œ ì‹œì‘)
    depends_on:
      nanococoa-aiserver:
        condition: service_healthy

    # ì¬ì‹œì‘ ì •ì±…
    restart: unless-stopped

    # í—¬ìŠ¤ì²´í¬
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    networks:
      - nanococoa-network

networks:
  nanococoa-network:
    name: nanococoa-network
    driver: bridge
```

**ì£¼ìš” íŠ¹ì§•**:
- GPU ë¦¬ì†ŒìŠ¤ë¥¼ AI ì„œë²„ì—ë§Œ í• ë‹¹
- MCP ì„œë²„ëŠ” AI ì„œë²„ì˜ health checkì´ ì„±ê³µí•œ í›„ì— ì‹œì‘ (`depends_on` ì¡°ê±´)
- ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ (`nanococoa-network`)ë¥¼ í†µí•´ ì„œë¹„ìŠ¤ ê°„ í†µì‹ 
- ë³¼ë¥¨ ë§ˆìš´íŠ¸ë¡œ ë°ì´í„° ì˜êµ¬ ì €ì¥ ë° ê³µìœ 

### 4.3. í¬íŠ¸ êµ¬ì„± (Port Configuration)

| ì»¨í…Œì´ë„ˆ | ë‚´ë¶€ í¬íŠ¸ | ì™¸ë¶€ í¬íŠ¸ | ì ‘ê·¼ ë²”ìœ„ | ìš©ë„ |
|----------|----------|----------|-----------|------|
| **í”„ë¡ íŠ¸ì—”ë“œ** | 8501 | 80 (HTTPS) | Public | ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ |
| **ë°±ì—”ë“œ** | 8080 | 8080 | Internal Only | ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ API |
| **nanoCocoa_aiserver** | 8000 | 8000 | Public | AI ëª¨ë¸ ì¶”ë¡  API |
| **nanoCocoa_mcpserver** | 3000 | 3000 | Public | MCP í”„ë¡œí† ì½œ ë¸Œë¦¿ì§€ |

**ì°¸ê³ **:
- AI ì„œë²„(8000)ì™€ MCP ì„œë²„(3000)ëŠ” ì™¸ë¶€ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í¬íŠ¸ ë…¸ì¶œ
- MCP ì„œë²„ëŠ” ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ `http://nanococoa-aiserver:8000`ìœ¼ë¡œ AI ì„œë²„ ì ‘ê·¼

---

## 5. í”„ë¡ íŠ¸ì—”ë“œ ì„¤ê³„ (Frontend Design)

### 5.1. ê¸°ìˆ  ìŠ¤íƒ

- **í”„ë ˆì„ì›Œí¬**: FastAPI
- **ì–¸ì–´**: Python 3.11+
- **ì„œë²„**: FastAPI (FastAPI ì„ë² ë”©)
- **í†µì‹ **: HTTP REST API (ë°±ì—”ë“œ 8080 í¬íŠ¸)

### 5.2. ì£¼ìš” ê¸°ëŠ¥

1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**
   - ë“œë˜ê·¸ ì•¤ ë“œë¡­ ë˜ëŠ” íŒŒì¼ ì„ íƒ
   - ì§€ì› í˜•ì‹: JPG, PNG
   - ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°

2. **ê´‘ê³  ë¬¸êµ¬ ì…ë ¥**
   - í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ
   - ìµœëŒ€ ê¸¸ì´ ì œí•œ (ì˜ˆ: 20ì)

3. **ìŠ¤íƒ€ì¼ ì„ íƒ**
   - ë°°ê²½ ìŠ¤íƒ€ì¼ (ì „í†µì‹œì¥, ê³ ê¸‰ìŠ¤ëŸ¬ìš´, ë¯¸ë‹ˆë©€ ë“±)
   - í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ (ê³¨ë“œ í’ì„ , ë„¤ì˜¨, 3D ë©”íƒˆ ë“±)

4. **ìƒì„± ì§„í–‰ ìƒí™© í‘œì‹œ**
   - ì§„í–‰ë¥  ë°” (Progress Bar)
   - í˜„ì¬ ë‹¨ê³„ í‘œì‹œ (ëˆ„ë¼ ì²˜ë¦¬ ì¤‘, ë°°ê²½ ìƒì„± ì¤‘, í…ìŠ¤íŠ¸ ìƒì„± ì¤‘)
   - ì¤‘ê°„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°

5. **ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**
   - ìµœì¢… ì´ë¯¸ì§€ í‘œì‹œ
   - ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (PNG í˜•ì‹)

### 5.3. UI í”Œë¡œìš°

```
[ì´ë¯¸ì§€ ì—…ë¡œë“œ] â†’ [ê´‘ê³  ë¬¸êµ¬ ì…ë ¥] â†’ [ìŠ¤íƒ€ì¼ ì„ íƒ] â†’ [ìƒì„± ë²„íŠ¼ í´ë¦­]
                                                              â†“
                                    [ì§„í–‰ ìƒí™© í‘œì‹œ + ì¤‘ê°„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°]
                                                              â†“
                                          [ìµœì¢… ê²°ê³¼ í‘œì‹œ + ë‹¤ìš´ë¡œë“œ]
```

### 5.4. ë°±ì—”ë“œ ì—°ë™

```python
import streamlit as st
import requests
import time

BACKEND_URL = "http://backend:8080"

# 1. ìƒì„± ìš”ì²­
def generate_ad(image, text, style):
    response = requests.post(
        f"{BACKEND_URL}/api/generate",
        json={
            "product_image": image,
            "ad_text": text,
            "background_style": style["background"],
            "text_style": style["text"]
        }
    )
    return response.json()["job_id"]

# 2. ìƒíƒœ í´ë§
def poll_status(job_id):
    while True:
        response = requests.get(f"{BACKEND_URL}/api/status/{job_id}")
        data = response.json()

        if data["status"] == "completed":
            return data["result"]
        elif data["status"] == "failed":
            raise Exception(data["error"])

        # ì§„í–‰ ìƒí™© í‘œì‹œ
        st.progress(data["progress"] / 100)
        st.text(data["message"])

        time.sleep(2)  # 2ì´ˆë§ˆë‹¤ í´ë§
```

---

## 6. ë°±ì—”ë“œ ì„¤ê³„ (Backend Design)

### 6.1. ê¸°ìˆ  ìŠ¤íƒ

- **í”„ë ˆì„ì›Œí¬**: FastAPI
- **ì–¸ì–´**: Python 3.11+
- **ì™¸ë¶€ API**: OpenAI GPT-5-mini
- **í†µì‹ **: HTTP REST API

### 6.2. ì£¼ìš” ê¸°ëŠ¥

1. **í”„ë¡¬í”„íŠ¸ ìƒì„± (LLM ì—°ë™)**
   - ì‚¬ìš©ì ì…ë ¥ (í•œê¸€ í…ìŠ¤íŠ¸ + ìŠ¤íƒ€ì¼ ì„ íƒ)ì„ ë¶„ì„
   - GPT-4oë¥¼ í†µí•´ AI ëª¨ë¸ì— ì í•©í•œ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ ìƒì„±

   **ì˜ˆì‹œ**:
   ```
   ì…ë ¥: "ê±´ì–´ë¬¼ ëŒ€ë°• ì„¸ì¼", ìŠ¤íƒ€ì¼: "ì „í†µì‹œì¥ ë¶„ìœ„ê¸°"

   LLM í”„ë¡¬í”„íŠ¸:
   "Generate a professional English prompt for an AI image generation model.
   Input: Korean text 'ê±´ì–´ë¬¼ ëŒ€ë°• ì„¸ì¼', style: traditional market atmosphere.
   Output: Detailed prompt for background generation and text style."

   LLM ì‘ë‹µ:
   {
     "background_prompt": "Traditional Korean market stall with dried seafood products, wooden display, warm lighting, authentic atmosphere, photorealistic, 8k",
     "text_prompt": "3D render of bold Korean text 'ëŒ€ë°• ì„¸ì¼', red and gold colors, festive style, hanging banner effect"
   }
   ```

2. **ëª¨ë¸ ì„œë²„ í˜¸ì¶œ**
   - ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì„œë²„ë¡œ ì „ì†¡
   - Job ID ë°˜í™˜

3. **ìƒíƒœ ê´€ë¦¬**
   - ëª¨ë¸ ì„œë²„ì˜ `/status/{job_id}` í´ë§
   - ì§„í–‰ ìƒí™©ì„ í”„ë¡ íŠ¸ì—”ë“œì— ì „ë‹¬

4. **ì—ëŸ¬ í•¸ë“¤ë§**
   - ëª¨ë¸ ì„œë²„ ì¥ì•  ì‹œ ì¬ì‹œë„ ë¡œì§
   - ì‚¬ìš©ìì—ê²Œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜

### 6.3. API êµ¬í˜„ ì˜ˆì‹œ

```python
from FastAPI import FastAPI, HTTPException
from openai import OpenAI
import httpx

app = FastAPI()
client = OpenAI()

MODEL_SERVER_URL = "http://model-serving:8000"

@app.post("/api/generate")
async def generate_ad(request: GenerateRequest):
    # 1. LLMì„ í†µí•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompts = await generate_prompts_with_llm(
        request.ad_text,
        request.background_style,
        request.text_style
    )

    # 2. ëª¨ë¸ ì„œë²„ í˜¸ì¶œ
    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{MODEL_SERVER_URL}/generate",
            json={
                "product_image": request.product_image,
                "text_content": request.ad_text,
                "bg_prompt": prompts["background"],
                "text_model_prompt": prompts["text"],
                "start_step": 1
            },
            timeout=10.0
        )

    return response.json()

async def generate_prompts_with_llm(text, bg_style, text_style):
    completion = client.chat.completions.create(
        model="gpt-5-mini",
        messages=[
            {
                "role": "system",
                "content": "You are an expert prompt engineer for AI image generation."
            },
            {
                "role": "user",
                "content": f"""Generate detailed English prompts for:
                - Text: {text}
                - Background style: {bg_style}
                - Text style: {text_style}

                Return JSON with 'background' and 'text' keys."""
            }
        ]
    )

    # JSON íŒŒì‹±
    result = completion.choices[0].message.content
    return eval(result)  # ì‹¤ì œë¡œëŠ” json.loads() ì‚¬ìš©
```

---

## 7. ëª¨ë¸ì„œë¹™ ì„¤ê³„ (Model Serving Design)

### 7.1. ìƒì„¸ ì„¤ê³„ ë¬¸ì„œ

ëª¨ë¸ì„œë¹™ ê³„ì¸µì˜ ìƒì„¸í•œ ì•„í‚¤í…ì²˜ëŠ” ë³„ë„ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:

**ğŸ“„ [nanoCocoa_AI_Server_ì•„í‚¤í…ì²˜ì„¤ê³„.md](./nanoCocoa_AI_Server_ì•„í‚¤í…ì²˜ì„¤ê³„.md)**

### 7.2. ì£¼ìš” íŠ¹ì§• ìš”ì•½

- **JIT (Just-In-Time) ëª¨ë¸ ë¡œë”©**: ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•´ í•„ìš”í•  ë•Œë§Œ ëª¨ë¸ì„ GPUì— ë¡œë“œ
- **ë¹„ë™ê¸° ì²˜ë¦¬**: `multiprocessing`ì„ í™œìš©í•œ Non-blocking ì¶”ë¡ 
- **3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸**: ë°°ê²½ ìƒì„± â†’ í…ìŠ¤íŠ¸ ìƒì„± â†’ ìµœì¢… í•©ì„±
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: CPU/RAM/GPU ì‚¬ìš©ë¥  ì‹¤ì‹œê°„ ì œê³µ
- **ë‹¨ê³„ë³„ ì¬ì‹œì‘**: ì‹¤íŒ¨ ì‹œ íŠ¹ì • ë‹¨ê³„ë¶€í„° ì¬ì‹¤í–‰ ê°€ëŠ¥

### 7.3. í•µì‹¬ API

```python
# ëª¨ë¸ ì„œë²„ í•µì‹¬ ë¡œì§ (ê°„ëµí™”)
@router.post("/generate")
async def generate_ad(req: GenerateRequest):
    job_id = str(uuid.uuid4())

    # Worker Process ìƒì„± (ë¹„ë™ê¸° ì²˜ë¦¬)
    p = multiprocessing.Process(
        target=worker_process,
        args=(job_id, req.model_dump(), shared_jobs[job_id])
    )
    p.start()

    return {"job_id": job_id, "status": "started"}

def worker_process(job_id, input_data, shared_state):
    # Step 1: ë°°ê²½ ìƒì„±
    step1_result = generate_background(
        input_data["product_image"],
        input_data["bg_prompt"]
    )
    shared_state["step1_result"] = step1_result

    # Step 2: LLM ê¸°ë°˜ HTML í…ìŠ¤íŠ¸ ë Œë”ë§ (Qwen ë¶„ì„ í™œìš©)
    qwen_analysis = None
    if input_data.get("use_qwen_analysis"):
        # Qwen2-VLë¡œ ì´ë¯¸ì§€ ë¶„ì„ (ê°ì²´ ìœ„ì¹˜, ìƒ‰ìƒ, ì—¬ë°± ë¶„ì„)
        qwen_analysis = analyze_image_with_qwen(step1_result)
    
    # LLMì— Qwen ë¶„ì„ ê²°ê³¼ ì „ë‹¬í•˜ì—¬ ìµœì  ë°°ì¹˜ ê²°ì •
    html_css_code = generate_html_with_llm(
        input_data["text_content"],
        input_data["html_style_prompt"],
        qwen_analysis  # ì´ë¯¸ì§€ ë¶„ì„ ì •ë³´ ì „ë‹¬
    )
    text_layer = render_html_to_image(html_css_code)

    # ìµœì¢… í•©ì„±
    final_result = composite_text_on_background(step1_result, text_layer)
    shared_state["final_result"] = final_result
    shared_state["status"] = "completed"
```

### 7.4. Qwen ì´ë¯¸ì§€ ë¶„ì„ ê¸°ë°˜ ìë™ë°°ì¹˜ (Auto Layout with Qwen Analysis)

#### 7.4.1. ê°œìš” (Overview)

**ëª©ì **: Step2+Step3ì˜ LLM Text ì˜µì…˜ì—ì„œ Qwen2-VLì˜ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ìµœì  ìœ„ì¹˜ì™€ ìŠ¤íƒ€ì¼ì„ ìë™ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.

**í”„ë¡œì„¸ìŠ¤**:
```
Step 1 ê²°ê³¼ ì´ë¯¸ì§€ â†’ Qwen2-VL ë¶„ì„ â†’ LLM í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ HTML/CSS ìƒì„± â†’ í…ìŠ¤íŠ¸ ë Œë”ë§
```

**Qwen ë¶„ì„ í•­ëª©**:
- ê°ì²´ ìœ„ì¹˜ ë° í¬ê¸° (product placement, bounding box)
- ìƒ‰ìƒ ë¶„í¬ ë° ëª…ì•” (color palette, brightness zones)
- ì—¬ë°± ì˜ì—­ ë¶„ì„ (empty spaces, optimal text zones)
- ì‹œê°ì  ì§‘ì¤‘ ì˜ì—­ (visual focus areas)

#### 7.4.2. Qwen ë¶„ì„ ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "objects": [
    {
      "type": "product",
      "location": "bottom-center",
      "bbox": [120, 450, 680, 980],
      "å ìš©ë¥ ": 0.35
    }
  ],
  "color_analysis": {
    "dominant_colors": ["#8B4513", "#F5DEB3", "#FFFFFF"],
    "brightness_map": {
      "top": 0.75,
      "middle": 0.50,
      "bottom": 0.45
    }
  },
  "empty_spaces": [
    {
      "region": "top-center",
      "bbox": [150, 50, 650, 350],
      "suitability": 0.90,
      "reason": "bright background, high contrast area"
    },
    {
      "region": "middle-left",
      "bbox": [50, 300, 200, 600],
      "suitability": 0.65,
      "reason": "moderate space but near product edge"
    }
  ],
  "recommendations": {
    "text_position": "top-center",
    "text_color": "#FF0000",
    "background_needed": true,
    "background_opacity": 0.7,
    "font_size_range": [48, 72]
  }
}
```

#### 7.4.3. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (Qwen ë¶„ì„ í†µí•©)

**Qwen ë¶„ì„ ê²°ê³¼ë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜**:

```python
def generate_llm_prompt_with_qwen(text_content, style_prompt, qwen_analysis):
    """Qwen ë¶„ì„ ê²°ê³¼ë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— í†µí•©"""
    
    # Qwen ê¶Œì¥ì‚¬í•­ ì¶”ì¶œ
    recommended_position = qwen_analysis["recommendations"]["text_position"]
    recommended_color = qwen_analysis["recommendations"]["text_color"]
    empty_space = qwen_analysis["empty_spaces"][0]  # ìµœì  ê³µê°„
    
    prompt = f"""Create HTML/CSS code for advertising text overlay.

**Text Content**: "{text_content}"
**Style Request**: {style_prompt}

**Image Analysis Results (Qwen2-VL)**:
- Product Location: {qwen_analysis["objects"][0]["location"]}
- Optimal Text Zone: {recommended_position}
- Recommended Position: {empty_space["bbox"]}
- Reason: {empty_space["reason"]}
- Background Brightness: {qwen_analysis["color_analysis"]["brightness_map"]}

**Layout Requirements**:
1. Position text in the "{recommended_position}" area
2. Avoid overlapping with product ({qwen_analysis["objects"][0]["bbox"]})
3. Use color "{recommended_color}" for high contrast
4. Add semi-transparent background (opacity: {qwen_analysis["recommendations"]["background_opacity"]})
5. Font size: {qwen_analysis["recommendations"]["font_size_range"][0]}-{qwen_analysis["recommendations"]["font_size_range"][1]}px

**Output**: HTML with inline CSS (800x1200px canvas)
"""
    return prompt
```

#### 7.4.4. ìë™ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜ (Auto Layout Algorithm)

**ë‹¨ê³„ë³„ ì²˜ë¦¬**:

1. **ì´ë¯¸ì§€ ë¶„ì„ (Qwen2-VL)**
   - JIT ë¡œë”©: GPUì— Qwen ëª¨ë¸ ë¡œë“œ
   - í”„ë¡¬í”„íŠ¸: "Analyze this image. Identify product location, color distribution, empty spaces suitable for text overlay."
   - ì¶œë ¥: JSON í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼
   - JIT ì–¸ë¡œë”©: GPU ë©”ëª¨ë¦¬ í•´ì œ

2. **ì—¬ë°± ìŠ¤ì½”ì–´ë§ (Empty Space Scoring)**
   - ê° ì˜ì—­ì˜ ì í•©ì„± ì ìˆ˜ ê³„ì‚° (0~1)
   - ê³ ë ¤ ìš”ì†Œ:
     - ì—¬ë°± í¬ê¸° (ë©´ì )
     - ë°ê¸° ëŒ€ë¹„ (í…ìŠ¤íŠ¸ ê°€ë…ì„±)
     - ê°ì²´ì™€ì˜ ê±°ë¦¬ (ê°„ì„­ ë°©ì§€)
     - ì‹œê°ì  ê· í˜• (ë ˆì´ì•„ì›ƒ ì¡°í™”)

3. **LLM í”„ë¡¬í”„íŠ¸ ê°•í™” (Prompt Enhancement)**
   - Qwen ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
   - ì œì•½ì‚¬í•­ ëª…ì‹œ (ìœ„ì¹˜, ìƒ‰ìƒ, í¬ê¸°)
   - LLMì— ì „ë‹¬í•˜ì—¬ HTML/CSS ìƒì„±

4. **í´ë°± ë©”ì»¤ë‹ˆì¦˜ (Fallback Mechanism)**
   - Qwen ë¶„ì„ ì‹¤íŒ¨ ì‹œ: ê¸°ë³¸ ìœ„ì¹˜ ì‚¬ìš© (`text_position` íŒŒë¼ë¯¸í„°)
   - LLM ìƒì„± ì‹¤íŒ¨ ì‹œ: í…œí”Œë¦¿ ê¸°ë°˜ HTML ì‚¬ìš©

#### 7.4.5. ê¶Œì¥ ì‚¬í•­ (Best Practices)

**ì„±ëŠ¥ ìµœì í™”**:
- Qwen2-VL ë¡œë”© ì‹œê°„: ì•½ 15-20ì´ˆ (L4 GPU)
- ë¶„ì„ ì‹œê°„: ì•½ 5-10ì´ˆ
- ì´ ì¶”ê°€ ì‹œê°„: ì•½ 20-30ì´ˆ
- **ê¶Œì¥**: `use_qwen_analysis=true`ëŠ” ê³ í’ˆì§ˆì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©

**ì •í™•ë„ í–¥ìƒ**:
- Step1 ê²°ê³¼ ì´ë¯¸ì§€ í•´ìƒë„: ìµœì†Œ 800x1200px ê¶Œì¥
- Qwen í”„ë¡¬í”„íŠ¸ íŠœë‹: ì—…ì¢…ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
- ê²€ì¦ ë¡œì§: Qwen ì¶œë ¥ JSON ìœ íš¨ì„± ê²€ì‚¬ í•„ìˆ˜

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**:
- âœ… **ì¶”ì²œ**: ë³µì¡í•œ ë°°ê²½, ë¶ˆê·œì¹™í•œ ê°ì²´ ë°°ì¹˜
- âœ… **ì¶”ì²œ**: ìë™í™”ëœ ëŒ€ëŸ‰ ìƒì„± (ì¼ê´€ëœ í’ˆì§ˆ)
- âŒ **ë¹„ì¶”ì²œ**: ë‹¨ìˆœ ë°°ê²½, ìˆ˜ë™ ì¡°ì •ì´ ë” ë¹ ë¥¸ ê²½ìš°
- âŒ **ë¹„ì¶”ì²œ**: ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸° (ì§€ì—° ì‹œê°„ ê³ ë ¤)

#### 7.4.6. ê²€í†  ì‚¬í•­ (Review Points)

**ê¸°ìˆ ì  ê²€í† **:
1. **GPU ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - Qwen2-VL ëª¨ë¸ í¬ê¸°: ì•½ 8GB VRAM
   - FLUX.1 ì–¸ë¡œë“œ í›„ Qwen ë¡œë“œ í•„ìš”
   - ì´ íŒŒì´í”„ë¼ì¸ ì‹œê°„ ì¦ê°€: +30ì´ˆ

2. **ë¶„ì„ ì‹ ë¢°ì„±**
   - Qwen ì¶œë ¥ ì¼ê´€ì„±: í…ŒìŠ¤íŠ¸ í•„ìš”
   - ì˜ëª»ëœ ë¶„ì„ ì‹œ í´ë°± ì „ëµ í•„ìˆ˜
   - JSON íŒŒì‹± ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”

3. **LLM í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ**
   - Qwen ë¶„ì„ ê²°ê³¼ë¥¼ LLMì´ ì˜¬ë°”ë¥´ê²Œ í•´ì„í•˜ëŠ”ì§€ ê²€ì¦
   - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë°˜ë³µ ê°œì„  í•„ìš”
   - A/B í…ŒìŠ¤íŠ¸: Qwen ì‚¬ìš© vs ë¯¸ì‚¬ìš© ë¹„êµ

**ì‚¬ìš©ì ê²½í—˜ ê²€í† **:
1. **ì²˜ë¦¬ ì‹œê°„**
   - ê¸°ì¡´: 60-90ì´ˆ (Step2 LLM ì˜µì…˜)
   - Qwen ì¶”ê°€ ì‹œ: 90-120ì´ˆ
   - ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ ìˆ˜ìš© ê°€ëŠ¥ì„± í‰ê°€

2. **í’ˆì§ˆ ê°œì„  íš¨ê³¼**
   - í…ìŠ¤íŠ¸ ë°°ì¹˜ ì •í™•ë„ í–¥ìƒ ì •ë„ ì¸¡ì •
   - ìˆ˜ë™ ì¡°ì • í•„ìš”ì„± ê°ì†Œ ì •ë„ í™•ì¸
   - ì‚¬ìš©ì ë§Œì¡±ë„ ì¡°ì‚¬ í•„ìš”

3. **ì˜µì…˜ ì œê³µ ë°©ì‹**
   - ê¸°ë³¸ê°’: `use_qwen_analysis=false` (ë¹ ë¥¸ ìƒì„±)
   - ê³ ê¸‰ ì˜µì…˜: `use_qwen_analysis=true` (ê³ í’ˆì§ˆ ìë™ë°°ì¹˜)
   - UIì—ì„œ ì²´í¬ë°•ìŠ¤ë¡œ ì œê³µ ê¶Œì¥

**ë¹„ìš© íš¨ìœ¨ì„± ê²€í† **:
- GPU ê°€ë™ ì‹œê°„ ì¦ê°€: ì•½ 50% ì¦ê°€
- LLM API í˜¸ì¶œ ì¦ê°€: Qwen í”„ë¡¬í”„íŠ¸ + ê²°ê³¼ ì „ë‹¬ (í† í° ì¦ê°€)
- ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ ë¶„ì„ í•„ìš”

#### 7.4.7. í–¥í›„ ê°œì„  ë°©í–¥ (Future Improvements)

**ë‹¨ê¸° (1-2ì£¼)**:
- [ ] Qwen ë¶„ì„ ê²°ê³¼ ìºì‹± (ë™ì¼ ì´ë¯¸ì§€ ì¬ì‚¬ìš©)
- [ ] ë¶„ì„ ê²°ê³¼ ì‹œê°í™” (ë””ë²„ê¹…ìš© íˆíŠ¸ë§µ)
- [ ] ì—…ì¢…ë³„ Qwen í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

**ì¤‘ê¸° (1-2ê°œì›”)**:
- [ ] Qwen íŒŒì¸íŠœë‹ (ê´‘ê³  ì´ë¯¸ì§€ íŠ¹í™”)
- [ ] ë‹¤ì¤‘ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì§€ì› (í—¤ë“œë¼ì¸ + ì„œë¸Œí…ìŠ¤íŠ¸)
- [ ] ì‹¤ì‹œê°„ ë°°ì¹˜ ì¡°ì • API (ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜)

**ì¥ê¸° (3ê°œì›” ì´ìƒ)**:
- [ ] ê²½ëŸ‰í™” ëª¨ë¸ ì ìš© (Qwen2-VL 7B â†’ 4B)
- [ ] ì—£ì§€ ë””ë°”ì´ìŠ¤ ë°°í¬ (í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ë¶„ì„)
- [ ] ë©€í‹°ëª¨ë‹¬ LLM í†µí•© (GPT-4V ë“±)

---

## 8. ë³´ì•ˆ ë° ì•ˆì •ì„± (Security & Reliability)

### 8.1. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **API í‚¤ ê´€ë¦¬**
   - í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬ (`.env` íŒŒì¼)
   - Docker secrets í™œìš©
   - GitHubì— ì—…ë¡œë“œ ê¸ˆì§€

2. **ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬**
   - ëª¨ë¸ì„œë¹™ê³¼ ë°±ì—”ë“œëŠ” ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ì—ì„œë§Œ ì ‘ê·¼
   - í”„ë¡ íŠ¸ì—”ë“œë§Œ ì™¸ë¶€ ë…¸ì¶œ

3. **ì…ë ¥ ê²€ì¦**
   - ì´ë¯¸ì§€ í¬ê¸° ì œí•œ (ì˜ˆ: 10MB)
   - í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
   - íŒŒì¼ í˜•ì‹ ê²€ì¦

### 8.2. ì•ˆì •ì„± í™•ë³´

1. **ì—ëŸ¬ í•¸ë“¤ë§**
   - GPU OOM ë°œìƒ ì‹œ ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì¬ì‹œë„
   - ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜

2. **ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**
   - ë‹¨ì¼ ì‘ì—…ë§Œ ì²˜ë¦¬ (ë™ì‹œì„± ì œì–´)
   - ì‘ì—… í êµ¬í˜„ (í–¥í›„ í™•ì¥)

3. **ëª¨ë‹ˆí„°ë§**
   - ì‹¤ì‹œê°„ GPU/CPU/RAM ì‚¬ìš©ë¥  ì¶”ì 
   - ì‘ì—… ì‹œê°„ ë¡œê¹…

---

## 9. ê´‘ê³  í˜ì´ì§€ ìƒì„± ì‹œìŠ¤í…œ (Homepage Generator System)

### 9.1. ê°œìš”

ê´‘ê³  í˜ì´ì§€ ìƒì„± ì‹œìŠ¤í…œì€ ê³ ê° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™„ì „í•œ ê´‘ê³  í™ˆí˜ì´ì§€ë¥¼ ìë™ ìƒì„±í•˜ëŠ” LangGraph ê¸°ë°˜ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**ì£¼ìš” íŠ¹ì§•**:
- LangGraph ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ë‹¨ê³„ë³„ ìƒì„±
- OpenAI ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… (ë¸Œë ˆì¸ìŠ¤í† ë°, ì „ëµ, ë””ìì¸)
- MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•œ AI ì´ë¯¸ì§€ ìƒì„± í†µí•©
- Tailwind CSS ê¸°ë°˜ ë°˜ì‘í˜• ë””ìì¸
- Multi-Page Application (MPA) êµ¬ì¡°

### 9.2. ì‹œìŠ¤í…œ êµ¬ì¡°

```mermaid
graph TB
    subgraph "Backend (FastAPI)"
        UserInput["ê³ ê° ë°ì´í„° ì…ë ¥
(store_name, budget, goal)"]
        DB["PostgreSQL
ê³ ê° ì •ë³´ ì €ì¥"]
    end

    subgraph "Homepage Generator (LangGraph)"
        direction TB
        
        subgraph "Multi-Agent Brainstorm"
            Manager["ë§¤ë‹ˆì € ì—ì´ì „íŠ¸"]
            Marketer["ë§ˆì¼€í„° ì—ì´ì „íŠ¸"]
            Designer["ë””ìì´ë„ˆ ì—ì´ì „íŠ¸"]
            Manager --> Marketer
            Marketer --> Designer
            Designer --> Manager
        end
        
        subgraph "LangGraph Workflow"
            A["Node A: Concept Designer
ë§¤ì¥ ì»¨ì…‰ ì •ì˜"]
            B["Node B: Marketing Strategy
ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½"]
            C["Node C: Homepage Designer
í™ˆí˜ì´ì§€ êµ¬ì¡° ì„¤ê³„"]
            D["Node D: Content Designer
ì½˜í…ì¸  ìƒì„¸ ì„¤ê³„"]
            E["Node E: Generate Images
AI ì´ë¯¸ì§€ ìƒì„± (MCP)"]
            F["Node F: Header/Footer
ê³µí†µ ì»´í¬ë„ŒíŠ¸ ìƒì„±"]
            G["Node G: HTML Code
í˜ì´ì§€ë³„ HTML ìƒì„±"]
            H["Node H: Package Output
ìµœì¢… íŒ¨í‚¤ì§•"]
        end
    end

    subgraph "MCP Adapter"
        MCPClient["MCP Client
HTTP í†µì‹ "]
    end

    subgraph "AI Server (nanoCocoa)"
        ImageGen["ì´ë¯¸ì§€ ìƒì„± API
FLUX + Qwen + LLM"]
    end

    UserInput --> DB
    DB --> Manager
    Manager --> A
    A --> B --> C --> D --> E
    E --> F --> G --> H
    
    E -.->|call_tool
generate_ad_image| MCPClient
    MCPClient -->|HTTP POST| ImageGen
    ImageGen -.->|Base64 Image| MCPClient
    MCPClient -.->|Result| E

    H --> Output["ìƒì„±ëœ í™ˆí˜ì´ì§€
HTML/CSS + Images"]
```

### 9.3. ë°ì´í„° íë¦„ (Data Flow)

#### 9.3.1. ì „ì²´ í”„ë¡œì„¸ìŠ¤

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant Backend as Backend (FastAPI)
    participant DB as PostgreSQL
    participant HPGen as Homepage Generator
    participant Agents as Multi-Agent System
    participant LGraph as LangGraph Workflow
    participant MCP as MCP Client
    participant AIServer as nanoCocoa AI Server

    User->>Backend: 1. ê³ ê° ì •ë³´ ì…ë ¥ (store_name, budget, goal)
    Backend->>DB: 2. ê³ ê° ë°ì´í„° ì €ì¥
    DB-->>Backend: 3. customer_id ë°˜í™˜
    
    Backend->>HPGen: 4. POST /generate {customer_data}
    HPGen->>DB: 5. ê³ ê° ë°ì´í„° ì¡°íšŒ
    DB-->>HPGen: 6. StoreConfig ë°˜í™˜
    
    HPGen->>Agents: 7. ë¸Œë ˆì¸ìŠ¤í† ë° ì‹œì‘
    Agents->>Agents: 8. Manager â†” Marketer â†” Designer í˜‘ì—…
    Agents-->>HPGen: 9. ë¸Œë ˆì¸ìŠ¤í† ë° ê²°ê³¼
    
    HPGen->>LGraph: 10. Workflow ì‹¤í–‰
    
    LGraph->>LGraph: Node A: ë§¤ì¥ ì»¨ì…‰ ì •ì˜
    LGraph->>LGraph: Node B: ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½
    LGraph->>LGraph: Node C: í™ˆí˜ì´ì§€ êµ¬ì¡° ì„¤ê³„
    LGraph->>LGraph: Node D: ì½˜í…ì¸  ìƒì„¸ ì„¤ê³„
    
    LGraph->>MCP: Node E: ì´ë¯¸ì§€ ìƒì„± ìš”ì²­
    MCP->>AIServer: generate_ad_image(product_image, prompts)
    AIServer-->>MCP: Base64 ì´ë¯¸ì§€
    MCP-->>LGraph: ìƒì„±ëœ ì´ë¯¸ì§€
    
    LGraph->>LGraph: Node F: Header/Footer ìƒì„± (Tailwind)
    LGraph->>LGraph: Node G: í˜ì´ì§€ë³„ Main HTML ìƒì„±
    LGraph->>LGraph: Node H: ìµœì¢… íŒ¨í‚¤ì§•
    
    LGraph-->>HPGen: ìµœì¢… State (HTML + CSS + Images)
    HPGen->>HPGen: íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥
    HPGen-->>Backend: output_path ë°˜í™˜
    Backend-->>User: ìƒì„± ì™„ë£Œ (í™ˆí˜ì´ì§€ ë§í¬)
```

#### 9.3.2. LangGraph Workflow ìƒì„¸

**Node êµ¬ì„±**:

1. **Concept Designer**: ë§¤ì¥ ì»¨ì…‰ ë° ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° ì •ì˜
   - ì…ë ¥: StoreConfig (store_name, store_type, advertising_goal)
   - ì¶œë ¥: StoreConcept (concept, brand_identity, values)

2. **Marketing Strategy**: ë§ˆì¼€íŒ… ì „ëµ ë° íƒ€ê²Ÿ ê³ ê° ë¶„ì„
   - ì…ë ¥: StoreConcept
   - ì¶œë ¥: MarketingStrategy (target_audience, messaging, channels)

3. **Homepage Designer**: í™ˆí˜ì´ì§€ ì „ì²´ êµ¬ì¡° ì„¤ê³„
   - ì…ë ¥: StoreConcept, MarketingStrategy
   - ì¶œë ¥: HomePageDesign (pages, navigation, layout)

4. **Content Designer**: í˜ì´ì§€ë³„ ì½˜í…ì¸  ìƒì„¸ ì„¤ê³„
   - ì…ë ¥: HomePageDesign
   - ì¶œë ¥: ContentDesign (sections, copy, cta)

5. **Generate Images**: MCPë¥¼ í†µí•œ AI ì´ë¯¸ì§€ ìƒì„±
   - ì…ë ¥: ContentDesign (ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸)
   - ì¶œë ¥: generated_images (Base64)
   - MCP Clientë¥¼ í†µí•´ nanoCocoa AI Server í˜¸ì¶œ

6. **Header/Footer**: ê³µí†µ ì»´í¬ë„ŒíŠ¸ ìƒì„±
   - ì…ë ¥: HomePageDesign, generated_images
   - ì¶œë ¥: header_html, footer_html (Tailwind CSS)

7. **HTML Code**: í˜ì´ì§€ë³„ Main ì½˜í…ì¸  ìƒì„±
   - ì…ë ¥: ContentDesign, generated_images
   - ì¶œë ¥: html_codes (MPA: index.html, about.html, contact.html)

8. **Package Output**: ìµœì¢… íŒŒì¼ êµ¬ì¡° ìƒì„±
   - ì…ë ¥: header_html, footer_html, html_codes, generated_images
   - ì¶œë ¥: ì™„ì „í•œ í™ˆí˜ì´ì§€ (HTML + CSS + Images)

### 9.4. ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… (Multi-Agent Collaboration)

**ë¸Œë ˆì¸ìŠ¤í† ë° ë‹¨ê³„**ì—ì„œëŠ” 3ê°œì˜ OpenAI ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•©ë‹ˆë‹¤:

**ì—ì´ì „íŠ¸ êµ¬ì„±**:
- **Manager Agent**: íšŒì˜ ì§„í–‰ ë° ì˜ì‚¬ê²°ì • ì¡°ìœ¨
- **Marketer Agent**: ë§ˆì¼€íŒ… ì „ëµ ë° ê³ ê° ë¶„ì„
- **Designer Agent**: ë””ìì¸ ë°©í–¥ ë° UX ì œì•ˆ

**í˜‘ì—… í”„ë¡œì„¸ìŠ¤**:
1. Managerê°€ ê³ ê° ì •ë³´ë¥¼ ê³µìœ í•˜ê³  íšŒì˜ ì‹œì‘
2. Marketerê°€ íƒ€ê²Ÿ ê³ ê° ë° ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ
3. Designerê°€ ë””ìì¸ ì»¨ì…‰ ë° ë ˆì´ì•„ì›ƒ ì œì•ˆ
4. Managerê°€ ì˜ê²¬ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë°©í–¥ ê²°ì •
5. ë¸Œë ˆì¸ìŠ¤í† ë° ê²°ê³¼ë¥¼ LangGraph Stateì— ì €ì¥

### 9.5. MCP í†µí•© (MCP Integration)

**mcpadapter ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¥¼ í†µí•´ AI ì´ë¯¸ì§€ ìƒì„± ì„œë²„ì™€ í†µí•©:

**ì½”ë“œ ì˜ˆì‹œ**:
```python
from mcpadapter import MCPClient

async with MCPClient("http://nanococoa-mcpserver:3000") as client:
    result = await client.call_tool(
        "generate_ad_image",
        {
            "product_image_path": product_image_path,
            "background_prompt": bg_prompt,
            "text_content": text_content,
            "text_prompt": text_style_prompt,
            "use_qwen_analysis": True,
        }
    )
    
    # ê²°ê³¼ì—ì„œ final_result (Base64) ì¶”ì¶œ
    final_image_base64 = result.get("final_result")
```

**íŠ¹ì§•**:
- ë¹„ë™ê¸° HTTP í†µì‹  (httpx)
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ (max_retries=3)
- íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ (ê¸°ë³¸ 900ì´ˆ)
- ì—ëŸ¬ í•¸ë“¤ë§

### 9.6. ìƒì„±ëœ í™ˆí˜ì´ì§€ êµ¬ì¡°

```
generated_sites/{store_name}_{timestamp}/
â”œâ”€â”€ index.html              # ë©”ì¸ í˜ì´ì§€
â”œâ”€â”€ about.html              # ì†Œê°œ í˜ì´ì§€
â”œâ”€â”€ services.html           # ì„œë¹„ìŠ¤ í˜ì´ì§€
â”œâ”€â”€ contact.html            # ì—°ë½ í˜ì´ì§€
â”œâ”€â”€ css/
â”‚   â””â”€â”€ style.css          # (ì˜µì…˜, Tailwind CDN ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”)
â””â”€â”€ images/
    â”œâ”€â”€ hero.png           # íˆì–´ë¡œ ì´ë¯¸ì§€ (Base64 â†’ PNG ì €ì¥)
    â”œâ”€â”€ product_1.png      # ì œí’ˆ ì´ë¯¸ì§€
    â””â”€â”€ cta.png            # CTA ì´ë¯¸ì§€
```

**ê¸°ìˆ  ìŠ¤íƒ**:
- **HTML5**: ì‹œë§¨í‹± ë§ˆí¬ì—…
- **Tailwind CSS**: CDN ë°©ì‹ (ë¹Œë“œ ë¶ˆí•„ìš”)
- **ë°˜ì‘í˜• ë””ìì¸**: ëª¨ë°”ì¼/íƒœë¸”ë¦¿/ë°ìŠ¤í¬í†± ì§€ì›
- **ì ‘ê·¼ì„±**: ARIA ë ˆì´ë¸”, í‚¤ë³´ë“œ ë„¤ë¹„ê²Œì´ì…˜

### 9.7. API ì—”ë“œí¬ì¸íŠ¸

#### 9.7.1. Homepage Generator API (Port 8080)

| ë©”ì„œë“œ | ê²½ë¡œ | ì„¤ëª… | ìš”ì²­ | ì‘ë‹µ |
|--------|------|------|------|------|
| GET | `/` | í—¬ìŠ¤ì²´í¬ | - | `{status, service, version}` |
| POST | `/generate` | í™ˆí˜ì´ì§€ ìƒì„± | `CustomerData` | `{output_path, status}` |

**ìš”ì²­ ì˜ˆì‹œ**:
```json
{
  "store_name": "ê¹€ë°¥ì²œêµ­ ê°•ë‚¨ì ",
  "store_type": "ìŒì‹ì  (ë¶„ì‹)",
  "budget": 500,
  "period": 30,
  "advertising_goal": "ì‹ ê·œ ê³ ê° ìœ ì¹˜",
  "target_customer": "20-30ëŒ€ ì§ì¥ì¸",
  "advertising_media": "ë„¤ì´ë²„ ë¸”ë¡œê·¸, ì¸ìŠ¤íƒ€ê·¸ë¨",
  "store_strength": "24ì‹œê°„ ì˜ì—…, ë¹ ë¥¸ ì¡°ë¦¬",
  "location": "ì„œìš¸ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ",
  "phone_number": "02-1234-5678"
}
```

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "status": "success",
  "output_path": "/generated_sites/ê¹€ë°¥ì²œêµ­_ê°•ë‚¨ì _20260123_143052",
  "pages": ["index.html", "about.html", "services.html", "contact.html"],
  "generated_images": 3
}
```

### 9.8. ë°°í¬ êµ¬ì„± (Deployment)

**Docker Compose êµ¬ì„±**:
```yaml
services:
  backend:
    build: ./backend
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - homepage-generator

  homepage-generator:
    build: ./homepage_generator
    ports:
      - "8081:8081"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MCP_SERVER_URL=http://nanococoa-mcpserver:3000
    depends_on:
      - nanococoa-mcpserver

  postgres:
    image: postgres:15
    ports:
      - "5432:5432"
    volumes:
      - ./backend/postgres_data:/var/lib/postgresql/data
```

### 9.9. ì„±ëŠ¥ ìµœì í™”

**ë¹„ë™ê¸° ì²˜ë¦¬**:
- FastAPI ë¹„ë™ê¸° ì—”ë“œí¬ì¸íŠ¸
- httpx AsyncClient (MCP í†µì‹ )
- LangGraph ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰

**ìºì‹± ì „ëµ**:
- ë¸Œë ˆì¸ìŠ¤í† ë° ê²°ê³¼ ìºì‹± (ë™ì¼ ê³ ê° ì •ë³´)
- ìƒì„±ëœ ì´ë¯¸ì§€ ì¬ì‚¬ìš© (ìœ ì‚¬ í”„ë¡¬í”„íŠ¸)

**ì—ëŸ¬ ë³µêµ¬**:
- MCP ì—°ê²° ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)
- LangGraph State ì €ì¥ (ì¤‘ë‹¨ ì§€ì  ë³µêµ¬)
- ë¶€ë¶„ ìƒì„± ê²°ê³¼ ì €ì¥ (ë‹¨ê³„ë³„ ì²´í¬í¬ì¸íŠ¸)

---

## 10. í–¥í›„ í™•ì¥ ê³„íš (Future Enhancements)

### 10.1. ë‹¨ê¸° ê³„íš (1~2ì£¼)

- [ ] ì‘ì—… í ì‹œìŠ¤í…œ êµ¬í˜„ (ë‹¤ì¤‘ ì‚¬ìš©ì ì§€ì›)
- [ ] Redis ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬ (ì¸ë©”ëª¨ë¦¬ â†’ ì˜êµ¬ ì €ì¥)
- [ ] ì‚¬ìš©ì ì¸ì¦ ë° ì„¸ì…˜ ê´€ë¦¬
- [ ] í™ˆí˜ì´ì§€ í…œí”Œë¦¿ ë‹¤ì–‘í™” (ì—…ì¢…ë³„ í…œí”Œë¦¿)

### 10.2. ì¤‘ê¸° ê³„íš (1~2ê°œì›”)

- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ (ì‘ì—… ì´ë ¥ ì €ì¥)
- [ ] ì‚¬ìš©ì ê°¤ëŸ¬ë¦¬ ê¸°ëŠ¥
- [ ] A/B í…ŒìŠ¤íŠ¸ ì§€ì› (ì—¬ëŸ¬ ë²„ì „ ìƒì„± ë° ë¹„êµ)
- [ ] ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥
- [ ] SEO ìµœì í™” ìë™ ì ìš©

---

## 11. ì°¸ê³  ë¬¸ì„œ (References)

- [ê³ ê¸‰_í”„ë¡œì íŠ¸_ìˆ˜í–‰_ê³„íš_ë°_í™˜ê²½_ê²€í† _ë³´ê³ ì„œ.md](./ê³ ê¸‰_í”„ë¡œì íŠ¸_ìˆ˜í–‰_ê³„íš_ë°_í™˜ê²½_ê²€í† _ë³´ê³ ì„œ.md)
- [nanoCocoa_AI_Server_ì•„í‚¤í…ì²˜ì„¤ê³„.md](./nanoCocoa_AI_Server_ì•„í‚¤í…ì²˜ì„¤ê³„.md)

---

**ë¬¸ì„œ ë³€ê²½ ì´ë ¥**

| ë²„ì „ | ë‚ ì§œ | ì‘ì„±ì | ë³€ê²½ ë‚´ìš© |
|------|------|--------|-----------|
| v1.0 | 2026.01.01 | ê¹€ëª…í™˜ | ì´ˆì•ˆ ì‘ì„± |
| v1.1 | 2026.01.23 | ê¹€ëª…í™˜ | Qwen ì´ë¯¸ì§€ ë¶„ì„, ê´‘ê³  í˜ì´ì§€ ìƒì„± ì‹œìŠ¤í…œ ì¶”ê°€ |
| v1.2 | 2026.01.23 | ê¹€ëª…í™˜ | step2+step3 Qwen ìë™ë°°ì¹˜ ê¶Œì¥ì‚¬í•­ ë° ê²€í† ì‚¬í•­ ì¶”ê°€ |

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1abf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import io\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import random\n",
    "import spaces\n",
    "import torch\n",
    "from diffusers import Flux2Pipeline, Flux2Transformer2DModel\n",
    "from diffusers import BitsAndBytesConfig as DiffBitsAndBytesConfig\n",
    "import requests\n",
    "from PIL import Image\n",
    "import json\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, InferenceClient\n",
    "from helper_dev_utils import get_auto_logger\n",
    "logger = get_auto_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d230d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face 로그인 (FLUX 모델 접근 권한 필요)\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 토큰 가져오기 또는 직접 입력\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "logger.info(f\"Hugging Face Token: {hf_token[:2]} ... {hf_token[-2:]}\")\n",
    "\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"✓ Logged in with HF_TOKEN from environment\")\n",
    "else:\n",
    "    # 수동 로그인 (토큰 입력 필요)\n",
    "    login()\n",
    "    print(\"✓ Manual login completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# [수정 1] AutoPipelineForImage2Image 추가 import\n",
    "from diffusers import DiffusionPipeline, AutoPipelineForImage2Image \n",
    "from diffusers.utils import logging as diffusers_logging\n",
    "\n",
    "# 불필요한 경고 숨기기 (선택사항)\n",
    "diffusers_logging.set_verbosity_error()\n",
    "\n",
    "# 프로젝트 경로 설정 (기존 유지)\n",
    "project_root = Path.cwd().parent.parent / \"src\" / \"nanoCocoa_aiserver\"\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "try:\n",
    "    from config import TORCH_DTYPE\n",
    "    from services.monitor import flush_gpu\n",
    "    from helper_dev_utils import get_auto_logger\n",
    "except ImportError:\n",
    "    TORCH_DTYPE = torch.bfloat16\n",
    "    def flush_gpu(): pass\n",
    "    def get_auto_logger():\n",
    "        import logging\n",
    "        return logging.getLogger(\"FluxGenerator\")\n",
    "\n",
    "logger = get_auto_logger()\n",
    "\n",
    "class FluxGenerator:\n",
    "    def __init__(self):\n",
    "        self.model_id = \"diffusers/FLUX.2-dev-bnb-4bit\"\n",
    "        self.pipe_txt2img = None\n",
    "        self.pipe_img2img = None\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        logger.info(f\"FluxGenerator initialized using: {self.model_id}\")\n",
    "\n",
    "    def _flush_gpu(self):\n",
    "        flush_gpu()\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    def _load_pipelines(self):\n",
    "        if self.pipe_txt2img is not None:\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Loading FLUX.2 Pipeline...\")\n",
    "        self._flush_gpu()\n",
    "        \n",
    "        try:\n",
    "            # 1. Txt2Img 파이프라인 로드\n",
    "            from transformers import BitsAndBytesConfig\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "            )\n",
    "            max_memory = {0: \"20GB\", \"cpu\": \"80GB\"}\n",
    "\n",
    "            self.pipe_txt2img = DiffusionPipeline.from_pretrained(\n",
    "                self.model_id,\n",
    "                torch_dtype=TORCH_DTYPE,\n",
    "                device_map=\"balanced\",\n",
    "                max_memory=max_memory,\n",
    "                quantization_config=quantization_config\n",
    "            )\n",
    "\n",
    "            # CPU Offload (VRAM 절약)\n",
    "            if not hasattr(self.pipe_txt2img, \"hf_device_map\"):\n",
    "                 self.pipe_txt2img.enable_model_cpu_offload()\n",
    "\n",
    "            # VAE Tiling (OOM 방지)\n",
    "            if hasattr(self.pipe_txt2img, \"vae\"):\n",
    "                self.pipe_txt2img.vae.enable_tiling()\n",
    "                self.pipe_txt2img.vae.enable_slicing()\n",
    "\n",
    "            # [핵심 수정] AutoPipeline을 사용하여 Img2Img 파이프라인 자동 변환\n",
    "            # Flux 1인지 2인지 상관없이 적절한 클래스로 매핑해줍니다.\n",
    "            try:\n",
    "                self.pipe_img2img = AutoPipelineForImage2Image.from_pipe(self.pipe_txt2img)\n",
    "                logger.info(\"Img2Img Pipeline created via AutoPipeline.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to create Img2Img pipe: {e}\")\n",
    "                # 정말 실패했을 경우엔 img2img를 None으로 두어 폴백 처리\n",
    "                self.pipe_img2img = None\n",
    "\n",
    "            logger.info(\"FLUX.2 Pipelines loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load pipeline: {e}\")\n",
    "            self._flush_gpu()\n",
    "            raise e\n",
    "\n",
    "    def generate_background_and_compose_image(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        input_image: Optional[Image.Image] = None,\n",
    "        width: int = 1024,\n",
    "        height: int = 1024,\n",
    "        num_inference_steps: int = 30,\n",
    "        guidance_scale: float = 3.5,\n",
    "        strength: float = 0.75,\n",
    "        seed: int = None,\n",
    "        **kwargs\n",
    "    ) -> Image.Image:\n",
    "        \n",
    "        self._load_pipelines()\n",
    "        self._flush_gpu()\n",
    "        \n",
    "        generator = torch.Generator(device=\"cpu\").manual_seed(seed) if seed else None\n",
    "\n",
    "        common_args = {\n",
    "            \"prompt\": prompt,\n",
    "            \"num_inference_steps\": num_inference_steps,\n",
    "            \"guidance_scale\": guidance_scale,\n",
    "            \"generator\": generator,\n",
    "            \"max_sequence_length\": 512,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                if input_image is None:\n",
    "                    # [Txt2Img]\n",
    "                    logger.info(\"Generating [Txt2Img]...\")\n",
    "                    result = self.pipe_txt2img(**common_args)\n",
    "                else:\n",
    "                    # [Img2Img]\n",
    "                    logger.info(\"Generating [Img2Img]...\")\n",
    "                    \n",
    "                    # 1. Img2Img 파이프라인이 정상적으로 로드되었는지 확인\n",
    "                    if self.pipe_img2img is None:\n",
    "                        raise RuntimeError(\"Img2Img pipeline failed to load. Cannot perform image-to-image generation.\")\n",
    "\n",
    "                    # 2. 이미지 전처리\n",
    "                    if input_image.size != (width, height):\n",
    "                        input_image = input_image.resize((width, height), Image.LANCZOS)\n",
    "                    \n",
    "                    common_args[\"image\"] = input_image\n",
    "                    common_args[\"strength\"] = strength\n",
    "                    \n",
    "                    result = self.pipe_img2img(**common_args)\n",
    "            \n",
    "            return result.images[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during generation: {e}\")\n",
    "            raise e\n",
    "        finally:\n",
    "            self._flush_gpu()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 실행 테스트\n",
    "# -------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if 'flux_generator' in globals():\n",
    "        del flux_generator\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    flux_generator = FluxGenerator()\n",
    "    \n",
    "    # 이미지 생성 테스트\n",
    "    ad_prompt = \"High-quality product photography, rustic wooden table, soft sunlight, bokeh background, 8k\"\n",
    "    \n",
    "    # 예시 이미지가 없다면 새로 생성 (테스트용)\n",
    "    if not Path(\"image01.png\").exists():\n",
    "        Image.new('RGB', (1024, 1024), color='white').save(\"image01.png\")\n",
    "    \n",
    "    image01 = Image.open(\"image01.png\")\n",
    "    \n",
    "    try:\n",
    "        ad_image = flux_generator.generate_background_and_compose_image(\n",
    "            prompt=ad_prompt,\n",
    "            input_image=image01,\n",
    "            width=1024,\n",
    "            height=1024,\n",
    "            strength=0.75\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(ad_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Execution Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea71dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106ad55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdba4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 정리\n",
    "flux_generator.unload()\n",
    "logger.info(\"All resources cleaned up\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_adv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

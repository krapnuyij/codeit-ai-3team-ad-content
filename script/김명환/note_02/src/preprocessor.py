"""
ê°ì²´ ë§¤íŒ… ëª¨ë“ˆ: BiRefNetì„ ì‚¬ìš©í•œ ë°°ê²½ ì œê±°
Object Matting Module: Background Removal using BiRefNet
"""

import torch
from PIL import Image
from transformers import AutoModelForImageSegmentation
from torchvision import transforms
from typing import Union
from pathlib import Path
import logging

# Try to import helper_dev_utils, fallback to standard logging if not available
try:
    from helper_dev_utils import get_auto_logger

    logger = get_auto_logger()
except ImportError:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

from .utils import flush_gpu, load_image


class ObjectMatting:
    """
    BiRefNetì„ ì‚¬ìš©í•˜ì—¬ ì œí’ˆ ì´ë¯¸ì§€ì—ì„œ ë°°ê²½ì„ ì œê±°í•˜ëŠ” í´ë˜ìŠ¤

    ì´ í´ë˜ìŠ¤ëŠ” ê¹¨ë—í•œ RGBA ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ë°°ê²½ì„ ì œê±°í•©ë‹ˆë‹¤.
    ì´ëŠ” í•©ì„± ë‹¨ê³„ì—ì„œ IP-Adapter ì˜¤ì—¼ì„ ë°©ì§€í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.

    Attributes:
        model_name (str): ì‚¬ìš©í•  HuggingFace ëª¨ë¸ ì´ë¦„
        device (str): ëª¨ë¸ì„ ì‹¤í–‰í•  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu')
        model: BiRefNet ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (í•„ìš”í•  ë•Œë§Œ ë¡œë“œ)
        transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜ íŒŒì´í”„ë¼ì¸
    """

    def __init__(self, model_name: str = "ZhengPeng7/BiRefNet", device: str = None):
        """
        ObjectMatting ëª¨ë¸ ì´ˆê¸°í™”

        Args:
            model_name: HuggingFace ëª¨ë¸ ì‹ë³„ì (ê¸°ë³¸ê°’: BiRefNet)
            device: ëª¨ë¸ ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', ê¸°ë³¸ê°’: ìë™ ê°ì§€)
        """
        self.model_name = model_name
        # CUDA ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU, ì•„ë‹ˆë©´ CPU ì‚¬ìš©
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.transform = None

        print(f"ğŸ”§ ObjectMatting ì´ˆê¸°í™”: {model_name}")

    def _load_model(self):
        """BiRefNet ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ì— ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.model is None:
            print(f"  BiRefNet ëª¨ë¸ì„ {self.device}ì— ë¡œë“œ ì¤‘...")
            # HuggingFaceì—ì„œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
            self.model = AutoModelForImageSegmentation.from_pretrained(
                self.model_name, trust_remote_code=True  # ì»¤ìŠ¤í…€ ì½”ë“œ ì‹¤í–‰ í—ˆìš©
            )
            self.model.to(self.device)  # GPU ë˜ëŠ” CPUë¡œ ì´ë™
            self.model.eval()  # í‰ê°€ ëª¨ë“œ (í•™ìŠµ ì•ˆ í•¨)

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì •ì˜
            # 1024x1024ë¡œ ë¦¬ì‚¬ì´ì¦ˆ -> í…ì„œ ë³€í™˜ -> ImageNet ì •ê·œí™”
            self.transform = transforms.Compose(
                [
                    transforms.Resize((1024, 1024)),  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •
                    transforms.ToTensor(),  # PIL -> Tensor ë³€í™˜
                    transforms.Normalize(
                        [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]
                    ),  # ImageNet ì •ê·œí™”
                ]
            )

            print(f"  âœ“ BiRefNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    def _unload_model(self):
        """GPU VRAMì„ í™•ë³´í•˜ê¸° ìœ„í•´ ëª¨ë¸ì„ ì–¸ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.model is not None:
            print("  BiRefNet ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...")
            self.model.to("cpu")  # GPUì—ì„œ CPUë¡œ ì´ë™
            del self.model  # ëª¨ë¸ ì‚­ì œ
            self.model = None
            self.transform = None
            flush_gpu()  # GPU ìºì‹œ ì •ë¦¬

    def remove_background(
        self, image_path: Union[str, Path], return_rgba: bool = True
    ) -> Image.Image:
        """
        ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë°°ê²½ì„ ì œê±°í•©ë‹ˆë‹¤.

        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            return_rgba: Trueì´ë©´ RGBA ì´ë¯¸ì§€ ë°˜í™˜, Falseì´ë©´ ê²€ì€ ë°°ê²½ì˜ RGB ë°˜í™˜

        Returns:
            ë°°ê²½ì´ ì œê±°ëœ PIL ì´ë¯¸ì§€ (RGBA ë˜ëŠ” RGB)

        Example:
            >>> matting = ObjectMatting()
            >>> clean_image = matting.remove_background("product.png")
            >>> clean_image.save("product_no_bg.png")
        """
        try:
            # ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
            self._load_model()

            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
            original_image = load_image(image_path)
            original_size = original_image.size

            # ì²˜ë¦¬ë¥¼ ìœ„í•´ RGBë¡œ ë³€í™˜
            if original_image.mode != "RGB":
                product_image = original_image.convert("RGB")
            else:
                product_image = original_image

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (1024x1024ë¡œ ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”)
            input_tensor = self.transform(product_image).unsqueeze(0).to(self.device)

            # ì¶”ë¡  ì‹¤í–‰ (ë°°ê²½ ë§ˆìŠ¤í¬ ìƒì„±)
            print("  ë°°ê²½ ì œê±° ì‹¤í–‰ ì¤‘...")
            with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
                predictions = self.model(input_tensor)[-1]  # ëª¨ë¸ ì¶œë ¥
                pred_mask = (
                    predictions.sigmoid().cpu()
                )  # ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™” í›„ CPUë¡œ ì´ë™

            # ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
            pred_mask = pred_mask.squeeze().numpy()  # Tensor -> NumPy ë°°ì—´
            mask_image = Image.fromarray(
                (pred_mask * 255).astype("uint8")
            )  # 0-255 ë²”ìœ„ë¡œ ë³€í™˜
            mask_image = mask_image.resize(
                original_size, Image.LANCZOS
            )  # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›

            # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
            if return_rgba:
                # RGBA ì´ë¯¸ì§€ ìƒì„± (íˆ¬ëª… ë°°ê²½)
                result = product_image.convert("RGBA")
                result.putalpha(mask_image)  # ì•ŒíŒŒ ì±„ë„ë¡œ ë§ˆìŠ¤í¬ ì ìš©
                print("  âœ“ ë°°ê²½ ì œê±° ì™„ë£Œ (RGBA)")
            else:
                # ê²€ì€ ë°°ê²½ì˜ RGB ì´ë¯¸ì§€ ìƒì„±
                result = Image.new("RGB", original_size, (0, 0, 0))
                result.paste(product_image, mask=mask_image)
                print("  âœ“ ë°°ê²½ ì œê±° ì™„ë£Œ (RGB)")

            return result

        finally:
            # VRAM í™•ë³´ë¥¼ ìœ„í•´ í•­ìƒ ëª¨ë¸ ì–¸ë¡œë“œ
            self._unload_model()

    def __del__(self):
        """ê°ì²´ ì†Œë©¸ ì‹œ ì •ë¦¬ ì‘ì—…"""
        self._unload_model()

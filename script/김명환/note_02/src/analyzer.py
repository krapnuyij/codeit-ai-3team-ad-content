"""
ê³µê°„ ë¶„ì„ ëª¨ë“ˆ: Qwen2-VLì„ ì‚¬ìš©í•œ ìµœì ì˜ ê°ì²´ ë°°ì¹˜ ìœ„ì¹˜ íƒì§€
Spatial Analysis Module: Detect optimal object placement using Qwen2-VL
"""

import torch
from PIL import Image, ImageDraw
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
from typing import Union, Dict, List, Tuple
import re
import logging

# Try to import helper_dev_utils, fallback to standard logging if not available
try:
    from helper_dev_utils import get_auto_logger
    logger = get_auto_logger()
except ImportError:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

from .utils import flush_gpu


class SpatialAnalyzer:
    """
    Qwen2-VLì„ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ ì´ë¯¸ì§€ì—ì„œ ìµœì ì˜ ê°ì²´ ë°°ì¹˜ ìœ„ì¹˜ë¥¼ ì°¾ëŠ” í´ë˜ìŠ¤

    ì´ í´ë˜ìŠ¤ëŠ” Vision-Language ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í‘œë©´ì„ ê°ì§€í•˜ê³ ,
    ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê²°ì •í•˜ë©°, ê°ì²´ í•©ì„±ì„ ìœ„í•œ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Attributes:
        model_name (str): ì‚¬ìš©í•  HuggingFace ëª¨ë¸ ì´ë¦„
        device (str): ëª¨ë¸ì„ ì‹¤í–‰í•  ë””ë°”ì´ìŠ¤
        model: Qwen2-VL ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        processor: ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í”„ë¡œì„¸ì„œ
    """

    def __init__(
        self, model_name: str = "Qwen/Qwen2-VL-7B-Instruct", device: str = None
    ):
        """
        SpatialAnalyzer ì´ˆê¸°í™”

        Args:
            model_name: HuggingFace ëª¨ë¸ ì‹ë³„ì (ê¸°ë³¸ê°’: Qwen2-VL-7B-Instruct)
            device: ëª¨ë¸ ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', ê¸°ë³¸ê°’: ìë™ ê°ì§€)
        """
        self.model_name = model_name
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.processor = None

        print(f"ğŸ”§ SpatialAnalyzer ì´ˆê¸°í™”: {model_name}")

    def _load_model(self):
        """Qwen2-VL ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.model is None:
            print(f"  Qwen2-VL ëª¨ë¸ì„ {self.device}ì— ë¡œë“œ ì¤‘...")

            # Vision-Language ëª¨ë¸ ë¡œë“œ
            self.model = Qwen2VLForConditionalGeneration.from_pretrained(
                self.model_name,
                torch_dtype=torch.bfloat16,  # ë©”ëª¨ë¦¬ ì ˆì•½
                device_map="auto",  # ìë™ ë””ë°”ì´ìŠ¤ ë°°ì¹˜
            )

            # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í”„ë¡œì„¸ì„œ ë¡œë“œ
            self.processor = AutoProcessor.from_pretrained(self.model_name)

            print(f"  âœ“ Qwen2-VL ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    def _unload_model(self):
        """VRAM í™•ë³´ë¥¼ ìœ„í•´ ëª¨ë¸ì„ ì–¸ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.model is not None:
            print("  Qwen2-VL ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...")
            self.model.to("cpu")  # GPUì—ì„œ CPUë¡œ ì´ë™
            del self.model
            del self.processor
            self.model = None
            self.processor = None
            flush_gpu()  # GPU ìºì‹œ ì •ë¦¬

    def detect_surface(
        self,
        image: Union[Image.Image, str],
        query: str = "Find the flat surface where I can place an object. Return the bounding box coordinates.",
    ) -> Dict[str, any]:
        """
        ê°ì²´ ë°°ì¹˜ë¥¼ ìœ„í•œ ìµœì ì˜ í‘œë©´ì„ íƒì§€í•©ë‹ˆë‹¤.

        Vision-Language ëª¨ë¸ì— ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ì œê³µí•˜ì—¬
        ê°ì²´ë¥¼ ë†“ì„ ìˆ˜ ìˆëŠ” ìµœì ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

        Args:
            image: PIL Image ê°ì²´ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ
            query: VL ëª¨ë¸ì— ë¬¼ì–´ë³¼ ì§ˆë¬¸ (ìœ„ì¹˜ íƒì§€ ìš”ì²­)

        Returns:
            ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬:
                - 'bbox': [x1, y1, x2, y2] ì •ê·œí™”ëœ ì¢Œí‘œ (0-1000 ë²”ìœ„)
                - 'text': ëª¨ë¸ì˜ ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸
                - 'image_size': ì…ë ¥ ì´ë¯¸ì§€ì˜ (width, height)

        Example:
            >>> analyzer = SpatialAnalyzer()
            >>> result = analyzer.detect_surface(
            ...     bg_image,
            ...     "ë§¥ì£¼ë³‘ì„ ë†“ì„ í…Œì´ë¸” ì¤‘ì•™ì„ ì°¾ì•„ì£¼ì„¸ìš”"
            ... )
            >>> bbox = result['bbox']  # [x1, y1, x2, y2]
        """
        try:
            # ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
            self._load_model()

            # ê²½ë¡œê°€ ì œê³µëœ ê²½ìš° ì´ë¯¸ì§€ ë¡œë“œ
            if isinstance(image, str):
                from .utils import load_image

                image = load_image(image)

            image_size = image.size  # (width, height)

            print(f"  ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ({image_size[0]}x{image_size[1]})...")
            print(f"  ì§ˆë¬¸: {query}")

            # ëª¨ë¸ì„ ìœ„í•œ ë©”ì‹œì§€ ì¤€ë¹„ (ë©€í‹°ëª¨ë‹¬ ì…ë ¥)
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "image": image,  # ì´ë¯¸ì§€ ì…ë ¥
                        },
                        {"type": "text", "text": query},  # í…ìŠ¤íŠ¸ ì§ˆë¬¸
                    ],
                }
            ]

            # ì…ë ¥ ì „ì²˜ë¦¬
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            image_inputs, video_inputs = process_vision_info(messages)

            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            inputs = inputs.to(self.device)

            # ì‘ë‹µ ìƒì„± (ì¶”ë¡ )
            with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
                generated_ids = self.model.generate(
                    **inputs, max_new_tokens=256  # ìµœëŒ€ ì‘ë‹µ ê¸¸ì´
                )

            # ì…ë ¥ í† í° ì œê±° (ìƒì„±ëœ ë¶€ë¶„ë§Œ ì¶”ì¶œ)
            generated_ids_trimmed = [
                out_ids[len(in_ids) :]
                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]

            # ì‘ë‹µ ë””ì½”ë”© (í† í° -> í…ìŠ¤íŠ¸)
            output_text = self.processor.batch_decode(
                generated_ids_trimmed,
                skip_special_tokens=True,
                clean_up_tokenization_spaces=False,
            )[0]

            print(f"  ëª¨ë¸ ì‘ë‹µ: {output_text[:100]}...")

            # ì‘ë‹µì—ì„œ ë°”ìš´ë”© ë°•ìŠ¤ íŒŒì‹±
            bbox = self._parse_bbox(output_text)

            result = {"bbox": bbox, "text": output_text, "image_size": image_size}

            print(f"  âœ“ í‘œë©´ íƒì§€ ì™„ë£Œ: {bbox}")

            return result

        finally:
            # VRAM í™•ë³´ë¥¼ ìœ„í•´ í•­ìƒ ëª¨ë¸ ì–¸ë¡œë“œ
            self._unload_model()

    def _parse_bbox(self, text: str) -> List[int]:
        """
        ëª¨ë¸ ì¶œë ¥ì—ì„œ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.

        Qwen-VLì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ bboxë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:
        - í˜•ì‹ 1: <|box_start|>(x1,y1),(x2,y2)<|box_end|>
        - í˜•ì‹ 2: í…ìŠ¤íŠ¸ ë‚´ì˜ ìˆ«ì ë‚˜ì—´

        Returns:
            ì •ê·œí™”ëœ ì¢Œí‘œì˜ [x1, y1, x2, y2] (0-1000 ë²”ìœ„)
        """
        # íŒ¨í„´ 1: <|box_start|>(x1,y1),(x2,y2)<|box_end|> í˜•íƒœ ì°¾ê¸°
        box_pattern = r"<\|box_start\|\>\((\d+),(\d+)\),\((\d+),(\d+)\)<\|box_end\|\>"
        match = re.search(box_pattern, text)

        if match:
            return [
                int(match.group(1)),
                int(match.group(2)),
                int(match.group(3)),
                int(match.group(4)),
            ]

        # íŒ¨í„´ 2: ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ 4ê°œì˜ ìˆ«ì ì°¾ê¸°
        numbers = re.findall(r"\b\d+\b", text)
        if len(numbers) >= 4:
            # ì²˜ìŒ 4ê°œ ìˆ«ìë¥¼ bboxë¡œ ì‚¬ìš©
            return [int(numbers[0]), int(numbers[1]), int(numbers[2]), int(numbers[3])]

        # ê¸°ë³¸ê°’: íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¤‘ì•™ ì˜ì—­ ì‚¬ìš©
        print("  âš  bbox íŒŒì‹± ì‹¤íŒ¨, ì¤‘ì•™ ì˜ì—­ ì‚¬ìš©")
        return [400, 400, 600, 600]  # ì¤‘ì•™ ì˜ì—­ (ì •ê·œí™” 0-1000)

    def create_mask(
        self,
        image_size: Tuple[int, int],
        bbox: List[int],
        mask_color: int = 255,
        background_color: int = 0,
    ) -> Image.Image:
        """
        ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¡œë¶€í„° ì´ì§„ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            image_size: ëŒ€ìƒ ì´ë¯¸ì§€ì˜ (width, height)
            bbox: ì •ê·œí™”ëœ ì¢Œí‘œì˜ [x1, y1, x2, y2] (0-1000 ë²”ìœ„)
            mask_color: ë§ˆìŠ¤í¬ ì˜ì—­ì˜ ìƒ‰ìƒ (ê¸°ë³¸ê°’: 255 = í°ìƒ‰)
            background_color: ë°°ê²½ ìƒ‰ìƒ (ê¸°ë³¸ê°’: 0 = ê²€ì •)

        Returns:
            ì´ì§„ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ('L' ëª¨ë“œì˜ PIL.Image)

        Example:
            >>> mask = analyzer.create_mask((1024, 1024), [400, 400, 600, 600])
        """
        width, height = image_size

        # ì •ê·œí™”ëœ ì¢Œí‘œ(0-1000)ë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
        x1 = int(bbox[0] * width / 1000)
        y1 = int(bbox[1] * height / 1000)
        x2 = int(bbox[2] * width / 1000)
        y2 = int(bbox[3] * height / 1000)

        # ê²€ì€ ë°°ê²½ ìƒì„±
        mask = Image.new("L", image_size, background_color)
        draw = ImageDraw.Draw(mask)

        # ë§ˆìŠ¤í¬ ì˜ì—­ì— í°ìƒ‰ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        draw.rectangle([x1, y1, x2, y2], fill=mask_color)

        print(
            f"  âœ“ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ: {image_size[0]}x{image_size[1]}, "
            f"ì˜ì—­: ({x1},{y1})-({x2},{y2})"
        )

        return mask

    def visualize_bbox(
        self, image: Image.Image, bbox: List[int], color: str = "red", width: int = 3
    ) -> Image.Image:
        """
        ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

        Args:
            image: ì…ë ¥ PIL Image
            bbox: ì •ê·œí™”ëœ ì¢Œí‘œì˜ [x1, y1, x2, y2] (0-1000 ë²”ìœ„)
            color: ë°”ìš´ë”© ë°•ìŠ¤ ìƒ‰ìƒ
            width: ì„  ë‘ê»˜

        Returns:
            ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€

        Example:
            >>> bbox_img = analyzer.visualize_bbox(bg_image, [400, 400, 600, 600])
        """
        img_copy = image.copy()
        draw = ImageDraw.Draw(img_copy)

        # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
        img_width, img_height = image.size
        x1 = int(bbox[0] * img_width / 1000)
        y1 = int(bbox[1] * img_height / 1000)
        x2 = int(bbox[2] * img_width / 1000)
        y2 = int(bbox[3] * img_height / 1000)

        # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        draw.rectangle([x1, y1, x2, y2], outline=color, width=width)

        return img_copy

    def __del__(self):
        """ê°ì²´ ì†Œë©¸ ì‹œ ì •ë¦¬ ì‘ì—…"""
        self._unload_model()

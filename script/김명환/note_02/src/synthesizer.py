"""
ê°ì²´ í•©ì„± ëª¨ë“ˆ: FLUX.1-Fill + IP-Adapterë¥¼ ì‚¬ìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ê°ì²´ ë°°ì¹˜
Object Synthesis Module: Natural object placement using FLUX.1-Fill + IP-Adapter
"""

import torch
from PIL import Image
from diffusers import FluxFillPipeline
from diffusers.models import FluxTransformer2DModel
from transformers import BitsAndBytesConfig
from typing import Optional, Union
from pathlib import Path
import logging

# Try to import helper_dev_utils, fallback to standard logging if not available
try:
    from helper_dev_utils import get_auto_logger
    logger = get_auto_logger()
except ImportError:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

from .utils import flush_gpu


class ObjectSynthesizer:
    """
    FLUX.1-Fill-devë¥¼ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì¡°ëª…ê³¼ ê·¸ë¦¼ìë¡œ
    ê°ì²´ë¥¼ ë°°ê²½ì— í•©ì„±í•˜ëŠ” í´ë˜ìŠ¤

    ì´ í´ë˜ìŠ¤ëŠ” ì¸í˜ì¸íŒ…ì„ ìˆ˜í–‰í•˜ì—¬ ë§ˆìŠ¤í¬ëœ ì˜ì—­ì— ìƒˆë¡œìš´ ê°ì²´ë¥¼ ìƒì„±í•˜ë©°,
    ì£¼ë³€ ì¡°ëª… ë° ì›ê·¼ê°ê³¼ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

    Note:
        - í˜„ì¬ IP-AdapterëŠ” ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (diffusers ë¯¸í†µí•©)
        - ê°ì²´ íŠ¹ì§•ì€ í”„ë¡¬í”„íŠ¸ì— ìƒì„¸íˆ ê¸°ìˆ í•´ì•¼ í•©ë‹ˆë‹¤

    Attributes:
        base_model (str): FLUX.1-Fill-dev ëª¨ë¸ ì´ë¦„
        ip_adapter_model (str): IP-Adapter ëª¨ë¸ ì´ë¦„ (ì˜ˆì•½ë¨, í˜„ì¬ ë¯¸ì‚¬ìš©)
        device (str): ëª¨ë¸ ì‹¤í–‰ ë””ë°”ì´ìŠ¤
        torch_dtype: ëª¨ë¸ ê°€ì¤‘ì¹˜ ë°ì´í„° íƒ€ì…
        pipe: FLUX Fill íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤
    """

    def __init__(
        self,
        base_model: str = "black-forest-labs/FLUX.1-Fill-dev",
        ip_adapter_model: str = "XLabs-AI/flux-ip-adapter-v2",
        device: str = None,
        torch_dtype: torch.dtype = torch.bfloat16,
        enable_ip_adapter: bool = True,
    ):
        """
        ObjectSynthesizer ì´ˆê¸°í™”

        Args:
            base_model: FLUX.1-Fill-dev ëª¨ë¸ ì‹ë³„ì
            ip_adapter_model: IP-Adapter ëª¨ë¸ ì‹ë³„ì
            device: ëª¨ë¸ ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', ê¸°ë³¸ê°’: ìë™ ê°ì§€)
            torch_dtype: ëª¨ë¸ ê°€ì¤‘ì¹˜ ë°ì´í„° íƒ€ì… (bfloat16 ê¶Œì¥)
            enable_ip_adapter: IP-Adapter í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        self.base_model = base_model
        self.ip_adapter_model = ip_adapter_model
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.torch_dtype = torch_dtype
        self.enable_ip_adapter = enable_ip_adapter
        self.ip_adapter_scale = 0.8  # ê¸°ë³¸ IP-Adapter ìŠ¤ì¼€ì¼
        self.pipe = None  # ì§€ì—° ë¡œë”© (FluxFillPipeline)
        self.flux_pipe = None  # ì§€ì—° ë¡œë”© (FluxPipeline for IP-Adapter)

        print(f"ğŸ”§ ObjectSynthesizer ì´ˆê¸°í™”")
        print(f"   ë² ì´ìŠ¤ ëª¨ë¸: {base_model}")
        print(f"   IP-Adapter ëª¨ë¸: {ip_adapter_model}")
        print(f"   IP-Adapter í™œì„±í™”: {'âœ“ ì˜ˆ' if enable_ip_adapter else 'âœ— ì•„ë‹ˆì˜¤'}")

    def _print_gpu_memory(self, stage: str = ""):
        """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            stage_msg = f" [{stage}]" if stage else ""
            print(f"    GPU ë©”ëª¨ë¦¬{stage_msg}: {allocated:.2f}GB í• ë‹¹ / {reserved:.2f}GB ì˜ˆì•½")

    def _load_model(self, with_ip_adapter: bool = False):
        """
        FLUX.1-Fill íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.

        Args:
            with_ip_adapter: IP-Adapterë¥¼ í•¨ê»˜ ë¡œë“œí• ì§€ ì—¬ë¶€
        """
        if self.pipe is None:
            print(f"  FLUX.1-Fill íŒŒì´í”„ë¼ì¸ì„ {self.device}ì— ë¡œë“œ ì¤‘...")

            # L4 GPUë¥¼ ìœ„í•œ 8bit ì–‘ìí™” ì„¤ì •
            quantization_config = BitsAndBytesConfig(
                load_in_8bit=True,
                bnb_8bit_compute_dtype=torch.bfloat16,
            )

            # 1ë‹¨ê³„: ë² ì´ìŠ¤ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ 8bit ì–‘ìí™”ë¡œ ë¡œë“œ
            print(f"  íŠ¸ëœìŠ¤í¬ë¨¸ ë¡œë“œ ì¤‘ (8bit ì–‘ìí™”)...")
            base_transformer = FluxTransformer2DModel.from_pretrained(
                self.base_model,
                subfolder="transformer",
                torch_dtype=self.torch_dtype,
                quantization_config=quantization_config,  # 8bit ì–‘ìí™”
            )
            self._print_gpu_memory("íŠ¸ëœìŠ¤í¬ë¨¸ ë¡œë“œ í›„")

            # 2ë‹¨ê³„: ì–‘ìí™”ëœ íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„±
            print(f"  íŒŒì´í”„ë¼ì¸ ìƒì„± ì¤‘...")
            self.pipe = FluxFillPipeline.from_pretrained(
                self.base_model,
                transformer=base_transformer,  # ì–‘ìí™”ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ì‚¬ìš©
                torch_dtype=self.torch_dtype,
            )
            self._print_gpu_memory("íŒŒì´í”„ë¼ì¸ ìƒì„± í›„")

            # ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜ í™œì„±í™”
            if self.device == "cuda":
                # CPU ì˜¤í”„ë¡œë”©: ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»´í¬ë„ŒíŠ¸ë¥¼ ìë™ìœ¼ë¡œ CPUë¡œ ì´ë™
                self.pipe.enable_model_cpu_offload()
                # ì–´í…ì…˜ ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ VRAM ì¶”ê°€ ì ˆì•½ (1-2GB ì ˆì•½)
                self.pipe.enable_attention_slicing()
                print(f"  âœ“ Attention Slicing í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ)")
                self._print_gpu_memory("ìµœì í™” ì ìš© í›„")

            # IP-Adapter ë¡œë“œ (ìš”ì²­ ì‹œ)
            # NOTE: FluxFillPipelineì€ load_ip_adapterë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
            # IP-AdapterëŠ” 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
            if with_ip_adapter and self.enable_ip_adapter:
                print(f"  âš ï¸  FluxFillPipelineì€ IP-Adapterë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print(f"  IP-Adapterë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ use_two_stage=Trueë¡œ ì„¤ì •í•˜ì„¸ìš”.")

            print(f"  âœ“ FLUX.1-Fill íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ (8bit ì–‘ìí™”)")
            if not with_ip_adapter:
                print(f"  âš ï¸  ì°¸ê³ : IP-AdapterëŠ” í˜„ì¬ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤.")

    def _unload_model(self):
        """VRAM í™•ë³´ë¥¼ ìœ„í•´ íŒŒì´í”„ë¼ì¸ì„ ì–¸ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.pipe is not None:
            print("  FLUX.1-Fill íŒŒì´í”„ë¼ì¸ ì–¸ë¡œë“œ ì¤‘...")
            if hasattr(self.pipe, "to"):
                self.pipe.to("cpu")
            del self.pipe
            self.pipe = None
            flush_gpu()  # GPU ìºì‹œ ì •ë¦¬

    def _prepare_reference_image(self, reference: Image.Image) -> Image.Image:
        """
        ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        IP-AdapterëŠ” RGB ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìœ¼ë¯€ë¡œ,
        RGBAë‚˜ ë‹¤ë¥¸ ëª¨ë“œì˜ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            reference: ì°¸ì¡° ì´ë¯¸ì§€ (PIL.Image)

        Returns:
            RGB ëª¨ë“œì˜ PIL.Image
        """
        if reference.mode == "RGBA":
            # í°ìƒ‰ ë°°ê²½ì— ì•ŒíŒŒ ì±„ë„ì„ ì‚¬ìš©í•˜ì—¬ í•©ì„±
            rgb_ref = Image.new("RGB", reference.size, (255, 255, 255))
            rgb_ref.paste(reference, mask=reference.split()[3])
            return rgb_ref
        elif reference.mode != "RGB":
            return reference.convert("RGB")
        return reference

    def _unload_flux_pipeline(self):
        """FluxPipelineì„ ì–¸ë¡œë“œí•˜ì—¬ VRAMì„ í™•ë³´í•©ë‹ˆë‹¤."""
        if hasattr(self, 'flux_pipe') and self.flux_pipe is not None:
            print("  FluxPipeline ì–¸ë¡œë“œ ì¤‘...")
            if hasattr(self.flux_pipe, "to"):
                self.flux_pipe.to("cpu")
            del self.flux_pipe
            self.flux_pipe = None
            flush_gpu()
            print("  âœ“ FluxPipeline ì–¸ë¡œë“œ ì™„ë£Œ")

    def _load_flux_pipeline(self):
        """
        1ë‹¨ê³„ìš© FluxPipeline + IP-Adapterë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

        ì´ íŒŒì´í”„ë¼ì¸ì€ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ì‹œê°ì  íŠ¹ì§•ì„ ë°˜ì˜í•˜ì—¬
        ì´ˆê¸° í•©ì„± ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        if self.flux_pipe is None:
            print(f"  FluxPipeline + IP-Adapterë¥¼ {self.device}ì— ë¡œë“œ ì¤‘...")

            from diffusers import FluxPipeline

            # FLUX.1-dev (text-to-image) ë¡œë“œ
            print(f"  FLUX.1-dev íŒŒì´í”„ë¼ì¸ ìƒì„± ì¤‘...")
            self.flux_pipe = FluxPipeline.from_pretrained(
                "black-forest-labs/FLUX.1-dev",
                torch_dtype=self.torch_dtype,
            )
            self._print_gpu_memory("FluxPipeline ë¡œë“œ í›„")

            # ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”
            if self.device == "cuda":
                self.flux_pipe.enable_model_cpu_offload()
                self.flux_pipe.enable_attention_slicing()
                print(f"  âœ“ ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")
                self._print_gpu_memory("ìµœì í™” ì ìš© í›„")

            # IP-Adapter ë¡œë“œ
            print(f"  IP-Adapter ë¡œë“œ ì¤‘: {self.ip_adapter_model}")
            self.flux_pipe.load_ip_adapter(
                self.ip_adapter_model,
                weight_name="ip_adapter.safetensors",
                image_encoder_pretrained_model_name_or_path="openai/clip-vit-large-patch14"
            )
            self._print_gpu_memory("IP-Adapter ë¡œë“œ í›„")

            # IMPORTANT: IP-Adapterì˜ ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ëª…ì‹œì ìœ¼ë¡œ GPUë¡œ ì´ë™
            # CPU offloadingê³¼ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ device mismatchë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•¨
            if self.device == "cuda" and hasattr(self.flux_pipe, 'image_encoder'):
                print(f"  ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ GPUë¡œ ì´ë™ ì¤‘...")
                self.flux_pipe.image_encoder.to(self.device, dtype=self.torch_dtype)
                print(f"  âœ“ ì´ë¯¸ì§€ ì¸ì½”ë” GPU ì´ë™ ì™„ë£Œ")

            # IP-Adapter ìŠ¤ì¼€ì¼ ì„¤ì •
            self.flux_pipe.set_ip_adapter_scale(self.ip_adapter_scale)

            print(f"  âœ“ FluxPipeline + IP-Adapter ë¡œë“œ ì™„ë£Œ")
            print(f"  âœ“ IP-Adapter ìŠ¤ì¼€ì¼: {self.ip_adapter_scale}")

    def _stage1_ip_adapter_generation(
        self,
        background: Image.Image,
        mask: Image.Image,
        reference: Image.Image,
        prompt: str,
        ip_adapter_scale: float,
        seed: Optional[int],
    ) -> Image.Image:
        """
        1ë‹¨ê³„: IP-Adapterë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¸ì¡° ì´ë¯¸ì§€ íŠ¹ì§•ì„ ë°˜ì˜í•œ ì´ˆê¸° í•©ì„± ìƒì„±

        Args:
            background: ë°°ê²½ ì´ë¯¸ì§€
            mask: ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (í˜„ì¬ëŠ” ì •ë³´ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
            reference: ì°¸ì¡° ì´ë¯¸ì§€ (ì œí’ˆì˜ ê¹¨ë—í•œ ì´ë¯¸ì§€)
            prompt: ì¥ë©´ ì„¤ëª… í”„ë¡¬í”„íŠ¸
            ip_adapter_scale: IP-Adapter ê°•ë„ (0.0-1.0)
            seed: ëœë¤ ì‹œë“œ

        Returns:
            ì°¸ì¡° ì´ë¯¸ì§€ íŠ¹ì§•ì´ ë°˜ì˜ëœ ì´ˆê¸° í•©ì„± ì´ë¯¸ì§€
        """
        print(f"\n  [1ë‹¨ê³„] IP-Adapterë¡œ ì°¸ì¡° ì´ë¯¸ì§€ íŠ¹ì§• ë°˜ì˜ ì¤‘...")

        # FluxPipeline + IP-Adapter ë¡œë“œ
        self._load_flux_pipeline()

        # ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
        reference_rgb = self._prepare_reference_image(reference)
        print(f"  ì°¸ì¡° ì´ë¯¸ì§€ í¬ê¸°: {reference_rgb.size}, ëª¨ë“œ: {reference_rgb.mode}")

        # ì‹œë“œ ì„¤ì •
        generator = torch.Generator(device=self.device).manual_seed(seed) if seed else None

        # IP-Adapterë¡œ ìƒì„±
        print(f"  IP-Adapterë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        print(f"  í”„ë¡¬í”„íŠ¸: {prompt[:80]}...")
        output = self.flux_pipe(
            prompt=prompt,
            ip_adapter_image=reference_rgb,
            height=background.size[1],
            width=background.size[0],
            num_inference_steps=28,
            guidance_scale=3.5,
            generator=generator,
        )

        stage1_image = output.images[0]
        print(f"  âœ“ 1ë‹¨ê³„ ì™„ë£Œ: ì°¸ì¡° ì´ë¯¸ì§€ íŠ¹ì§•ì´ ë°˜ì˜ëœ ì´ë¯¸ì§€ ìƒì„±ë¨")

        # ë©”ëª¨ë¦¬ í™•ë³´
        self._unload_flux_pipeline()

        return stage1_image

    def _stage2_fill_refinement(
        self,
        stage1_image: Image.Image,
        mask: Image.Image,
        prompt: str,
        num_inference_steps: int,
        guidance_scale: float,
        seed: Optional[int],
    ) -> Image.Image:
        """
        2ë‹¨ê³„: FluxFillPipelineìœ¼ë¡œ ë§ˆìŠ¤í¬ ê²½ê³„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ê¸°

        Args:
            stage1_image: 1ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€
            mask: ë§ˆìŠ¤í¬ ì´ë¯¸ì§€
            prompt: ì¥ë©´ ì„¤ëª… í”„ë¡¬í”„íŠ¸
            num_inference_steps: ë””ë…¸ì´ì§• ìŠ¤í… ìˆ˜
            guidance_scale: CFG ìŠ¤ì¼€ì¼
            seed: ëœë¤ ì‹œë“œ

        Returns:
            ë§ˆìŠ¤í¬ ê²½ê³„ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì–´ì§„ ìµœì¢… ì´ë¯¸ì§€
        """
        print(f"\n  [2ë‹¨ê³„] FluxFillë¡œ ë§ˆìŠ¤í¬ ê²½ê³„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ê¸°...")

        # FluxFillPipeline ë¡œë“œ
        self._load_model()

        # ì‹œë“œ ì„¤ì •
        generator = torch.Generator(device=self.device).manual_seed(seed) if seed else None

        # ì¸í˜ì¸íŒ…ìœ¼ë¡œ ë‹¤ë“¬ê¸°
        print(f"  ì¸í˜ì¸íŒ… ì‹¤í–‰ ì¤‘...")
        output = self.pipe(
            prompt=prompt,
            image=stage1_image,  # 1ë‹¨ê³„ ê²°ê³¼ë¥¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ìš©
            mask_image=mask,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=generator,
            height=stage1_image.size[1],
            width=stage1_image.size[0],
        )

        final_image = output.images[0]
        print(f"  âœ“ 2ë‹¨ê³„ ì™„ë£Œ: ìì—°ìŠ¤ëŸ¬ìš´ ê²½ê³„ ë¸”ë Œë”© ì™„ë£Œ")

        # ë©”ëª¨ë¦¬ í™•ë³´
        self._unload_model()

        return final_image

    def fill_in_object(
        self,
        background: Union[Image.Image, str, Path],
        mask: Union[Image.Image, str, Path],
        reference: Union[Image.Image, str, Path],
        prompt: str,
        num_inference_steps: int = 28,
        guidance_scale: float = 3.5,
        ip_adapter_scale: float = 0.8,
        seed: Optional[int] = None,
        use_two_stage: bool = True,
    ) -> Image.Image:
        """
        ë§ˆìŠ¤í¬ëœ ìœ„ì¹˜ì— ì°¸ì¡° ê°ì²´ë¥¼ ë°°ê²½ì— í•©ì„±í•©ë‹ˆë‹¤.

        Args:
            background: ë°°ê²½ ì´ë¯¸ì§€ (PIL.Image ë˜ëŠ” ê²½ë¡œ)
            mask: ê°ì²´ë¥¼ ë°°ì¹˜í•  ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ì§„ ë§ˆìŠ¤í¬ (PIL.Image ë˜ëŠ” ê²½ë¡œ)
            reference: ê°ì²´ì˜ ê¹¨ë—í•œ ì°¸ì¡° ì´ë¯¸ì§€ (IP-Adapterë¡œ íŠ¹ì§• ë°˜ì˜)
            prompt: ìµœì¢… ì¥ë©´ì˜ í…ìŠ¤íŠ¸ ì„¤ëª…
            num_inference_steps: ë””ë…¸ì´ì§• ìŠ¤í… ìˆ˜ (ê¸°ë³¸ê°’: 28)
            guidance_scale: CFG ìŠ¤ì¼€ì¼ (ê¸°ë³¸ê°’: 3.5)
            ip_adapter_scale: IP-Adapter ê°•ë„ (0.0-1.0, ê¸°ë³¸ê°’: 0.8)
            seed: ì¬í˜„ ê°€ëŠ¥ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ
            use_two_stage: 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)

        Returns:
            ìµœì¢… í•©ì„±ëœ ì´ë¯¸ì§€ (PIL.Image)

        ì‹¤í–‰ ë°©ì‹:
            1. 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ (IP-Adapter ì‚¬ìš©, ë©”ëª¨ë¦¬ ë§ì´ í•„ìš”):
               - use_two_stage=True, enable_ip_adapter=True
               - FluxPipeline(IP-Adapter) â†’ FluxFillPipeline ìˆœì°¨ ì‹¤í–‰
               - ì°¸ì¡° ì´ë¯¸ì§€ì˜ ì‹œê°ì  íŠ¹ì§•ì„ ë°˜ì˜í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ í•©ì„±
               - ë©”ëª¨ë¦¬: ~22GB+ (ëª¨ë¸ 2ê°œ, ìˆœì°¨ ë¡œë“œ/ì–¸ë¡œë“œ)

            2. ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ (í…ìŠ¤íŠ¸ë§Œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì ):
               - use_two_stage=False (IP-Adapter ë¬´ì‹œ)
               - FluxFillPipelineë§Œ ì‚¬ìš©
               - ì°¸ì¡° ì´ë¯¸ì§€ ë¬´ì‹œ, í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©
               - ë©”ëª¨ë¦¬: ~11GB (ëª¨ë¸ 1ê°œ)
               - âš ï¸ FluxFillPipelineì€ IP-Adapterë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ

        Note:
            - FluxFillPipelineì€ load_ip_adapter ë©”ì„œë“œë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
            - IP-Adapterë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë°˜ë“œì‹œ use_two_stage=Trueë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤
            - ë‹¨ì¼ íŒŒì´í”„ë¼ì¸(use_two_stage=False)ì€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤

        Example:
            >>> # 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ (IP-Adapter ì‚¬ìš©, ë©”ëª¨ë¦¬ ë§ì´ í•„ìš”)
            >>> synthesizer = ObjectSynthesizer(enable_ip_adapter=True)
            >>> result = synthesizer.fill_in_object(
            ...     background=bg_image,
            ...     mask=mask_image,
            ...     reference=clean_product,
            ...     prompt="ê°ˆìƒ‰ ìœ ë¦¬ë³‘ì˜ ë§¥ì£¼, ë”°ëœ»í•œ ë°” ì¡°ëª…ì˜ ë‚˜ë¬´ í…Œì´ë¸” ìœ„",
            ...     use_two_stage=True,  # IP-Adapter ì‚¬ìš©
            ...     seed=42
            ... )
            >>>
            >>> # ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ (í…ìŠ¤íŠ¸ë§Œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            >>> result = synthesizer.fill_in_object(
            ...     background=bg_image,
            ...     mask=mask_image,
            ...     reference=clean_product,  # ë¬´ì‹œë¨
            ...     prompt="ê°ˆìƒ‰ ìœ ë¦¬ë³‘ì˜ ë§¥ì£¼, ë”°ëœ»í•œ ë°” ì¡°ëª…ì˜ ë‚˜ë¬´ í…Œì´ë¸” ìœ„",
            ...     use_two_stage=False,  # í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
            ...     seed=42
            ... )
        """
        try:
            # ê²½ë¡œê°€ ì œê³µëœ ê²½ìš° ì´ë¯¸ì§€ ë¡œë“œ
            background = self._load_image_if_path(background)
            mask = self._load_image_if_path(mask)
            reference = self._load_image_if_path(reference)

            # ë§ˆìŠ¤í¬ë¥¼ 'L' ëª¨ë“œ(ê·¸ë ˆì´ìŠ¤ì¼€ì¼)ë¡œ ë³€í™˜
            if mask.mode != "L":
                mask = mask.convert("L")

            # ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
            reference = self._prepare_reference_image(reference)

            print(f"\n{'='*60}")
            print(f"  ê°ì²´ í•©ì„± ì‹œì‘")
            print(f"  ë°°ê²½ í¬ê¸°: {background.size}")
            print(f"  ì°¸ì¡° ì´ë¯¸ì§€ í¬ê¸°: {reference.size}")
            print(f"  í”„ë¡¬í”„íŠ¸: {prompt[:80]}...")
            print(f"  IP-Adapter í™œì„±í™”: {self.enable_ip_adapter}")
            print(f"  2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸: {use_two_stage}")
            print(f"  IP-Adapter ìŠ¤ì¼€ì¼: {ip_adapter_scale}")
            print(f"{'='*60}\n")

            # IP-Adapter ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¥¸ ì‹¤í–‰ ë°©ì‹ ê²°ì •
            if use_two_stage and self.enable_ip_adapter:
                # ===== 2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ (ë©”ëª¨ë¦¬ ë§ì´ í•„ìš”) =====
                print(f"  âš ï¸  2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ)")

                # 1ë‹¨ê³„: IP-Adapterë¡œ ì°¸ì¡° ì´ë¯¸ì§€ íŠ¹ì§• ë°˜ì˜
                stage1_result = self._stage1_ip_adapter_generation(
                    background=background,
                    mask=mask,
                    reference=reference,
                    prompt=prompt,
                    ip_adapter_scale=ip_adapter_scale,
                    seed=seed,
                )

                # 2ë‹¨ê³„: FluxFillë¡œ ë§ˆìŠ¤í¬ ê²½ê³„ ë‹¤ë“¬ê¸°
                final_result = self._stage2_fill_refinement(
                    stage1_image=stage1_result,
                    mask=mask,
                    prompt=prompt,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    seed=seed,
                )

                print(f"\n{'='*60}")
                print(f"  âœ“ 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                print(f"  ì°¸ì¡° ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì´ ìµœì¢… ê²°ê³¼ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"{'='*60}\n")

                return final_result

            else:
                # ===== ê¸°ì¡´ ë°©ì‹: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš© =====
                print(f"  âš ï¸  ê¸°ì¡´ ë°©ì‹ ì‹¤í–‰ (IP-Adapter ë¯¸ì‚¬ìš©)")
                print(f"  ì°¸ì¡° ì´ë¯¸ì§€ëŠ” ë¬´ì‹œë©ë‹ˆë‹¤.")

                # ëª¨ë¸ ë¡œë“œ
                self._load_model(with_ip_adapter=False)

                # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
                if seed is not None:
                    generator = torch.Generator(device=self.device).manual_seed(seed)
                else:
                    generator = None

                # ì¸í˜ì¸íŒ… ì‹¤í–‰ (í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©)
                output = self.pipe(
                    prompt=prompt,
                    image=background,
                    mask_image=mask,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    generator=generator,
                    height=background.size[1],
                    width=background.size[0],
                )

                result = output.images[0]
                print(f"  âœ“ ê¸°ì¡´ ë°©ì‹ í•©ì„± ì™„ë£Œ")

                return result

        finally:
            # VRAM í™•ë³´ë¥¼ ìœ„í•´ í•­ìƒ ëª¨ë¸ ì–¸ë¡œë“œ
            self._unload_model()
            self._unload_flux_pipeline()

    def _load_image_if_path(self, image: Union[Image.Image, str, Path]) -> Image.Image:
        """ê²½ë¡œê°€ ì œê³µëœ ê²½ìš° ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if isinstance(image, (str, Path)):
            from .utils import load_image

            return load_image(image)
        return image

    def __del__(self):
        """ê°ì²´ ì†Œë©¸ ì‹œ ì •ë¦¬ ì‘ì—…"""
        self._unload_model()
        self._unload_flux_pipeline()

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Ad-Gen-Pipeline Validation Notebook\n",
    "\n",
    "This notebook validates each step of the advertisement image generation pipeline:\n",
    "1. **Object Matting**: Remove background from product image\n",
    "2. **Background Generation**: Create atmospheric background\n",
    "3. **Spatial Analysis**: Find optimal placement location\n",
    "4. **Object Synthesis**: Blend object into background with natural lighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "import logging\n\n# Try to import helper_dev_utils, fallback to standard logging if not available\ntry:\n    from helper_dev_utils import get_auto_logger\n    logger = get_auto_logger()\nexcept ImportError:\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger(__name__)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Import our modules\n",
    "from src import (\n",
    "    flush_gpu,\n",
    "    load_image,\n",
    "    save_image,\n",
    "    ObjectMatting,\n",
    "    BackgroundGenerator,\n",
    "    SpatialAnalyzer,\n",
    "    ObjectSynthesizer\n",
    ")\n",
    "from src.utils import get_device, print_gpu_memory\n",
    "\n",
    "# Check GPU availability\n",
    "device = get_device()\n",
    "print_gpu_memory()\n",
    "\n",
    "# Helper function to display images\n",
    "def show_images(images, titles=None, figsize=(15, 5)):\n",
    "    \"\"\"Display multiple images side by side.\"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (img, ax) in enumerate(zip(images, axes)):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "logger.debug(\"\\nâœ… Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Cell 2: Input Data Definition (User Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# USER CONFIGURATION: Modify these parameters\n",
    "# ==================================================\n",
    "\n",
    "# Input product image path\n",
    "INPUT_IMAGE_PATH = \"../image.png\"  # ë…¸ê°€ë¦¬ ì´ë¯¸ì§€\n",
    "\n",
    "# Scenario: ë…¸ê°€ë¦¬ë¥¼ ìˆ ì•ˆì£¼ë¡œ ì œê³µí•˜ëŠ” í¬ìž¥ë§ˆì°¨/ì„ ìˆ ì§‘ ìž¥ë©´\n",
    "PROMPT_SCENARIO = (\n",
    "    \"A photorealistic shot of dried pollack fish (nogari) as a Korean bar snack \"\n",
    "    \"on a wooden table in a traditional Korean bar (pojangmacha), \"\n",
    "    \"warm ambient lighting, cozy atmosphere, shallow depth of field, \"\n",
    "    \"natural food photography, cinematic style\"\n",
    ")\n",
    "\n",
    "# Background-specific prompt (remove product mentions)\n",
    "PROMPT_BACKGROUND = (\n",
    "    \"An empty wooden table in a cozy Korean traditional bar (pojangmacha) \"\n",
    "    \"with soft warm lighting, empty space in center for food placement, \"\n",
    "    \"blurred background showing bar atmosphere with bokeh effect, \"\n",
    "    \"shallow depth of field, warm tones, no food on table\"\n",
    ")\n",
    "\n",
    "# Spatial query for object placement\n",
    "SPATIAL_QUERY = (\n",
    "    \"Find the flat surface on the table center where I can place dried fish snacks. \"\n",
    "    \"Return the bounding box coordinates for the empty area.\"\n",
    ")\n",
    "\n",
    "# Generation parameters\n",
    "IMAGE_SIZE = (1024, 1024)  # (width, height)\n",
    "SEED = 42  # For reproducibility\n",
    "IP_ADAPTER_SCALE = 0.8  # 0.7=natural, 1.0=preserve original\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(\"../outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "logger.debug(\"ðŸ“‹ Configuration:\")\n",
    "print(f\"   Input: {INPUT_IMAGE_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Image size: {IMAGE_SIZE}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "print(f\"\\nðŸ’­ Scenario: {PROMPT_SCENARIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Cell 3: Step 1 - Object Matting (Background Removal)\n",
    "\n",
    "Remove the background from the product image to create a clean reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"ðŸ”„ Step 1: Object Matting (Background Removal)\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Load original image\n",
    "original_image = load_image(INPUT_IMAGE_PATH)\n",
    "print(f\"\\nOriginal image loaded: {original_image.size}\")\n",
    "\n",
    "# Initialize ObjectMatting\n",
    "matting = ObjectMatting()\n",
    "\n",
    "# Remove background\n",
    "clean_ref_image = matting.remove_background(\n",
    "    INPUT_IMAGE_PATH,\n",
    "    return_rgba=True\n",
    ")\n",
    "\n",
    "# Save result\n",
    "output_path = OUTPUT_DIR / \"step1_clean_reference.png\"\n",
    "save_image(clean_ref_image, output_path)\n",
    "\n",
    "# Display results\n",
    "logger.debug(\"\\nðŸ“Š Validation Point: Is the background cleanly removed?\")\n",
    "show_images(\n",
    "    [original_image, clean_ref_image],\n",
    "    titles=[\"Original Product\", \"Background Removed (RGBA)\"],\n",
    "    figsize=(12, 6)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del matting\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\nâœ… Step 1 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Cell 4: Step 2 - Background Generation\n",
    "\n",
    "Generate an atmospheric background without the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"ðŸ”„ Step 2: Background Generation\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Initialize BackgroundGenerator\n",
    "bg_generator = BackgroundGenerator()\n",
    "\n",
    "# Generate background\n",
    "bg_image = bg_generator.generate_background(\n",
    "    prompt=PROMPT_BACKGROUND,\n",
    "    width=IMAGE_SIZE[0],\n",
    "    height=IMAGE_SIZE[1],\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=3.5,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Save result\n",
    "output_path = OUTPUT_DIR / \"step2_background.png\"\n",
    "save_image(bg_image, output_path)\n",
    "\n",
    "# Display result\n",
    "logger.debug(\"\\nðŸ“Š Validation Point: Does the background have space for object placement?\")\n",
    "show_images(\n",
    "    [bg_image],\n",
    "    titles=[\"Generated Background\"],\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del bg_generator\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\nâœ… Step 2 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Cell 5: Step 3 - Spatial Analysis (Object Placement)\n",
    "\n",
    "Analyze the background to find the optimal location for object placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"ðŸ”„ Step 3: Spatial Analysis (Object Placement)\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Initialize SpatialAnalyzer\n",
    "analyzer = SpatialAnalyzer()\n",
    "\n",
    "# Detect optimal surface\n",
    "detection_result = analyzer.detect_surface(\n",
    "    image=bg_image,\n",
    "    query=SPATIAL_QUERY\n",
    ")\n",
    "\n",
    "bbox = detection_result['bbox']\n",
    "print(f\"\\nðŸ“ Detected bounding box: {bbox}\")\n",
    "print(f\"   Model response: {detection_result['text'][:150]}...\")\n",
    "\n",
    "# Create mask\n",
    "mask_image = analyzer.create_mask(\n",
    "    image_size=detection_result['image_size'],\n",
    "    bbox=bbox\n",
    ")\n",
    "\n",
    "# Save mask\n",
    "output_path = OUTPUT_DIR / \"step3_mask.png\"\n",
    "save_image(mask_image, output_path)\n",
    "\n",
    "# Visualize bbox on background\n",
    "bg_with_bbox = analyzer.visualize_bbox(\n",
    "    image=bg_image,\n",
    "    bbox=bbox,\n",
    "    color='red',\n",
    "    width=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "logger.debug(\"\\nðŸ“Š Validation Point: Is the mask positioned appropriately?\")\n",
    "show_images(\n",
    "    [bg_image, bg_with_bbox, mask_image],\n",
    "    titles=[\"Background\", \"With BBox\", \"Binary Mask\"],\n",
    "    figsize=(18, 6)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del analyzer\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\nâœ… Step 3 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Cell 6: Step 4 - Object Synthesis (Final Composition)\n",
    "\n",
    "Synthesize the clean object into the background with natural lighting and shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "logger.debug(\"ðŸ”„ Step 4: Object Synthesis (Final Composition)\\n\")\nlogger.debug(\"=\" * 60)\n\n# Initialize ObjectSynthesizer\nsynthesizer = ObjectSynthesizer()\n\n# ===================================================================\n# IMPORTANT: FluxFillPipeline does NOT support IP-Adapter!\n# ===================================================================\n# Option 1: Single Pipeline (í…ìŠ¤íŠ¸ë§Œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ~11GB)\n#   - use_two_stage=False\n#   - ì°¸ì¡° ì´ë¯¸ì§€ëŠ” ë¬´ì‹œë˜ê³  í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©\n#   - ë©”ëª¨ë¦¬: ~11GB (FluxFillPipelineë§Œ ë¡œë“œ)\n#\n# Option 2: Two-Stage Pipeline (IP-Adapter ì‚¬ìš©, ë©”ëª¨ë¦¬ ë§Žì´ í•„ìš” ~22GB+)\n#   - use_two_stage=True\n#   - FluxPipeline(IP-Adapter) â†’ FluxFillPipeline ìˆœì°¨ ì‹¤í–‰\n#   - ì°¸ì¡° ì´ë¯¸ì§€ì˜ ì‹œê°ì  íŠ¹ì§•ì„ ë°˜ì˜\n#   - ë©”ëª¨ë¦¬: ~22GB+ (ëª¨ë¸ 2ê°œ, ìˆœì°¨ ë¡œë“œ/ì–¸ë¡œë“œ)\n# ===================================================================\n\n# Choose one option:\nUSE_TWO_STAGE = False  # True: IP-Adapter ì‚¬ìš© (ë©”ëª¨ë¦¬ ë§Žì´ í•„ìš”), False: í…ìŠ¤íŠ¸ë§Œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n\nif USE_TWO_STAGE:\n    logger.debug(\"âš ï¸  2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - IP-Adapter ì‚¬ìš© (ë©”ëª¨ë¦¬ ~22GB+ í•„ìš”)\")\nelse:\n    logger.debug(\"âœ… ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© (ë©”ëª¨ë¦¬ ~11GB, íš¨ìœ¨ì )\")\n    logger.debug(\"âš ï¸  ì°¸ì¡° ì´ë¯¸ì§€ëŠ” ë¬´ì‹œë˜ê³  í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤\")\n\n# Synthesize object into background\nfinal_image = synthesizer.fill_in_object(\n    background=bg_image,\n    mask=mask_image,\n    reference=clean_ref_image,\n    prompt=PROMPT_SCENARIO,\n    num_inference_steps=28,\n    guidance_scale=3.5,\n    ip_adapter_scale=IP_ADAPTER_SCALE,\n    seed=SEED,\n    use_two_stage=USE_TWO_STAGE\n)\n\n# Save final result\noutput_path = OUTPUT_DIR / \"step4_final_result.png\"\nsave_image(final_image, output_path)\n\n# Display final comparison\nlogger.debug(\"\\nðŸ“Š Validation Point: Is the object naturally blended with proper lighting/shadows?\")\nshow_images(\n    [clean_ref_image, bg_image, mask_image, final_image],\n    titles=[\"Clean Reference\", \"Background\", \"Mask\", \"Final Result\"],\n    figsize=(20, 5)\n)\n\n# Show before/after comparison\nlogger.debug(\"\\nðŸ” Before/After Comparison:\")\nshow_images(\n    [bg_image, final_image],\n    titles=[\"Background Only\", \"With Product\"],\n    figsize=(16, 8)\n)\n\n# Memory cleanup\ndel synthesizer\nflush_gpu()\nprint_gpu_memory()\nlogger.debug(\"\\nâœ… Step 4 complete!\\n\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
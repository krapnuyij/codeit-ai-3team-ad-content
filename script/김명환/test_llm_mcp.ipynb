{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2de75fc",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8a056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc5c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:09 D [ipykernel_launcher:18] - path: /home/spai0433/codeit-ai-3team-ad-content\n",
      "2026-01-12 23:27:09 D [ipykernel_launcher:18] - path: /home/spai0433/codeit-ai-3team-ad-content/src\n",
      "2026-01-12 23:27:09 D [ipykernel_launcher:20] - í”„ë¡œì íŠ¸ ë£¨íŠ¸: /home/spai0433/codeit-ai-3team-ad-content\n",
      "2026-01-12 23:27:09 D [ipykernel_launcher:21] - ì†ŒìŠ¤ ê²½ë¡œ: /home/spai0433/codeit-ai-3team-ad-content/src\n",
      "2026-01-12 23:27:09 D [ipykernel_launcher:27] - í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ: /home/spai0433/codeit-ai-3team-ad-content/.env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from helper_dev_utils import get_auto_logger\n",
    "logger = get_auto_logger()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "project_root = Path.cwd().parent.parent\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "# sys.pathì— ì¶”ê°€\n",
    "for path in [str(project_root), str(src_path)]:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "        logger.debug(f\"path: {path}\")\n",
    "\n",
    "logger.debug(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\")\n",
    "logger.debug(f\"ì†ŒìŠ¤ ê²½ë¡œ: {src_path}\")\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "env_path = project_root / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    logger.debug(f\"í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ: {env_path}\")\n",
    "else:\n",
    "    logger.warning(f\".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({env_path})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15bdc9",
   "metadata": {},
   "source": [
    "## 2. OpenAI API í‚¤ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818676ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:09 D [ipykernel_launcher:9] - OpenAI API í‚¤ í™•ì¸ë¨ (ê¸¸ì´: 164 ë¬¸ì)\n",
      "2026-01-12 23:27:09 D [ipykernel_launcher:10] -    í‚¤ prefix: sk-pr --- cxzEA\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API í‚¤ í™•ì¸\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    logger.debug(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    logger.debug(\"   .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:\")\n",
    "    logger.debug(\"   OPENAI_API_KEY=sk-...\")\n",
    "else:\n",
    "    logger.debug(f\"OpenAI API í‚¤ í™•ì¸ë¨ (ê¸¸ì´: {len(openai_api_key)} ë¬¸ì)\")\n",
    "    logger.debug(f\"   í‚¤ prefix: {openai_api_key[:5]} --- {openai_api_key[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ucldkd8c01",
   "metadata": {},
   "source": [
    "## 3. mcpadapter ì„í¬íŠ¸ ë° ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "y3k9mx3txx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:10 I [ipykernel_launcher:7] - mcpadapter ì„í¬íŠ¸ ì™„ë£Œ\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:8] -    MCP ì„œë²„ URL: http://localhost:3000\n"
     ]
    }
   ],
   "source": [
    "# mcpadapter ì„í¬íŠ¸\n",
    "from mcpadapter import MCPClient, LLMAdapter\n",
    "\n",
    "# ì„¤ì •\n",
    "MCP_SERVER_URL = \"http://localhost:3000\"\n",
    "\n",
    "logger.info(\"mcpadapter ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "logger.info(f\"   MCP ì„œë²„ URL: {MCP_SERVER_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "za8104rzn3g",
   "metadata": {},
   "source": [
    "## 4. ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1kxv0v0l2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:10 I [ipykernel_launcher:24] - ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:44] - ============================================================\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:45] - ê²½ë¡œ ì„¤ì • ì™„ë£Œ\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:46] - ============================================================\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:47] - ì‹¤í–‰ í™˜ê²½: LOCAL\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:48] - Static ê¸°ë³¸ ê²½ë¡œ: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:49] - ì—…ë¡œë“œ ë””ë ‰í† ë¦¬: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/uploads\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:50] - ê²°ê³¼ ë””ë ‰í† ë¦¬: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/results\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:51] - ì œí’ˆ ì´ë¯¸ì§€ ê²½ë¡œ: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/uploads/test_product.png\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:52] - ì¶œë ¥ ì´ë¯¸ì§€ ê²½ë¡œ: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/results/banana_ad_result.png\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:53] - ============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ ê²½ë¡œ ì„¤ì • (Docker/ë¡œì»¬ ìë™ ê°ì§€)\n",
    "# ===================================================================\n",
    "\n",
    "def get_static_base_path():\n",
    "    \"\"\"\n",
    "    í™˜ê²½ ë³€ìˆ˜ ê¸°ë°˜ static ê²½ë¡œ ë°˜í™˜\n",
    "    \n",
    "    - Docker í™˜ê²½: RUNTIME_ENV=docker, STATIC_BASE_PATH=/app/static\n",
    "    - ë¡œì»¬ í™˜ê²½: RUNTIME_ENV ë¯¸ì„¤ì • ë˜ëŠ” 'local'\n",
    "    \n",
    "    Returns:\n",
    "        Path: static ë””ë ‰í† ë¦¬ì˜ ì ˆëŒ€ ê²½ë¡œ\n",
    "    \"\"\"\n",
    "    runtime_env = os.getenv(\"RUNTIME_ENV\", \"local\")\n",
    "    \n",
    "    if runtime_env == \"docker\":\n",
    "        # Docker í™˜ê²½: STATIC_BASE_PATH í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©\n",
    "        static_base = os.getenv(\"STATIC_BASE_PATH\", \"/app/static\")\n",
    "        logger.info(f\"ğŸ³ Docker í™˜ê²½ ê°ì§€: {static_base}\")\n",
    "    else:\n",
    "        # ë¡œì»¬ ê°œë°œ í™˜ê²½: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ\n",
    "        static_base = src_path / \"nanoCocoa_aiserver\" / \"static\"\n",
    "        logger.info(f\"ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€: {static_base}\")\n",
    "    \n",
    "    return Path(static_base)\n",
    "\n",
    "# í™˜ê²½ë³„ ê²½ë¡œ ì„¤ì •\n",
    "STATIC_BASE = get_static_base_path()\n",
    "UPLOADS_DIR = STATIC_BASE / \"uploads\"\n",
    "RESULTS_DIR = STATIC_BASE / \"results\"\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "UPLOADS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "product_image_filename = \"test_product.png\"\n",
    "output_image_filename = \"banana_ad_result.png\"\n",
    "\n",
    "product_image_path = UPLOADS_DIR / product_image_filename\n",
    "output_image_path = RESULTS_DIR / output_image_filename\n",
    "\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"ê²½ë¡œ ì„¤ì • ì™„ë£Œ\")\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(f\"ì‹¤í–‰ í™˜ê²½: {os.getenv('RUNTIME_ENV', 'local').upper()}\")\n",
    "logger.info(f\"Static ê¸°ë³¸ ê²½ë¡œ: {STATIC_BASE}\")\n",
    "logger.info(f\"ì—…ë¡œë“œ ë””ë ‰í† ë¦¬: {UPLOADS_DIR}\")\n",
    "logger.info(f\"ê²°ê³¼ ë””ë ‰í† ë¦¬: {RESULTS_DIR}\")\n",
    "logger.info(f\"ì œí’ˆ ì´ë¯¸ì§€ ê²½ë¡œ: {product_image_path}\")\n",
    "logger.info(f\"ì¶œë ¥ ì´ë¯¸ì§€ ê²½ë¡œ: {output_image_path}\")\n",
    "logger.info(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4ddc0",
   "metadata": {},
   "source": [
    "## 4-0. ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸ ë° ìƒì„±\n",
    "\n",
    "**ì¤‘ìš”**: í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ê´‘ê³  ìƒì„±ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:10 I [ipykernel_launcher:41] - ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/uploads/test_product.png\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:42] -    í¬ê¸°: 285,210 bytes\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìë™ ìƒì„± (í•„ìš” ì‹œ)\n",
    "if not product_image_path.exists():\n",
    "    logger.warning(f\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {product_image_path}\")\n",
    "    logger.info(\"í…ŒìŠ¤íŠ¸ìš© ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •\n",
    "    import stat\n",
    "    if UPLOADS_DIR.exists():\n",
    "        current_mode = UPLOADS_DIR.stat().st_mode\n",
    "        logger.info(f\"í˜„ì¬ ë””ë ‰í† ë¦¬ ê¶Œí•œ: {oct(stat.S_IMODE(current_mode))}\")\n",
    "        \n",
    "        # ì“°ê¸° ê¶Œí•œ ë¶€ì—¬ (755)\n",
    "        try:\n",
    "            UPLOADS_DIR.chmod(0o755)\n",
    "            logger.info(\"ë””ë ‰í† ë¦¬ ê¶Œí•œ ìˆ˜ì • ì™„ë£Œ (755)\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ê¶Œí•œ ìˆ˜ì • ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}\")\n",
    "    \n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "    # 512x512 ë°”ë‚˜ë‚˜ ì´ë¯¸ì§€ ìƒì„±\n",
    "    img = Image.new('RGB', (512, 512), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # ë°”ë‚˜ë‚˜ ëª¨ì–‘ ê·¸ë¦¬ê¸°\n",
    "    draw.ellipse([150, 100, 450, 200], fill='#FFD700', outline='#FFA500', width=3)\n",
    "    draw.ellipse([100, 200, 400, 300], fill='#FFD700', outline='#FFA500', width=3)\n",
    "    draw.ellipse([120, 280, 380, 400], fill='#FFD700', outline='#FFA500', width=3)\n",
    "    \n",
    "    # ì €ì¥\n",
    "    try:\n",
    "        img.save(product_image_path)\n",
    "        logger.info(f\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {product_image_path}\")\n",
    "        logger.info(f\"   í¬ê¸°: {product_image_path.stat().st_size:,} bytes\")\n",
    "    except PermissionError as e:\n",
    "        logger.error(f\"ì €ì¥ ì‹¤íŒ¨ (ê¶Œí•œ ì˜¤ë¥˜): {e}\")\n",
    "        logger.info(\"í•´ê²° ë°©ë²•:\")\n",
    "        logger.info(f\"   í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰: chmod 755 {UPLOADS_DIR}\")\n",
    "        raise\n",
    "else:\n",
    "    logger.info(f\"ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬: {product_image_path}\")\n",
    "    logger.info(f\"   í¬ê¸°: {product_image_path.stat().st_size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3bdfd",
   "metadata": {},
   "source": [
    "## 4-0-1. ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •\n",
    "\n",
    "**ì¤‘ìš”**: Docker ë³¼ë¥¨ ë§ˆìš´íŠ¸ ë””ë ‰í† ë¦¬ì— ì“°ê¸° ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce118eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:10 I [ipykernel_launcher:4] - ============================================================\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:5] - ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:6] - ============================================================\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:15] - ì—…ë¡œë“œ ë””ë ‰í† ë¦¬: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/uploads\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:16] -    í˜„ì¬ ê¶Œí•œ: 0o775\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:32] -    ì“°ê¸° ê¶Œí•œ ìˆìŒ\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:15] - ê²°ê³¼ ë””ë ‰í† ë¦¬: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/results\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:16] -    í˜„ì¬ ê¶Œí•œ: 0o775\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:32] -    ì“°ê¸° ê¶Œí•œ ìˆìŒ\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:36] - ============================================================\n"
     ]
    }
   ],
   "source": [
    "# ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •\n",
    "import stat\n",
    "\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸\")\n",
    "logger.info(\"=\" * 60)\n",
    "\n",
    "for dir_name, dir_path in [\n",
    "    (\"ì—…ë¡œë“œ\", UPLOADS_DIR),\n",
    "    (\"ê²°ê³¼\", RESULTS_DIR)\n",
    "]:\n",
    "    if dir_path.exists():\n",
    "        current_mode = dir_path.stat().st_mode\n",
    "        mode_oct = oct(stat.S_IMODE(current_mode))\n",
    "        logger.info(f\"{dir_name} ë””ë ‰í† ë¦¬: {dir_path}\")\n",
    "        logger.info(f\"   í˜„ì¬ ê¶Œí•œ: {mode_oct}\")\n",
    "        \n",
    "        # ì“°ê¸° ê¶Œí•œ í™•ì¸\n",
    "        if not os.access(dir_path, os.W_OK):\n",
    "            logger.warning(f\"   ì“°ê¸° ê¶Œí•œ ì—†ìŒ!\")\n",
    "            logger.info(f\"   ê¶Œí•œ ìˆ˜ì • ì‹œë„ ì¤‘...\")\n",
    "            \n",
    "            try:\n",
    "                # 777 ê¶Œí•œ ë¶€ì—¬ (ëª¨ë“  ì‚¬ìš©ì ì½ê¸°/ì“°ê¸°/ì‹¤í–‰)\n",
    "                dir_path.chmod(0o777)\n",
    "                logger.info(f\"   ê¶Œí•œ ìˆ˜ì • ì™„ë£Œ (777)\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"   ê¶Œí•œ ìˆ˜ì • ì‹¤íŒ¨: {e}\")\n",
    "                logger.info(f\"   í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "                logger.info(f\"      chmod 777 {dir_path}\")\n",
    "        else:\n",
    "            logger.info(f\"   ì“°ê¸° ê¶Œí•œ ìˆìŒ\")\n",
    "    else:\n",
    "        logger.warning(f\"{dir_name} ë””ë ‰í† ë¦¬ ì—†ìŒ: {dir_path}\")\n",
    "\n",
    "logger.info(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b22c58c",
   "metadata": {},
   "source": [
    "## 4-1. ì„œë²„ ìƒíƒœ ëŒ€ê¸° í—¬í¼ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b103af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:10 I [ipykernel_launcher:53] - ì„œë²„ ëŒ€ê¸° í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "async def wait_for_server_ready(max_wait_sec: int = 300, check_interval: int = 10) -> bool:\n",
    "    \"\"\"\n",
    "    AI ì„œë²„ê°€ idle ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°\n",
    "    \n",
    "    Args:\n",
    "        max_wait_sec: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’ 300ì´ˆ = 5ë¶„)\n",
    "        check_interval: ìƒíƒœ í™•ì¸ ê°„ê²© (ì´ˆ, ê¸°ë³¸ê°’ 10ì´ˆ)\n",
    "    \n",
    "    Returns:\n",
    "        True: ì„œë²„ê°€ idle ìƒíƒœ\n",
    "        False: íƒ€ì„ì•„ì›ƒ ë°œìƒ\n",
    "    \"\"\"\n",
    "    logger.info(f\"ğŸ• AI ì„œë²„ idle ìƒíƒœ ëŒ€ê¸° ì¤‘... (ìµœëŒ€ {max_wait_sec}ì´ˆ)\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        elapsed = 0\n",
    "        while elapsed < max_wait_sec:\n",
    "            health = await client.call_tool(\"check_server_health\", {})\n",
    "            \n",
    "            # healthê°€ ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±\n",
    "            if isinstance(health, str):\n",
    "                # \"ìƒíƒœ: busy\" ë˜ëŠ” \"ìƒíƒœ: idle\" íŒ¨í„´ ì°¾ê¸°\n",
    "                if \"idle\" in health.lower():\n",
    "                    logger.info(f\"   ì„œë²„ idle ìƒíƒœ í™•ì¸ (ëŒ€ê¸° ì‹œê°„: {elapsed}ì´ˆ)\")\n",
    "                    return True\n",
    "                elif \"busy\" in health.lower():\n",
    "                    logger.info(f\"   â³ ì„œë²„ busy ìƒíƒœ... {check_interval}ì´ˆ í›„ ì¬í™•ì¸ (ê²½ê³¼: {elapsed}ì´ˆ/{max_wait_sec}ì´ˆ)\")\n",
    "                else:\n",
    "                    # ìƒíƒœë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë©´ ë°”ë¡œ ì§„í–‰\n",
    "                    logger.warning(f\"   ì„œë²„ ìƒíƒœ ë¶ˆëª…: {health}\")\n",
    "                    return True\n",
    "            else:\n",
    "                # dict í˜•íƒœì¸ ê²½ìš°\n",
    "                status = health.get(\"status\", \"unknown\") if isinstance(health, dict) else \"unknown\"\n",
    "                if status == \"idle\":\n",
    "                    logger.info(f\"   ì„œë²„ idle ìƒíƒœ í™•ì¸ (ëŒ€ê¸° ì‹œê°„: {elapsed}ì´ˆ)\")\n",
    "                    return True\n",
    "                elif status == \"busy\":\n",
    "                    logger.info(f\"   â³ ì„œë²„ busy ìƒíƒœ... {check_interval}ì´ˆ í›„ ì¬í™•ì¸ (ê²½ê³¼: {elapsed}ì´ˆ/{max_wait_sec}ì´ˆ)\")\n",
    "                else:\n",
    "                    logger.warning(f\"   ì„œë²„ ìƒíƒœ: {status}\")\n",
    "                    return True\n",
    "                \n",
    "            await asyncio.sleep(check_interval)\n",
    "            elapsed += check_interval\n",
    "        \n",
    "        logger.warning(f\"   â° íƒ€ì„ì•„ì›ƒ: {max_wait_sec}ì´ˆ ë™ì•ˆ ì„œë²„ê°€ idle ìƒíƒœê°€ ë˜ì§€ ì•ŠìŒ\")\n",
    "        return False\n",
    "\n",
    "logger.info(\"ì„œë²„ ëŒ€ê¸° í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4mzggv5ezdr",
   "metadata": {},
   "source": [
    "## 7. LLMAdapterë¥¼ í†µí•œ ìì—°ì–´ ê´‘ê³  ìƒì„±\n",
    "\n",
    "LLMAdapterëŠ” ìì—°ì–´ ìš”ì²­ì„ ìë™ìœ¼ë¡œ MCP ë„êµ¬ í˜¸ì¶œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "k01pshxrcnk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:10 I [ipykernel_launcher:8] - ============================================================\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:9] - LLMAdapter ê´‘ê³  ìƒì„± í…ŒìŠ¤íŠ¸\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:10] - ============================================================\n",
      "2026-01-12 23:27:10 I [mcp_client:51] - MCPClient ì´ˆê¸°í™”: base_url=http://localhost:3000\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:37] - ìì—°ì–´ ìš”ì²­ ì „ì†¡ ì¤‘...\n",
      "2026-01-12 23:27:10 I [ipykernel_launcher:38] - ìš”ì²­ ë‚´ìš©:\n",
      "\n",
      "ì‚¬ìš©ì: ë°”ë‚˜ë‚˜ íŠ¹ê°€ ê´‘ê³  ë§Œë“¤ì–´ì¤˜\n",
      "\n",
      "- product_image_path: \"/home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/uploads/test_product.png\"\n",
      "- save_output_path: \"/home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/results/banana...\n",
      "2026-01-12 23:27:47 I [llm_adapter:330] - MCP ë„êµ¬ í˜¸ì¶œ tool_name=generate_ad_image\n",
      "2026-01-12 23:27:47 I [llm_adapter:331] - MCP ë„êµ¬ í˜¸ì¶œ tool_args={'product_image_path': '/home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/uploads/test_product.png', 'background_prompt': 'Warm rustic market scene with wooden crate and banana bunch, soft studio window light, warm yellow-green palette, subtle bokeh, natural textures, high-end editorial composition', 'text_content': 'ë§›ìˆëŠ”ë°”ë‚˜ë‚˜ 2500ì›', 'text_prompt': '3D render glossy yellow balloon text with soft highlights, slight metallic sheen, studio lighting reflections, beveled edges', 'background_negative_prompt': 'blurry, low quality, distorted, bad lighting, harsh shadows, overexposed, cluttered, watermark, text, logo', 'text_negative_prompt': 'floor, ground, background, scene, flat, 2D, low quality, blurry, distorted letters, rough edges, poor rendering', 'composition_negative_prompt': 'artificial looking, pasted on, halos, color mismatch, poor blending, seams, visible edges, mismatched lighting, low quality, amateur work', 'composition_mode': 'overlay', 'text_position': 'auto', 'bg_composition_prompt': 'Banana product naturally placed, seamless integration, matching soft studio lighting, consistent depth of field, warm color harmony', 'bg_composition_negative_prompt': 'floating, disconnected, unrealistic shadows, mismatched lighting, pasted on, hovering, wrong perspective, inconsistent shadows', 'composition_prompt': 'Text floating naturally above the bananas with soft realistic shadows, consistent studio lighting, strong visual hierarchy, professional polished commercial quality', 'strength': 0.35, 'guidance_scale': 4.0, 'composition_strength': 0.4, 'composition_steps': 28, 'composition_guidance_scale': 4.0, 'auto_unload': True, 'wait_for_completion': False, 'save_output_path': '/home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/results/banana_ad_result.png'}\n",
      "2026-01-12 23:27:57 I [llm_adapter:336] - MCP ë„êµ¬ í˜¸ì¶œ ì„±ê³µ: {\"status\": \"started\", \"job_id\": \"a75e9f66-5d16-46aa-b8e7-b7dfa344f7bd\", \"message\": \"Ad generation started. Use check_generation_status to monitor progress.\"}...\n",
      "2026-01-12 23:27:57 W [llm_adapter:356] - ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜(1) ì´ˆê³¼\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:51] - ============================================================\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:52] - ë„êµ¬ í˜¸ì¶œ ê²°ê³¼\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:53] - ============================================================\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:55] - Tool Response: {\"status\": \"started\", \"job_id\": \"a75e9f66-5d16-46aa-b8e7-b7dfa344f7bd\", \"message\": \"Ad generation started. Use check_generation_status to monitor progress.\"}...\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:69] - ë„êµ¬ ì‘ë‹µ(JSON)ì—ì„œ ì¶”ì¶œëœ Job ID: a75e9f66-5d16-46aa-b8e7-b7dfa344f7bd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "async def generate_ad_with_llm():\n",
    "    \"\"\"\n",
    "    LLMAdapterë¥¼ ì‚¬ìš©í•œ ìì—°ì–´ ê´‘ê³  ìƒì„±\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"LLMAdapter ê´‘ê³  ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    # OpenAI API í‚¤ í™•ì¸\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        logger.error(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # LLMAdapter ì´ˆê¸°í™” ë° ìì—°ì–´ ìš”ì²­\n",
    "    async with LLMAdapter(\n",
    "        openai_api_key=openai_api_key,\n",
    "        mcp_server_url=MCP_SERVER_URL,\n",
    "        model=\"gpt-5-mini\",\n",
    "    ) as adapter:\n",
    "        \n",
    "        user_request = f\"\"\"\n",
    "ì‚¬ìš©ì: ë°”ë‚˜ë‚˜ íŠ¹ê°€ ê´‘ê³  ë§Œë“¤ì–´ì¤˜\n",
    "\n",
    "- product_image_path: \"{product_image_path}\"\n",
    "- save_output_path: \"{output_image_path}\"\n",
    "- text_content: \"ë§›ìˆëŠ”ë°”ë‚˜ë‚˜ 2500ì›\"\n",
    "- wait_for_completion: false\n",
    "- composition_mode: \"overlay\"\n",
    "\n",
    "ëª¨ë“  í”„ë¡¬í”„íŠ¸ëŠ” ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "        \n",
    "        logger.info(\"ìì—°ì–´ ìš”ì²­ ì „ì†¡ ì¤‘...\")\n",
    "        logger.info(f\"ìš”ì²­ ë‚´ìš©:\\n{user_request[:250]}...\")\n",
    "        \n",
    "        # max_tool_calls=1: ë„êµ¬ë§Œ í˜¸ì¶œ (LLM ì‘ë‹µ ë¶ˆí•„ìš”)\n",
    "        # ëŒ€ì‹  adapter.conversation_historyì—ì„œ ë„êµ¬ ì‘ë‹µ ì¶”ì¶œ\n",
    "        response = await adapter.chat(user_request, max_tool_calls=1)\n",
    "        \n",
    "        # ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ conversation_historyì—ì„œ ì¶”ì¶œ\n",
    "        tool_response = None\n",
    "        for msg in reversed(adapter.conversation_history):\n",
    "            if msg.get(\"role\") == \"tool\":\n",
    "                tool_response = msg.get(\"content\")\n",
    "                break\n",
    "        \n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(\"ë„êµ¬ í˜¸ì¶œ ê²°ê³¼\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        if tool_response:\n",
    "            logger.info(f\"Tool Response: {tool_response[:300]}...\")\n",
    "        else:\n",
    "            logger.warning(\"ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # LLM ì‘ë‹µ ë¬´ì‹œ (max_tool_calls=1 ì œí•œ ë©”ì‹œì§€)\n",
    "        \n",
    "        # job_id ì¶”ì¶œ ìš°ì„ ìˆœìœ„:\n",
    "        # 1. ë„êµ¬ ì‘ë‹µì—ì„œ JSON íŒŒì‹± (ìµœìš°ì„ )\n",
    "        if tool_response:\n",
    "            try:\n",
    "                # JSON íŒŒì‹± ì‹œë„\n",
    "                tool_data = json.loads(tool_response)\n",
    "                if \"job_id\" in tool_data:\n",
    "                    job_id = tool_data[\"job_id\"]\n",
    "                    logger.info(f\"ë„êµ¬ ì‘ë‹µ(JSON)ì—ì„œ ì¶”ì¶œëœ Job ID: {job_id}\")\n",
    "                    return job_id\n",
    "            except json.JSONDecodeError:\n",
    "                # UUID íŒ¨í„´ ê²€ìƒ‰\n",
    "                uuid_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'\n",
    "                matches = re.findall(uuid_pattern, tool_response, re.IGNORECASE)\n",
    "                if matches:\n",
    "                    job_id = matches[0]\n",
    "                    logger.info(f\"ë„êµ¬ ì‘ë‹µ(UUID)ì—ì„œ ì¶”ì¶œëœ Job ID: {job_id}\")\n",
    "                    return job_id\n",
    "        \n",
    "        # 2. LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹± ì‹œë„\n",
    "        try:\n",
    "            # JSON ë¸”ë¡ ì°¾ê¸° (```json ... ``` ë˜ëŠ” ì§ì ‘ JSON)\n",
    "            json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                data = json.loads(json_match.group(1))\n",
    "            else:\n",
    "                # ì§ì ‘ JSON íŒŒì‹± ì‹œë„\n",
    "                data = json.loads(response)\n",
    "            \n",
    "            if \"job_id\" in data:\n",
    "                job_id = data[\"job_id\"]\n",
    "                logger.info(f\"LLM ì‘ë‹µ(JSON)ì—ì„œ ì¶”ì¶œëœ Job ID: {job_id}\")\n",
    "                return job_id\n",
    "        except (json.JSONDecodeError, KeyError, TypeError) as e:\n",
    "            logger.debug(f\"JSON íŒŒì‹± ì‹¤íŒ¨ (ë‹¤ìŒ ë°©ë²• ì‹œë„): {e}\")\n",
    "        \n",
    "        # 3. UUID íŒ¨í„´ ê²€ìƒ‰\n",
    "        uuid_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'\n",
    "        matches = re.findall(uuid_pattern, response, re.IGNORECASE)\n",
    "        if matches:\n",
    "            job_id = matches[0]\n",
    "            logger.info(f\"UUID íŒ¨í„´ì—ì„œ ì¶”ì¶œëœ Job ID: {job_id}\")\n",
    "            return job_id\n",
    "        \n",
    "        # 4. ì‘ì—… ID ë ˆì´ë¸” íŒ¨í„´ (í•œê¸€/ì˜ë¬¸)\n",
    "        match = re.search(r'(?:ì‘ì—…|Job|Task)\\s*(?:ID|id)[:\\s]*([a-f0-9\\-]+)', response, re.IGNORECASE)\n",
    "        if match:\n",
    "            job_id = match.group(1)\n",
    "            logger.info(f\"ë ˆì´ë¸” íŒ¨í„´ì—ì„œ ì¶”ì¶œëœ Job ID: {job_id}\")\n",
    "            return job_id\n",
    "        \n",
    "        logger.warning(\"job_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        logger.info(f\"ë„êµ¬ ì‘ë‹µ:\\n{tool_response}\")\n",
    "        logger.info(f\"LLM ì‘ë‹µ:\\n{response}\")\n",
    "        return None\n",
    "\n",
    "# ì‹¤í–‰\n",
    "job_id = await generate_ad_with_llm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3af111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:27:57 I [ipykernel_launcher:5] - ============================================================\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:6] - LLMAdapter ê¸°ë³¸ í…ŒìŠ¤íŠ¸\n",
      "2026-01-12 23:27:57 I [ipykernel_launcher:7] - ============================================================\n",
      "2026-01-12 23:27:57 I [mcp_client:51] - MCPClient ì´ˆê¸°í™”: base_url=http://localhost:3000\n",
      "2026-01-12 23:27:58 I [llm_adapter:330] - MCP ë„êµ¬ í˜¸ì¶œ tool_name=check_server_health\n",
      "2026-01-12 23:27:58 I [llm_adapter:331] - MCP ë„êµ¬ í˜¸ì¶œ tool_args={}\n",
      "2026-01-12 23:27:59 I [llm_adapter:336] - MCP ë„êµ¬ í˜¸ì¶œ ì„±ê³µ: ì„œë²„ ìƒíƒœ: busy\n",
      "ì „ì²´ ì‘ì—…: 1ê°œ\n",
      "í™œì„± ì‘ì—…: 1ê°œ\n",
      "\n",
      "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤:\n",
      "  CPU: 14.0%\n",
      "  RAM: 4.4/15.6 GB (28.1%)\n",
      "  GPU 0 (NVIDIA L4): 0%, VRAM: 0.5/22.5 GB\n",
      "...\n",
      "2026-01-12 23:28:06 I [ipykernel_launcher:22] - ì„œë²„ ìƒíƒœ ì‘ë‹µ:\n",
      "ì„œë²„ ìƒíƒœ í™•ì¸ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "\n",
      "ìš”ì•½\n",
      "- ì„œë²„ ìƒíƒœ: busy\n",
      "- ì „ì²´ ì‘ì—…: 1ê°œ\n",
      "- í™œì„±(ì‹¤í–‰ ì¤‘) ì‘ì—…: 1ê°œ\n",
      "\n",
      "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤\n",
      "- CPU ì‚¬ìš©ë¥ : 14.0%\n",
      "- RAM: 4.4 / 15.6 GB (ì•½ 28.1%)\n",
      "- GPU 0 (NVIDIA L4): ì‚¬ìš©ë¥  0%, VRAM 0.5 / 22.5 GB\n",
      "\n",
      "í•´ì„ ë° ì œì•ˆ\n",
      "- ì„œë²„ëŠ” \"busy\" ìƒíƒœì´ë‚˜ í˜„ì¬ ë¦¬ì†ŒìŠ¤(CPU/RAM/GPU)ëŠ” ì—¬ìœ  ìˆëŠ” í¸ì…ë‹ˆë‹¤. í™œì„± ì‘ì—…ì´ í•˜ë‚˜ ì‹¤í–‰ ì¤‘ì´ë¼ ìƒíƒœê°€ busyë¡œ í‘œì‹œëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "- ì›í•˜ì‹œë©´ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ì˜ ìƒì„¸ ìƒíƒœ í™•ì¸(check_generation_status), ì „ì²´ ì‘ì—… ëª©ë¡ ì¡°íšŒ(get_all_jobs), ë˜ëŠ” í•´ë‹¹ ì‘ì—… ì¤‘ë‹¨(stop_generation)Â·ì‚­ì œ(delete_job) ë“±ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì–´ë–¤ ì‘ì—…ì„ ì§„í–‰í• ê¹Œìš”? (ì˜ˆ: ì „ì²´ ì‘ì—… ëª©ë¡ ë³´ê¸° / íŠ¹ì • job ìƒíƒœ í™•ì¸ â€” job_id ì•Œë ¤ì£¼ì„¸ìš” / ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì¤‘ë‹¨)\n",
      "2026-01-12 23:28:09 I [llm_adapter:330] - MCP ë„êµ¬ í˜¸ì¶œ tool_name=list_available_fonts\n",
      "2026-01-12 23:28:09 I [llm_adapter:331] - MCP ë„êµ¬ í˜¸ì¶œ tool_args={}\n",
      "2026-01-12 23:28:09 I [llm_adapter:336] - MCP ë„êµ¬ í˜¸ì¶œ ì„±ê³µ: ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ (54ê°œ):\n",
      "\n",
      "  - D2coding/D2CodingLigature/D2Coding-Ver1.3.2-20180524-ligature.ttf\n",
      "  - D2coding/D2CodingLigature/D2CodingBold-Ver1.3.2-20180524-ligature.ttf\n",
      "  - NanumSquareNeo/NanumSquareNeo/Nanu...\n",
      "2026-01-12 23:28:20 I [ipykernel_launcher:26] - í°íŠ¸ ëª©ë¡ ì‘ë‹µ:\n",
      "ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤ â€” ì´ 54ê°œ(ìœ„ì— ì „ì²´ ëª©ë¡ í‘œì‹œë¨).\n",
      "\n",
      "ë‹¤ìŒìœ¼ë¡œ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "- íŠ¹ì • í°íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ì‹œë©´ ëª©ë¡ì— ìˆëŠ” ì •í™•í•œ íŒŒì¼ëª…(ì˜ˆ: NanumSquareRoundEB.ttf)ì„ ì•Œë ¤ì£¼ì„¸ìš”. font_name íŒŒë¼ë¯¸í„°ì— ê·¸ ê²½ë¡œ/ì´ë¦„ì„ ë„£ì–´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "- ì¶”ì²œì„ ì›í•˜ì‹œë©´ ê´‘ê³  ë¬¸êµ¬(text_content)ì™€ ê´‘ê³  ìœ í˜•(ì˜ˆ: sale / premium / casual / promotion / general), ì›í•˜ëŠ” í†¤(energetic / elegant / friendly / modern...\n"
     ]
    }
   ],
   "source": [
    "async def test_llm_basic():\n",
    "    \"\"\"\n",
    "    LLMAdapter ê¸°ë³¸ í…ŒìŠ¤íŠ¸: ì„œë²„ ìƒíƒœ í™•ì¸\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"LLMAdapter ê¸°ë³¸ í…ŒìŠ¤íŠ¸\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        logger.error(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    async with LLMAdapter(\n",
    "        openai_api_key=openai_api_key,\n",
    "        mcp_server_url=MCP_SERVER_URL,\n",
    "        model=\"gpt-5-mini\",\n",
    "    ) as adapter:\n",
    "        \n",
    "        # 1. ì„œë²„ ìƒíƒœ í™•ì¸\n",
    "        response1 = await adapter.chat(\"AI ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì¤˜\")\n",
    "        logger.info(f\"ì„œë²„ ìƒíƒœ ì‘ë‹µ:\\n{response1}\")\n",
    "        \n",
    "        # 2. í°íŠ¸ ëª©ë¡ í™•ì¸\n",
    "        response2 = await adapter.chat(\"ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ëª©ë¡ì„ ì•Œë ¤ì¤˜\")\n",
    "        logger.info(f\"í°íŠ¸ ëª©ë¡ ì‘ë‹µ:\\n{response2[:300]}...\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await test_llm_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b986c8",
   "metadata": {},
   "source": [
    "## 7-1. LLMAdapter ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (ì„œë²„ ìƒíƒœ í™•ì¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eeae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-12 23:28:20 I [ipykernel_launcher:22] - ============================================================\n",
      "2026-01-12 23:28:20 I [ipykernel_launcher:23] - Step 2: ì‘ì—… ìƒíƒœ í™•ì¸ (Job ID: a75e9f66-5d16-46aa-b8e7-b7dfa344f7bd)\n",
      "2026-01-12 23:28:20 I [ipykernel_launcher:25] - ì™„ë£Œ ì‹œ ì €ì¥ ê²½ë¡œ: /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver/static/results/banana_ad_result.png\n",
      "2026-01-12 23:28:20 I [ipykernel_launcher:26] - ============================================================\n",
      "2026-01-12 23:28:20 I [mcp_client:51] - MCPClient ì´ˆê¸°í™”: base_url=http://localhost:3000\n",
      "2026-01-12 23:28:30 I [ipykernel_launcher:58] -    [1/300] status=running, progress=0%\n",
      "2026-01-12 23:28:30 I [ipykernel_launcher:69] -    ì§„í–‰ ì¤‘... (ë‹¨ê³„: step1_background)\n",
      "2026-01-12 23:28:40 I [ipykernel_launcher:58] -    [2/300] status=running, progress=0%\n",
      "2026-01-12 23:28:40 I [ipykernel_launcher:69] -    ì§„í–‰ ì¤‘... (ë‹¨ê³„: step1_background)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: ì‘ì—… ìƒíƒœ ì¡°íšŒ (í´ë§) - ì™„ë£Œ ì‹œ ì´ë¯¸ì§€ ì €ì¥ í¬í•¨\n",
    "import json\n",
    "\n",
    "async def check_ad_generation_status(\n",
    "    job_id: str, \n",
    "    save_result_path: str = None,\n",
    "    max_attempts: int = 300, \n",
    "    interval: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Job IDë¡œ ì‘ì—… ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì™„ë£Œ ì‹œ ì´ë¯¸ì§€ë¥¼ ì €ì¥\n",
    "    \n",
    "    Args:\n",
    "        job_id: í™•ì¸í•  ì‘ì—… ID\n",
    "        save_result_path: ì™„ë£Œ ì‹œ ì €ì¥í•  ì´ë¯¸ì§€ ê²½ë¡œ (ì¤‘ìš”!)\n",
    "        max_attempts: ìµœëŒ€ ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 300íšŒ)\n",
    "        interval: í™•ì¸ ê°„ê²© (ì´ˆ, ê¸°ë³¸ê°’: 10ì´ˆ)\n",
    "    \n",
    "    Returns:\n",
    "        ìµœì¢… ìƒíƒœ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(f\"Step 2: ì‘ì—… ìƒíƒœ í™•ì¸ (Job ID: {job_id})\")\n",
    "    if save_result_path:\n",
    "        logger.info(f\"ì™„ë£Œ ì‹œ ì €ì¥ ê²½ë¡œ: {save_result_path}\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        \n",
    "        attempt = 0\n",
    "        while attempt < max_attempts:\n",
    "            await asyncio.sleep(interval)\n",
    "            attempt += 1\n",
    "            \n",
    "            # ìƒíƒœ í™•ì¸ (save_result_path ì „ë‹¬!)\n",
    "            status_params = {\"job_id\": job_id}\n",
    "            if save_result_path:\n",
    "                status_params[\"save_result_path\"] = save_result_path\n",
    "            \n",
    "            status_result = await client.call_tool(\n",
    "                \"check_generation_status\",\n",
    "                status_params\n",
    "            )\n",
    "            \n",
    "            # JSON íŒŒì‹± ì‹œë„\n",
    "            try:\n",
    "                if isinstance(status_result, str):\n",
    "                    status_data = json.loads(status_result)\n",
    "                else:\n",
    "                    status_data = status_result\n",
    "                \n",
    "                status = status_data.get(\"status\")\n",
    "                progress = status_data.get(\"progress_percent\", 0)\n",
    "                \n",
    "                logger.info(f\"   [{attempt}/{max_attempts}] status={status}, progress={progress}%\")\n",
    "                \n",
    "                if status == \"completed\":\n",
    "                    logger.info(\"ì‘ì—… ì™„ë£Œ!\")\n",
    "                    if save_result_path:\n",
    "                        logger.info(f\"   ì´ë¯¸ì§€ ì €ì¥ë¨: {save_result_path}\")\n",
    "                    return status_data\n",
    "                elif status == \"failed\":\n",
    "                    logger.error(f\"ì‘ì—… ì‹¤íŒ¨: {status_data.get('message')}\")\n",
    "                    return status_data\n",
    "                else:\n",
    "                    logger.info(f\"   ì§„í–‰ ì¤‘... (ë‹¨ê³„: {status_data.get('current_step')})\")\n",
    "                    \n",
    "            except (json.JSONDecodeError, AttributeError) as e:\n",
    "                # Fallback: ë¬¸ìì—´ ì‘ë‹µ ì²˜ë¦¬\n",
    "                logger.debug(f\"JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ë¶„ì„: {e}\")\n",
    "                logger.info(f\"   [{attempt}/{max_attempts}] ìƒíƒœ: {status_result}\")\n",
    "                \n",
    "                if isinstance(status_result, dict):\n",
    "                    status = status_result.get(\"status\")\n",
    "                    progress = status_result.get(\"progress\", 0)\n",
    "                    \n",
    "                    if status == \"completed\":\n",
    "                        logger.info(\"ì‘ì—… ì™„ë£Œ!\")\n",
    "                        if save_result_path:\n",
    "                            logger.info(f\"   ì´ë¯¸ì§€ ì €ì¥ë¨: {save_result_path}\")\n",
    "                        return status_result\n",
    "                    elif status == \"failed\":\n",
    "                        logger.error(f\"ì‘ì—… ì‹¤íŒ¨: {status_result.get('error')}\")\n",
    "                        return status_result\n",
    "                else:\n",
    "                    # ë¬¸ìì—´ ê²€ìƒ‰\n",
    "                    if \"completed\" in str(status_result).lower():\n",
    "                        logger.info(\"ì‘ì—… ì™„ë£Œ!\")\n",
    "                        if save_result_path:\n",
    "                            logger.info(f\"   ì´ë¯¸ì§€ ì €ì¥ë¨: {save_result_path}\")\n",
    "                        return status_result\n",
    "                    elif \"failed\" in str(status_result).lower():\n",
    "                        logger.error(f\"ì‘ì—… ì‹¤íŒ¨: {status_result}\")\n",
    "                        return status_result\n",
    "        \n",
    "        logger.warning(f\"â° íƒ€ì„ì•„ì›ƒ: {max_attempts * interval}ì´ˆ ë™ì•ˆ ì‘ì—…ì´ ì™„ë£Œë˜ì§€ ì•ŠìŒ\")\n",
    "        return {\"status\": \"timeout\", \"message\": \"ì‘ì—…ì´ ì œí•œ ì‹œê°„ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"}\n",
    "        \n",
    "\n",
    "# ì‹¤í–‰ (job_idë¥¼ ì• ì…€ì—ì„œ ë°›ì•„ì•¼ í•¨)\n",
    "if 'job_id' in dir() and job_id:\n",
    "    status_result = await check_ad_generation_status(\n",
    "        job_id, \n",
    "        save_result_path=str(output_image_path)\n",
    "    )\n",
    "else:\n",
    "    logger.warning(\"job_idê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ì „ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d25f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Step 3: ê²°ê³¼ í™•ì¸ ë° ì¶œë ¥\n",
    "def display_ad_result():\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ ê´‘ê³  ì´ë¯¸ì§€ í™•ì¸ ë° í‘œì‹œ\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"Step 3: ê²°ê³¼ í™•ì¸ ë° ì¶œë ¥\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    if output_image_path.exists():\n",
    "        file_size = output_image_path.stat().st_size\n",
    "        logger.info(f\"ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!\")\n",
    "        logger.info(f\"   ê²½ë¡œ: {output_image_path}\")\n",
    "        logger.info(f\"   í¬ê¸°: {file_size:,} bytes ({file_size / 1024:.1f} KB)\")\n",
    "        logger.info(\"ì´ë¯¸ì§€ í‘œì‹œ:\")\n",
    "        display(Image(filename=str(output_image_path)))\n",
    "        \n",
    "    else:\n",
    "        logger.error(f\"ì¶œë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {output_image_path}\")\n",
    "        logger.info(\"í™•ì¸ì‚¬í•­:\")\n",
    "        logger.info(f\"   1. ì‘ì—…ì´ ì •ìƒ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "        logger.info(f\"   2. ê²°ê³¼ ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {RESULTS_DIR.exists()}\")\n",
    "        if RESULTS_DIR.exists():\n",
    "            files = list(RESULTS_DIR.glob(\"*\"))\n",
    "            logger.info(f\"   3. ê²°ê³¼ ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡:\")\n",
    "            for f in files:\n",
    "                logger.info(f\"      - {f.name} ({f.stat().st_size:,} bytes)\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "display_ad_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3faf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_llm_font_recommendation():\n",
    "    \"\"\"\n",
    "    LLMAdapterë¥¼ í†µí•œ í°íŠ¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"LLMAdapter í°íŠ¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    \n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        logger.error(\"OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    async with LLMAdapter(\n",
    "        openai_api_key=openai_api_key,\n",
    "        mcp_server_url=MCP_SERVER_URL,\n",
    "        model=\"gpt-4o\",\n",
    "    ) as adapter:\n",
    "        \n",
    "        test_cases = [\n",
    "            \"50% í• ì¸ ì„¸ì¼ ê´‘ê³ ì— ì–´ìš¸ë¦¬ëŠ” êµµì€ í°íŠ¸ ì¶”ì²œí•´ì¤˜\",\n",
    "            \"ëª…í’ˆ í”„ë¦¬ë¯¸ì—„ ê´‘ê³ ì— ìš°ì•„í•œ í°íŠ¸ ì¶”ì²œí•´ì¤˜\",\n",
    "            \"ì¹œê·¼í•œ ìºì£¼ì–¼ ê´‘ê³ ì— ì†ê¸€ì”¨ ëŠë‚Œ í°íŠ¸ ì¶”ì²œí•´ì¤˜\"\n",
    "        ]\n",
    "        \n",
    "        for i, request in enumerate(test_cases, 1):\n",
    "            logger.info(f\"\\n[í…ŒìŠ¤íŠ¸ {i}] {request}\")\n",
    "            response = await adapter.chat(request)\n",
    "            logger.info(f\"ì‘ë‹µ:\\n{response}\\n\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await test_llm_font_recommendation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741dfa5",
   "metadata": {},
   "source": [
    "## 8. LLMAdapterë¥¼ í†µí•œ í°íŠ¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸: ì„œë²„ ìƒíƒœ í™•ì¸\n",
    "async def quick_test():\n",
    "    \"\"\"MCP ì„œë²„ ì—°ê²° ë° ìƒíƒœ í™•ì¸\"\"\"\n",
    "    logger.info(\"=== ë¹ ë¥¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ===\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        # ì„œë²„ ìƒíƒœ í™•ì¸\n",
    "        health = await client.call_tool(\"check_server_health\", {})\n",
    "        logger.info(f\"ì„œë²„ ìƒíƒœ:\\n{health}\")\n",
    "        \n",
    "        # í°íŠ¸ ëª©ë¡ í™•ì¸\n",
    "        fonts = await client.call_tool(\"list_available_fonts\", {})\n",
    "        logger.info(f\"ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸:\\n{fonts}\")\n",
    "        \n",
    "    logger.info(\"=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\")\n",
    "\n",
    "await quick_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29c650",
   "metadata": {},
   "source": [
    "## í°íŠ¸ ìë™ ì„ íƒ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774414be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í°íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ\n",
    "async def test_font_metadata():\n",
    "    \"\"\"í°íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    logger.info(\"=== í°íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ===\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        # í°íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ\n",
    "        metadata = await client.call_tool(\"get_fonts_metadata\", {})\n",
    "        logger.info(f\"í°íŠ¸ ë©”íƒ€ë°ì´í„°:\\n{metadata[:500]}...\")  # ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "    \n",
    "    logger.info(\"=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\")\n",
    "\n",
    "await test_font_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd157ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë²„ì— ë“±ë¡ëœ íˆ´ ëª©ë¡ í™•ì¸\n",
    "async def check_available_tools():\n",
    "    \"\"\"MCP ì„œë²„ì— ë“±ë¡ëœ íˆ´ ëª©ë¡ í™•ì¸\"\"\"\n",
    "    logger.info(\"=== ì„œë²„ ë“±ë¡ íˆ´ í™•ì¸ ===\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        # httpxë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ /tools ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ\n",
    "        response = await client._client.get(f\"{MCP_SERVER_URL}/tools\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        tools = data.get(\"tools\", [])\n",
    "        logger.info(f\"ë“±ë¡ëœ íˆ´ ê°œìˆ˜: {len(tools)}\")\n",
    "        logger.info(\"íˆ´ ëª©ë¡:\")\n",
    "        for tool in tools:\n",
    "            logger.info(f\"  - {tool['name']}: {tool['description'][:80]}...\")\n",
    "    \n",
    "    logger.info(\"=== í™•ì¸ ì™„ë£Œ ===\")\n",
    "\n",
    "await check_available_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ì„¸ì¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ\n",
    "async def test_font_recommendation_sale():\n",
    "    \"\"\"ì„¸ì¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    logger.info(\"=== ì„¸ì¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ ===\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        # í•œê¸€ ì„¸ì¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ\n",
    "        result = await client.call_tool(\"recommend_font_for_ad\", {\n",
    "            \"text_content\": \"50% í• ì¸\",\n",
    "            \"ad_type\": \"sale\",\n",
    "            \"weight_preference\": \"bold\"\n",
    "        })\n",
    "        logger.info(f\"ì¶”ì²œ ê²°ê³¼:\\n{result}\")\n",
    "    \n",
    "    logger.info(\"=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\")\n",
    "\n",
    "await test_font_recommendation_sale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c67bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. í”„ë¦¬ë¯¸ì—„ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ\n",
    "async def test_font_recommendation_premium():\n",
    "    \"\"\"í”„ë¦¬ë¯¸ì—„ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    logger.info(\"=== í”„ë¦¬ë¯¸ì—„ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ ===\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        # í•œê¸€ í”„ë¦¬ë¯¸ì—„ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ\n",
    "        result = await client.call_tool(\"recommend_font_for_ad\", {\n",
    "            \"text_content\": \"ëª…í’ˆ í•œì •íŒ\",\n",
    "            \"ad_type\": \"premium\",\n",
    "            \"tone\": \"elegant\"\n",
    "        })\n",
    "        logger.info(f\"ì¶”ì²œ ê²°ê³¼:\\n{result}\")\n",
    "    \n",
    "    logger.info(\"=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\")\n",
    "\n",
    "await test_font_recommendation_premium()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ìºì£¼ì–¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ\n",
    "async def test_font_recommendation_casual():\n",
    "    \"\"\"ìºì£¼ì–¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    logger.info(\"=== ìºì£¼ì–¼ ê´‘ê³ ìš© í°íŠ¸ ì¶”ì²œ ===\")\n",
    "    \n",
    "    async with MCPClient(\n",
    "        base_url=MCP_SERVER_URL,\n",
    "        timeout=30\n",
    "    ) as client:\n",
    "        # ì†ê¸€ì”¨ ìŠ¤íƒ€ì¼ í°íŠ¸ ì¶”ì²œ\n",
    "        result = await client.call_tool(\"recommend_font_for_ad\", {\n",
    "            \"text_content\": \"ì¹œêµ¬ì•¼ ë†€ëŸ¬ì™€\",\n",
    "            \"ad_type\": \"casual\",\n",
    "            \"tone\": \"friendly\"\n",
    "        })\n",
    "        logger.info(f\"ì¶”ì²œ ê²°ê³¼:\\n{result}\")\n",
    "    \n",
    "    logger.info(\"=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===\")\n",
    "\n",
    "await test_font_recommendation_casual()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

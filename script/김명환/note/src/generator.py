"""
ë°°ê²½ ìƒì„± ëª¨ë“ˆ: FLUX.1-devë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹¨ë—í•œ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
Background Generation Module: Create clean backgrounds using FLUX.1-dev
"""

import torch
from PIL import Image
from diffusers import FluxPipeline, PipelineQuantizationConfig, BitsAndBytesConfig
from typing import Optional
import logging

# Try to import helper_dev_utils, fallback to standard logging if not available
try:
    from helper_dev_utils import get_auto_logger
    logger = get_auto_logger()
except ImportError:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

from .utils import flush_gpu


class BackgroundGenerator:
    """
    FLUX.1-devë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì²´ê°€ ì—†ëŠ” ê¹¨ë—í•œ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤

    ì´ í´ë˜ìŠ¤ëŠ” ë‚˜ì¤‘ì— ê°ì²´ í•©ì„±ì— ì‚¬ìš©ë  ë¶„ìœ„ê¸° ìˆëŠ” ë°°ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    í”„ë¡¬í”„íŠ¸ëŠ” íŠ¹ì • ê°ì²´ë³´ë‹¤ëŠ” ë¶„ìœ„ê¸°, ì¡°ëª…, í™˜ê²½ì— ì´ˆì ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤.

    Attributes:
        model_name (str): ì‚¬ìš©í•  HuggingFace ëª¨ë¸ ì´ë¦„
        device (str): ëª¨ë¸ì„ ì‹¤í–‰í•  ë””ë°”ì´ìŠ¤
        torch_dtype: ëª¨ë¸ ê°€ì¤‘ì¹˜ì˜ ë°ì´í„° íƒ€ì… (FLUXëŠ” bfloat16 ê¶Œì¥)
        pipe: FLUX íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤
    """

    def __init__(
        self,
        model_name: str = "black-forest-labs/FLUX.1-dev",
        device: str = None,
        torch_dtype: torch.dtype = torch.bfloat16,
    ):
        """
        BackgroundGenerator ì´ˆê¸°í™”

        Args:
            model_name: HuggingFace ëª¨ë¸ ì‹ë³„ì (ê¸°ë³¸ê°’: FLUX.1-dev)
            device: ëª¨ë¸ ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', ê¸°ë³¸ê°’: ìë™ ê°ì§€)
            torch_dtype: ëª¨ë¸ ê°€ì¤‘ì¹˜ ë°ì´í„° íƒ€ì… (FLUXëŠ” bfloat16 ê¶Œì¥)
        """
        self.model_name = model_name
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.torch_dtype = torch_dtype
        self.pipe = None  # ì§€ì—° ë¡œë”© (í•„ìš”í•  ë•Œë§Œ ë¡œë“œ)

        print(f"ğŸ”§ BackgroundGenerator ì´ˆê¸°í™”: {model_name}")

    def _load_model(self):
        """FLUX.1-dev íŒŒì´í”„ë¼ì¸ì„ ë””ë°”ì´ìŠ¤ì— ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.pipe is None:
            print(f"  FLUX.1-dev íŒŒì´í”„ë¼ì¸ì„ {self.device}ì— ë¡œë“œ ì¤‘...")

            # L4 GPUë¥¼ ìœ„í•œ 8bit ì–‘ìí™” ì„¤ì •
            # BitsAndBytesConfigë¥¼ PipelineQuantizationConfigë¡œ ë˜í•‘
            bnb_config = BitsAndBytesConfig(
                load_in_8bit=True,
            )

            quantization_config = PipelineQuantizationConfig(
                quant_backend="bitsandbytes_8bit",
                quant_kwargs={
                    "load_in_8bit": True,
                },
            )

            # HuggingFaceì—ì„œ ì‚¬ì „í•™ìŠµëœ FLUX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
            # ì–‘ìí™” ì²˜ë¦¬ ì‹œ ìë™ìœ¼ë¡œ GPUë¡œ ì´ë™
            self.pipe = FluxPipeline.from_pretrained(
                self.model_name,
                torch_dtype=self.torch_dtype,  # bfloat16ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
                quantization_config=quantization_config,  # 8bit ì–‘ìí™”
            )

            # ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜ í™œì„±í™”
            if self.device == "cuda":
                # CPU ì˜¤í”„ë¡œë”©: ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»´í¬ë„ŒíŠ¸ë¥¼ ìë™ìœ¼ë¡œ CPUë¡œ ì´ë™
                self.pipe.enable_model_cpu_offload()
                # ì°¸ê³ : enable_attention_slicing()ì€ VRAM ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ì§€ë§Œ
                # ìƒì„± ì†ë„ê°€ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤
                # self.pipe.enable_attention_slicing()

            print(f"  âœ“ FLUX.1-dev íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ (8bit ì–‘ìí™”)")

    def _unload_model(self):
        """VRAM í™•ë³´ë¥¼ ìœ„í•´ íŒŒì´í”„ë¼ì¸ì„ ì–¸ë¡œë“œí•©ë‹ˆë‹¤."""
        if self.pipe is not None:
            print("  FLUX.1-dev íŒŒì´í”„ë¼ì¸ ì–¸ë¡œë“œ ì¤‘...")
            # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ CPUë¡œ ì´ë™
            if hasattr(self.pipe, "to"):
                self.pipe.to("cpu")
            del self.pipe
            self.pipe = None
            flush_gpu()  # GPU ìºì‹œ ì •ë¦¬

    def generate_background(
        self,
        prompt: str,
        width: int = 1024,
        height: int = 1024,
        num_inference_steps: int = 28,
        guidance_scale: float = 3.5,
        seed: Optional[int] = None,
    ) -> Image.Image:
        """
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            prompt: ì›í•˜ëŠ” ë°°ê²½ì˜ í…ìŠ¤íŠ¸ ì„¤ëª…
                   (ë¶„ìœ„ê¸°, ì¡°ëª…, í™˜ê²½ì— ì´ˆì ì„ ë§ì¶”ê³  ê°ì²´ ë¬˜ì‚¬ëŠ” ìµœì†Œí™”)
            width: ì¶œë ¥ ì´ë¯¸ì§€ ë„ˆë¹„ (ê¸°ë³¸ê°’: 1024)
            height: ì¶œë ¥ ì´ë¯¸ì§€ ë†’ì´ (ê¸°ë³¸ê°’: 1024)
            num_inference_steps: ë””ë…¸ì´ì§• ìŠ¤í… ìˆ˜ (ê¸°ë³¸ê°’: 28, ë†’ì„ìˆ˜ë¡ í’ˆì§ˆâ†‘ ì†ë„â†“)
            guidance_scale: CFG ìŠ¤ì¼€ì¼ (ê¸°ë³¸ê°’: 3.5, ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ ì¶©ì‹¤ë„â†‘)
            seed: ì¬í˜„ ê°€ëŠ¥ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ (Noneì´ë©´ ëœë¤)

        Returns:
            ìƒì„±ëœ ë°°ê²½ ì´ë¯¸ì§€ (PIL.Image)

        Example:
            >>> generator = BackgroundGenerator()
            >>> bg = generator.generate_background(
            ...     "ì•„ëŠ‘í•œ ë°”ì˜ ë‚˜ë¬´ í…Œì´ë¸”, ë”°ëœ»í•œ ì¡°ëª…, "
            ...     "ì¤‘ì•™ì— ë¹ˆ ê³µê°„, ì–•ì€ í”¼ì‚¬ê³„ ì‹¬ë„",
            ...     seed=42
            ... )
        """
        try:
            # ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
            self._load_model()

            # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
            if seed is not None:
                generator = torch.Generator(device=self.device).manual_seed(seed)
            else:
                generator = None

            print(f"  ë°°ê²½ ìƒì„± ì¤‘ ({width}x{height})...")
            print(f"  í”„ë¡¬í”„íŠ¸: {prompt[:80]}...")

            # ì´ë¯¸ì§€ ìƒì„±
            output = self.pipe(
                prompt=prompt,
                width=width,
                height=height,
                num_inference_steps=num_inference_steps,  # ë””ë…¸ì´ì§• ë°˜ë³µ íšŸìˆ˜
                guidance_scale=guidance_scale,  # í”„ë¡¬í”„íŠ¸ ê°€ì´ë˜ìŠ¤ ê°•ë„
                generator=generator,  # ì‹œë“œ ì œì–´
            )

            image = output.images[0]
            print(f"  âœ“ ë°°ê²½ ìƒì„± ì™„ë£Œ")

            return image

        finally:
            # VRAM í™•ë³´ë¥¼ ìœ„í•´ í•­ìƒ ëª¨ë¸ ì–¸ë¡œë“œ
            self._unload_model()

    def __del__(self):
        """ê°ì²´ ì†Œë©¸ ì‹œ ì •ë¦¬ ì‘ì—…"""
        self._unload_model()

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ad-Gen-Pipeline Validation Notebook\n",
    "\n",
    "This notebook validates each step of the advertisement image generation pipeline:\n",
    "1. **Object Matting**: Remove background from product image\n",
    "2. **Background Generation**: Create atmospheric background\n",
    "3. **Spatial Analysis**: Find optimal placement location\n",
    "4. **Object Synthesis**: Blend object into background with natural lighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-06 10:55:23 W [helper_utils_colab:211] - GoogleDrive not found, falling back to temp folder: /tmp\n",
      "2026-01-06 10:55:23 W [helper_utils_colab:122] - Cache directory not found, falling back to temp folder: /tmp\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from helper_dev_utils import get_auto_logger\n",
    "logger = get_auto_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda (NVIDIA L4)\n",
      "  ÏÇ¨Ïö© Í∞ÄÎä• VRAM: 22.03 GB\n",
      "  GPU Î©îÎ™®Î¶¨ - Ìï†ÎãπÎê®: 0.00 GB, ÏòàÏïΩÎê®: 0.00 GB\n",
      "2026-01-06 10:55:34 D [ipykernel_launcher:45] - \n",
      "‚úÖ Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Import our modules\n",
    "from src import (\n",
    "    flush_gpu,\n",
    "    load_image,\n",
    "    save_image,\n",
    "    ObjectMatting,\n",
    "    BackgroundGenerator,\n",
    "    SpatialAnalyzer,\n",
    "    ObjectSynthesizer\n",
    ")\n",
    "from src.utils import get_device, print_gpu_memory\n",
    "\n",
    "# Check GPU availability\n",
    "device = get_device()\n",
    "print_gpu_memory()\n",
    "\n",
    "# Helper function to display images\n",
    "def show_images(images, titles=None, figsize=(15, 5)):\n",
    "    \"\"\"Display multiple images side by side.\"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (img, ax) in enumerate(zip(images, axes)):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "logger.debug(\"\\n‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Input Data Definition (User Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-06 10:55:34 D [ipykernel_launcher:42] - üìã Configuration:\n",
      "   Input: ../image.png\n",
      "   Output: ../outputs\n",
      "   Image size: (1024, 1024)\n",
      "   Seed: 42\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PROMPT_SCENARIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Image size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIMAGE_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Seed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEED\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müí≠ Scenario: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mPROMPT_SCENARIO\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'PROMPT_SCENARIO' is not defined"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# USER CONFIGURATION: Modify these parameters\n",
    "# ==================================================\n",
    "\n",
    "# Input product image path\n",
    "INPUT_IMAGE_PATH = \"../image.png\"  # Replace with your product image\n",
    "\n",
    "# Scenario: 20s K-pop style couple drinking beer at a bar table\n",
    "PROMPT_SCENARIO = (\n",
    "    \"A photorealistic shot of a K-pop style couple in their early 20s \"\n",
    "    \"drinking beer at a bar table, soft ambient lighting, \"\n",
    "    \"cinematic atmosphere, shallow depth of field, warm tones\"\n",
    ")\n",
    "\n",
    "# Background-specific prompt (remove product mentions)\n",
    "PROMPT_BACKGROUND = (\n",
    "    \"A wooden table in a cozy bar with soft warm lighting, \"\n",
    "    \"empty space in center for product placement, \"\n",
    "    \"blurred background with bokeh effect, \"\n",
    "    \"shallow depth of field, cinematic atmosphere\"\n",
    ")\n",
    "\n",
    "# Spatial query for object placement\n",
    "SPATIAL_QUERY = (\n",
    "    \"Find the flat surface on the table center where I can place a beer bottle. \"\n",
    "    \"Return the bounding box coordinates.\"\n",
    ")\n",
    "\n",
    "# Generation parameters\n",
    "IMAGE_SIZE = (1024, 1024)  # (width, height)\n",
    "SEED = 42  # For reproducibility\n",
    "IP_ADAPTER_SCALE = 0.8  # 0.7=natural, 1.0=preserve original\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(\"../outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "logger.debug(\"üìã Configuration:\")\n",
    "print(f\"   Input: {INPUT_IMAGE_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Image size: {IMAGE_SIZE}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "print(f\"\\nüí≠ Scenario: {PROMPT_SCENARIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Step 1 - Object Matting (Background Removal)\n",
    "\n",
    "Remove the background from the product image to create a clean reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"üîÑ Step 1: Object Matting (Background Removal)\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Load original image\n",
    "original_image = load_image(INPUT_IMAGE_PATH)\n",
    "print(f\"\\nOriginal image loaded: {original_image.size}\")\n",
    "\n",
    "# Initialize ObjectMatting\n",
    "matting = ObjectMatting()\n",
    "\n",
    "# Remove background\n",
    "clean_ref_image = matting.remove_background(\n",
    "    INPUT_IMAGE_PATH,\n",
    "    return_rgba=True\n",
    ")\n",
    "\n",
    "# Save result\n",
    "output_path = OUTPUT_DIR / \"step1_clean_reference.png\"\n",
    "save_image(clean_ref_image, output_path)\n",
    "\n",
    "# Display results\n",
    "logger.debug(\"\\nüìä Validation Point: Is the background cleanly removed?\")\n",
    "show_images(\n",
    "    [original_image, clean_ref_image],\n",
    "    titles=[\"Original Product\", \"Background Removed (RGBA)\"],\n",
    "    figsize=(12, 6)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del matting\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\n‚úÖ Step 1 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Step 2 - Background Generation\n",
    "\n",
    "Generate an atmospheric background without the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"üîÑ Step 2: Background Generation\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Initialize BackgroundGenerator\n",
    "bg_generator = BackgroundGenerator()\n",
    "\n",
    "# Generate background\n",
    "bg_image = bg_generator.generate_background(\n",
    "    prompt=PROMPT_BACKGROUND,\n",
    "    width=IMAGE_SIZE[0],\n",
    "    height=IMAGE_SIZE[1],\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=3.5,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Save result\n",
    "output_path = OUTPUT_DIR / \"step2_background.png\"\n",
    "save_image(bg_image, output_path)\n",
    "\n",
    "# Display result\n",
    "logger.debug(\"\\nüìä Validation Point: Does the background have space for object placement?\")\n",
    "show_images(\n",
    "    [bg_image],\n",
    "    titles=[\"Generated Background\"],\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del bg_generator\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\n‚úÖ Step 2 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Step 3 - Spatial Analysis (Object Placement)\n",
    "\n",
    "Analyze the background to find the optimal location for object placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"üîÑ Step 3: Spatial Analysis (Object Placement)\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Initialize SpatialAnalyzer\n",
    "analyzer = SpatialAnalyzer()\n",
    "\n",
    "# Detect optimal surface\n",
    "detection_result = analyzer.detect_surface(\n",
    "    image=bg_image,\n",
    "    query=SPATIAL_QUERY\n",
    ")\n",
    "\n",
    "bbox = detection_result['bbox']\n",
    "print(f\"\\nüìç Detected bounding box: {bbox}\")\n",
    "print(f\"   Model response: {detection_result['text'][:150]}...\")\n",
    "\n",
    "# Create mask\n",
    "mask_image = analyzer.create_mask(\n",
    "    image_size=detection_result['image_size'],\n",
    "    bbox=bbox\n",
    ")\n",
    "\n",
    "# Save mask\n",
    "output_path = OUTPUT_DIR / \"step3_mask.png\"\n",
    "save_image(mask_image, output_path)\n",
    "\n",
    "# Visualize bbox on background\n",
    "bg_with_bbox = analyzer.visualize_bbox(\n",
    "    image=bg_image,\n",
    "    bbox=bbox,\n",
    "    color='red',\n",
    "    width=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "logger.debug(\"\\nüìä Validation Point: Is the mask positioned appropriately?\")\n",
    "show_images(\n",
    "    [bg_image, bg_with_bbox, mask_image],\n",
    "    titles=[\"Background\", \"With BBox\", \"Binary Mask\"],\n",
    "    figsize=(18, 6)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del analyzer\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\n‚úÖ Step 3 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Step 4 - Object Synthesis (Final Composition)\n",
    "\n",
    "Synthesize the clean object into the background with natural lighting and shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"üîÑ Step 4: Object Synthesis (Final Composition)\\n\")\n",
    "logger.debug(\"=\" * 60)\n",
    "\n",
    "# Initialize ObjectSynthesizer\n",
    "synthesizer = ObjectSynthesizer()\n",
    "\n",
    "# Synthesize object into background\n",
    "final_image = synthesizer.fill_in_object(\n",
    "    background=bg_image,\n",
    "    mask=mask_image,\n",
    "    reference=clean_ref_image,\n",
    "    prompt=PROMPT_SCENARIO,\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=3.5,\n",
    "    ip_adapter_scale=IP_ADAPTER_SCALE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Save final result\n",
    "output_path = OUTPUT_DIR / \"step4_final_result.png\"\n",
    "save_image(final_image, output_path)\n",
    "\n",
    "# Display final comparison\n",
    "logger.debug(\"\\nüìä Validation Point: Is the object naturally blended with proper lighting/shadows?\")\n",
    "show_images(\n",
    "    [clean_ref_image, bg_image, mask_image, final_image],\n",
    "    titles=[\"Clean Reference\", \"Background\", \"Mask\", \"Final Result\"],\n",
    "    figsize=(20, 5)\n",
    ")\n",
    "\n",
    "# Show before/after comparison\n",
    "logger.debug(\"\\nüîç Before/After Comparison:\")\n",
    "show_images(\n",
    "    [bg_image, final_image],\n",
    "    titles=[\"Background Only\", \"With Product\"],\n",
    "    figsize=(16, 8)\n",
    ")\n",
    "\n",
    "# Memory cleanup\n",
    "del synthesizer\n",
    "flush_gpu()\n",
    "print_gpu_memory()\n",
    "logger.debug(\"\\n‚úÖ Step 4 complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Full Pipeline Integration\n",
    "\n",
    "Run the entire pipeline end-to-end in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(\n",
    "    input_image_path,\n",
    "    prompt_scenario,\n",
    "    prompt_background,\n",
    "    spatial_query,\n",
    "    image_size=(1024, 1024),\n",
    "    ip_adapter_scale=0.8,\n",
    "    seed=None,\n",
    "    output_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Execute the complete Ad-Gen-Pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all intermediate and final images\n",
    "    \"\"\"\n",
    "    logger.debug(\"üöÄ Starting Full Pipeline Execution\\n\")\n",
    "    logger.debug(\"=\" * 70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Setup output directory\n",
    "    if output_dir is None:\n",
    "        output_dir = Path(\"../outputs/pipeline_run\")\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ============================================\n",
    "    # Step 1: Object Matting\n",
    "    # ============================================\n",
    "    logger.debug(\"\\n[1/4] Object Matting...\")\n",
    "    matting = ObjectMatting()\n",
    "    clean_ref = matting.remove_background(input_image_path, return_rgba=True)\n",
    "    save_image(clean_ref, output_dir / \"1_clean_reference.png\")\n",
    "    results['clean_reference'] = clean_ref\n",
    "    del matting\n",
    "    flush_gpu()\n",
    "    \n",
    "    # ============================================\n",
    "    # Step 2: Background Generation\n",
    "    # ============================================\n",
    "    logger.debug(\"\\n[2/4] Background Generation...\")\n",
    "    bg_gen = BackgroundGenerator()\n",
    "    background = bg_gen.generate_background(\n",
    "        prompt=prompt_background,\n",
    "        width=image_size[0],\n",
    "        height=image_size[1],\n",
    "        seed=seed\n",
    "    )\n",
    "    save_image(background, output_dir / \"2_background.png\")\n",
    "    results['background'] = background\n",
    "    del bg_gen\n",
    "    flush_gpu()\n",
    "    \n",
    "    # ============================================\n",
    "    # Step 3: Spatial Analysis\n",
    "    # ============================================\n",
    "    logger.debug(\"\\n[3/4] Spatial Analysis...\")\n",
    "    analyzer = SpatialAnalyzer()\n",
    "    detection = analyzer.detect_surface(background, spatial_query)\n",
    "    mask = analyzer.create_mask(detection['image_size'], detection['bbox'])\n",
    "    save_image(mask, output_dir / \"3_mask.png\")\n",
    "    results['mask'] = mask\n",
    "    results['bbox'] = detection['bbox']\n",
    "    del analyzer\n",
    "    flush_gpu()\n",
    "    \n",
    "    # ============================================\n",
    "    # Step 4: Object Synthesis\n",
    "    # ============================================\n",
    "    logger.debug(\"\\n[4/4] Object Synthesis...\")\n",
    "    synthesizer = ObjectSynthesizer()\n",
    "    final = synthesizer.fill_in_object(\n",
    "        background=background,\n",
    "        mask=mask,\n",
    "        reference=clean_ref,\n",
    "        prompt=prompt_scenario,\n",
    "        ip_adapter_scale=ip_adapter_scale,\n",
    "        seed=seed\n",
    "    )\n",
    "    save_image(final, output_dir / \"4_final_result.png\")\n",
    "    results['final'] = final\n",
    "    del synthesizer\n",
    "    flush_gpu()\n",
    "    \n",
    "    logger.debug(\"\\n\" + \"=\" * 70)\n",
    "    logger.debug(\"‚úÖ Pipeline Execution Complete!\")\n",
    "    print(f\"   Results saved to: {output_dir}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Execute Full Pipeline\n",
    "# ============================================\n",
    "\n",
    "pipeline_results = run_full_pipeline(\n",
    "    input_image_path=INPUT_IMAGE_PATH,\n",
    "    prompt_scenario=PROMPT_SCENARIO,\n",
    "    prompt_background=PROMPT_BACKGROUND,\n",
    "    spatial_query=SPATIAL_QUERY,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    ip_adapter_scale=IP_ADAPTER_SCALE,\n",
    "    seed=SEED,\n",
    "    output_dir=OUTPUT_DIR / \"full_pipeline\"\n",
    ")\n",
    "\n",
    "# Display all results\n",
    "logger.debug(\"\\nüé® Pipeline Results:\")\n",
    "show_images(\n",
    "    [\n",
    "        load_image(INPUT_IMAGE_PATH),\n",
    "        pipeline_results['clean_reference'],\n",
    "        pipeline_results['background'],\n",
    "        pipeline_results['mask'],\n",
    "        pipeline_results['final']\n",
    "    ],\n",
    "    titles=[\"Original\", \"Clean Ref\", \"Background\", \"Mask\", \"Final Result\"],\n",
    "    figsize=(25, 5)\n",
    ")\n",
    "\n",
    "logger.debug(\"\\nüéâ All validations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Parameter Tuning Experiments\n",
    "\n",
    "Test different IP-Adapter scales to find the optimal balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different IP-Adapter scales\n",
    "logger.debug(\"üß™ IP-Adapter Scale Comparison Experiment\\n\")\n",
    "\n",
    "scales_to_test = [0.6, 0.8, 1.0]\n",
    "comparison_results = []\n",
    "\n",
    "synthesizer = ObjectSynthesizer()\n",
    "\n",
    "for scale in scales_to_test:\n",
    "    print(f\"\\nTesting IP-Adapter scale: {scale}\")\n",
    "    \n",
    "    result = synthesizer.fill_in_object(\n",
    "        background=bg_image,\n",
    "        mask=mask_image,\n",
    "        reference=clean_ref_image,\n",
    "        prompt=PROMPT_SCENARIO,\n",
    "        ip_adapter_scale=scale,\n",
    "        seed=SEED\n",
    "    )\n",
    "    \n",
    "    comparison_results.append(result)\n",
    "    save_image(result, OUTPUT_DIR / f\"comparison_scale_{scale}.png\")\n",
    "\n",
    "del synthesizer\n",
    "flush_gpu()\n",
    "\n",
    "# Display comparison\n",
    "logger.debug(\"\\nüìä Comparison: Different IP-Adapter Scales\")\n",
    "show_images(\n",
    "    comparison_results,\n",
    "    titles=[f\"Scale {s} ({'Natural' if s == 0.6 else 'Balanced' if s == 0.8 else 'Preserve'})\" \n",
    "            for s in scales_to_test],\n",
    "    figsize=(18, 6)\n",
    ")\n",
    "\n",
    "logger.debug(\"\\nüí° Recommendation:\")\n",
    "logger.debug(\"   ‚Ä¢ Scale 0.6-0.7: More natural blending, less original preservation\")\n",
    "logger.debug(\"   ‚Ä¢ Scale 0.8: Good balance (recommended)\")\n",
    "logger.debug(\"   ‚Ä¢ Scale 1.0: Maximum original preservation, may look less natural\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Pipeline Steps:\n",
    "1. ‚úÖ **Object Matting**: Clean background removal with BiRefNet\n",
    "2. ‚úÖ **Background Generation**: Atmospheric scene creation with FLUX.1-dev\n",
    "3. ‚úÖ **Spatial Analysis**: Optimal placement detection with Qwen2-VL\n",
    "4. ‚úÖ **Object Synthesis**: Natural blending with FLUX.1-Fill + IP-Adapter\n",
    "\n",
    "### Key Features:\n",
    "- **VRAM Management**: Automatic model loading/unloading between steps\n",
    "- **Modular Design**: Each step can be validated independently\n",
    "- **Reproducibility**: Seed-based generation for consistent results\n",
    "- **Flexibility**: Adjustable IP-Adapter scale for different use cases\n",
    "\n",
    "### Next Steps:\n",
    "- Fine-tune prompts for your specific product category\n",
    "- Experiment with different IP-Adapter scales\n",
    "- Adjust image sizes based on your requirements\n",
    "- Batch process multiple products"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

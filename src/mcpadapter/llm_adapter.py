"""
LLM + MCP í†µí•© ì–´ëŒ‘í„°
OpenAI LLMì´ ìì—°ì–´ë¥¼ í•´ì„í•˜ì—¬ MCP ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ì§€ì›
"""

import json
import sys
from pathlib import Path

project_root = Path(__file__).resolve()
sys.path.insert(0, str(project_root))

import logging
from helper_dev_utils import get_auto_logger

logger = get_auto_logger()

from typing import Any, Dict, List, Optional
from openai import AsyncOpenAI
from .mcp_client import MCPClient, MCPClientError


class LLMAdapter:
    """
    LLM(OpenAI)ê³¼ MCP ì„œë²„ë¥¼ ì—°ê²°í•˜ëŠ” ì–´ëŒ‘í„°

    ìì—°ì–´ ì…ë ¥ì„ MCP ë„êµ¬ í˜¸ì¶œë¡œ ë³€í™˜í•˜ê³ ,
    MCP ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±

    ì‚¬ìš© ì˜ˆ:
        async with LLMAdapter(openai_api_key, mcp_url) as adapter:
            response = await adapter.chat("product.pngë¡œ SALE ê´‘ê³  ë§Œë“¤ì–´ì¤˜")
    """

    def __init__(
        self,
        openai_api_key: str,
        mcp_server_url: str = "http://localhost:3000",
        model: str = "gpt-4o",
        temperature: float = 1.0,
        max_completion_tokens: int = 4000,
    ):
        """
        Args:
            openai_api_key: OpenAI API í‚¤
            mcp_server_url: MCP ì„œë²„ URL
            model: ì‚¬ìš©í•  OpenAI ëª¨ë¸
            temperature: LLM ì˜¨ë„ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 1.0, gpt-5-miniëŠ” 1ë§Œ ì§€ì›)
            max_completion_tokens: ìµœëŒ€ ì™„ì„± í† í° ìˆ˜
        """
        self.openai_client = AsyncOpenAI(api_key=openai_api_key)
        self.mcp_client = MCPClient(base_url=mcp_server_url)
        self.model = model
        self.temperature = temperature
        self.max_completion_tokens = max_completion_tokens

        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history: List[Dict[str, Any]] = []

    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self.mcp_client.__aenter__()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.mcp_client.__aexit__(exc_type, exc_val, exc_tb)

    def _build_system_prompt(self, user_message: str, max_tool_calls: int = 5) -> str:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì‘ì—… ìœ í˜•ë³„ ìµœì  system prompt ìƒì„±

        ì‘ì—… ìœ í˜•:
        - ìƒì„±: generate_ad_image, generate_background_only, generate_text_asset_only
        - ì¡°íšŒ/ê´€ë¦¬: check_*, get_*, delete_*, stop_*
        - ì¶”ì²œ: recommend_font_for_ad, get_fonts_metadata

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            max_tool_calls: ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ (1=ì¦‰ì‹œì‹¤í–‰, >1=ëŒ€í™”ëª¨ë“œ)

        Returns:
            ì‘ì—… ìœ í˜•ì— ìµœì í™”ëœ system prompt
        """
        msg_lower = user_message.lower()

        # ìƒì„± í‚¤ì›Œë“œ ê°ì§€
        generation_keywords = [
            "ë§Œë“¤ì–´",
            "ìƒì„±",
            "ê´‘ê³ ",
            "ë°°ê²½",
            "í…ìŠ¤íŠ¸",
            "í•©ì„±",
            "create",
            "generate",
            "make",
            "ad",
            "background",
        ]
        is_generation = any(kw in msg_lower for kw in generation_keywords)

        # ì¡°íšŒ/ê´€ë¦¬ í‚¤ì›Œë“œ ê°ì§€
        query_keywords = [
            "í™•ì¸",
            "ì¡°íšŒ",
            "ìƒíƒœ",
            "ì‚­ì œ",
            "ì¤‘ë‹¨",
            "ëª©ë¡",
            "check",
            "status",
            "delete",
            "stop",
            "list",
            "get",
        ]
        is_query = any(kw in msg_lower for kw in query_keywords)

        if is_generation and not is_query:
            # ìƒì„± ì‘ì—…: max_tool_callsì— ë”°ë¼ ëª¨ë“œ ê²°ì •
            base_prompt = "ë‹¹ì‹ ì€ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± ì „ë¬¸ AIì…ë‹ˆë‹¤.\n\n"

            # max_tool_calls=1ì´ë©´ ì¦‰ì‹œ ì‹¤í–‰ ëª¨ë“œ
            if max_tool_calls == 1:
                base_prompt += (
                    "âš¡ [ì¦‰ì‹œ ì‹¤í–‰ ëª¨ë“œ]\n"
                    "ì‚¬ìš©ì í™•ì¸ ì—†ì´ ë°”ë¡œ generate_ad_image ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n"
                    "ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì„ íƒì§€(A/B/C)ë¥¼ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”.\n"
                    "ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”.\n\n"
                )
            else:
                base_prompt += (
                    "ğŸ’¬ [ëŒ€í™” ëª¨ë“œ]\n"
                    "í•„ìš”ì‹œ ì‚¬ìš©ìì—ê²Œ ì˜µì…˜ì„ ì œì‹œí•˜ê³  í™•ì¸ì„ ë°›ì€ í›„ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n\n"
                )

            base_prompt += (
                "[í•µì‹¬ ì›ì¹™]\n"
                "generate_ad_image í˜¸ì¶œ ì‹œ optional íŒŒë¼ë¯¸í„°ë¥¼ MUST ìƒì„±í•˜ì„¸ìš”.\n\n"
                "[í•„ìˆ˜ ìƒì„± íŒŒë¼ë¯¸í„°]\n"
                "1. background_negative_prompt (8-15 keywords)\n"
                "   í’ˆì§ˆ: blurry, low quality, distorted\n"
                "   ì¡°ëª…: bad lighting, harsh shadows, overexposed\n"
                "   ì •ë¦¬: cluttered, watermark, text, logo\n\n"
                "2. bg_composition_prompt (10-20 words)\n"
                "   Product integration, lighting consistency, depth of field, color harmony\n\n"
                "3. bg_composition_negative_prompt (7-12 keywords)\n"
                "   floating, disconnected, unrealistic shadows, mismatched lighting\n\n"
                "4. text_prompt (10-20 words)\n"
                "   Text style, font characteristics, readability, visual impact, brand tone\n\n"
                "5. text_negative_prompt (7-12 keywords)\n"
                "   unreadable, distorted text, blurry fonts, poor contrast, illegible\n\n"
                "6. composition_prompt (12-25 words)\n"
                "   Text integration, lighting/shadows, visual hierarchy, quality standards\n\n"
                "7. composition_negative_prompt (8-15 keywords)\n"
                "   artificial looking, pasted on, halos, color mismatch, poor blending\n\n"
                "[ì˜ˆì‹œ]\n"
                "ì‚¬ìš©ì: ë°”ë‚˜ë‚˜ íŠ¹ê°€ ê´‘ê³  ë§Œë“¤ì–´ì¤˜\n"
                "AI: generate_ad_image(\n"
                "  background_prompt='Vibrant Korean market, colorful fruit stalls...',\n"
                "  background_negative_prompt='blurry, cluttered, watermark, harsh shadows',\n"
                "  bg_composition_prompt='Banana naturally placed, matching warm lighting, realistic depth',\n"
                "  bg_composition_negative_prompt='floating, disconnected, unrealistic shadows',\n"
                "  text_prompt='Bold 3D Korean text with yellow-gold gradient, glossy surface',\n"
                "  text_negative_prompt='floor, ground, background, flat, 2D, blurry fonts',\n"
                "  composition_prompt='Text floating naturally with soft shadows, consistent lighting',\n"
                "  composition_negative_prompt='artificial looking, halos, color mismatch'\n"
                ")\n\n"
                "ëª¨ë“  í”„ë¡¬í”„íŠ¸ëŠ” ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
            )
            return base_prompt

        elif is_query:
            # ì¡°íšŒ/ê´€ë¦¬ ì‘ì—…: ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸
            return (
                "ë‹¹ì‹ ì€ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ ê´€ë¦¬ AIì…ë‹ˆë‹¤.\n\n"
                "[ì—­í• ]\n"
                "- ì‘ì—… ìƒíƒœ ì¡°íšŒ: check_generation_status(job_id)\n"
                "- ì„œë²„ ìƒíƒœ: check_server_health()\n"
                "- ì‘ì—… ëª©ë¡: get_all_jobs()\n"
                "- ì‘ì—… ì‚­ì œ: delete_job(job_id) ë˜ëŠ” delete_all_jobs()\n"
                "- ì‘ì—… ì¤‘ë‹¨: stop_generation(job_id)\n\n"
                "[ì§€ì¹¨]\n"
                "ì‚¬ìš©ì ìš”ì²­ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n"
                "job_idëŠ” ì‚¬ìš©ìê°€ ì œê³µí•˜ê±°ë‚˜ ì´ì „ ëŒ€í™”ì—ì„œ ì¶”ì¶œí•˜ì„¸ìš”."
            )

        else:
            # ì¶”ì²œ/ê¸°íƒ€ ì‘ì—…: ê· í˜•ì¡íŒ í”„ë¡¬í”„íŠ¸
            return (
                "ë‹¹ì‹ ì€ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± ì „ë¬¸ AIì…ë‹ˆë‹¤.\n\n"
                "[ì£¼ìš” ê¸°ëŠ¥]\n"
                "1. ê´‘ê³  ìƒì„±: generate_ad_image (ìƒì„¸ íŒŒë¼ë¯¸í„° í•„ìš”)\n"
                "2. í°íŠ¸ ì¶”ì²œ: recommend_font_for_ad(text_content, ad_type, tone)\n"
                "3. í°íŠ¸ ë©”íƒ€ë°ì´í„°: get_fonts_metadata(), list_available_fonts()\n"
                "4. ì‘ì—… ê´€ë¦¬: check_*, get_*, delete_*, stop_*\n\n"
                "[ê´‘ê³  ìƒì„± ì‹œ í•„ìˆ˜]\n"
                "background_negative_prompt, bg_composition_prompt, "
                "bg_composition_negative_prompt, text_prompt, text_negative_prompt, "
                "composition_prompt, composition_negative_promptë¥¼ ì˜ë¬¸ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.\n\n"
                "[í°íŠ¸ ì¶”ì²œ ì‹œ]\n"
                "ad_type: sale/premium/casual/promotion\n"
                "tone: energetic/elegant/friendly/modern"
            )

    async def chat(
        self,
        user_message: str,
        max_tool_calls: int = 5,
    ) -> str:
        """
        ìì—°ì–´ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì‘ë‹µ ìƒì„±

        ë‚´ë¶€ì ìœ¼ë¡œ LLMì´ í•„ìš”ì‹œ MCP ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³ ,
        ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            max_tool_calls: ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜

        Returns:
            LLMì˜ ìµœì¢… ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ (ì²« ë©”ì‹œì§€ì¸ ê²½ìš°ì—ë§Œ)
        if not self.conversation_history:
            system_prompt = self._build_system_prompt(user_message, max_tool_calls)
            self.conversation_history.append(
                {"role": "system", "content": system_prompt}
            )

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.conversation_history.append({"role": "user", "content": user_message})

        # MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ
        tools = await self._get_mcp_tools_schema()

        # LLMê³¼ ëŒ€í™” (ë„êµ¬ í˜¸ì¶œ í¬í•¨)
        tool_call_count = 0

        while tool_call_count < max_tool_calls:
            # LLM í˜¸ì¶œ
            response = await self.openai_client.chat.completions.create(
                model=self.model,
                messages=self.conversation_history,
                tools=tools,
                temperature=self.temperature,
                max_completion_tokens=self.max_completion_tokens,
            )

            message = response.choices[0].message

            # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
            if not message.tool_calls:
                self.conversation_history.append(
                    {"role": "assistant", "content": message.content}
                )
                return message.content

            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
            self.conversation_history.append(
                {
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [tc.dict() for tc in message.tool_calls],
                }
            )

            # ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
            for tool_call in message.tool_calls:
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)

                # generate_ad_image í•„ìˆ˜ optional íŒŒë¼ë¯¸í„° ìë™ ìƒì„± (ëˆ„ë½ ì‹œ)
                if tool_name == "generate_ad_image":
                    if not tool_args.get("bg_composition_prompt"):
                        tool_args["bg_composition_prompt"] = (
                            "Product naturally integrated with consistent lighting, "
                            "matching ambient shadows, proper depth of field, "
                            "harmonized color palette, seamless professional blend"
                        )
                        logger.info("bg_composition_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)")

                    if not tool_args.get("bg_composition_negative_prompt"):
                        tool_args["bg_composition_negative_prompt"] = (
                            "floating, disconnected, unrealistic shadows, "
                            "mismatched lighting, pasted on, poor integration"
                        )
                        logger.info(
                            "bg_composition_negative_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)"
                        )

                    if not tool_args.get("text_prompt"):
                        tool_args["text_prompt"] = (
                            "Bold professional typography with high readability, "
                            "strong visual impact, consistent brand tone, "
                            "clean font characteristics, optimized legibility"
                        )
                        logger.info("text_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)")

                    if not tool_args.get("text_negative_prompt"):
                        tool_args["text_negative_prompt"] = (
                            "unreadable, distorted text, blurry fonts, "
                            "poor contrast, illegible, warped letters"
                        )
                        logger.info("text_negative_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)")

                    if not tool_args.get("composition_prompt"):
                        tool_args["composition_prompt"] = (
                            "Text floating naturally above background with soft shadows beneath, "
                            "consistent atmospheric lighting, clear visual hierarchy as focal point, "
                            "professional overlay quality, smooth blending"
                        )
                        logger.info("composition_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)")

                    if not tool_args.get("composition_negative_prompt"):
                        tool_args["composition_negative_prompt"] = (
                            "artificial looking, pasted on, poorly integrated, "
                            "color mismatch, halos, visible edges, poor blending"
                        )
                        logger.info("composition_negative_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)")

                    if not tool_args.get("background_negative_prompt"):
                        tool_args["background_negative_prompt"] = (
                            "blurry, low quality, bad lighting, cluttered, watermark, "
                            "harsh shadows, overexposed, unprofessional"
                        )
                        logger.info("background_negative_prompt ìë™ ìƒì„±ë¨ (ê¸°ë³¸ê°’)")

                logger.info(f"MCP ë„êµ¬ í˜¸ì¶œ tool_name={tool_name}")
                logger.info(f"MCP ë„êµ¬ í˜¸ì¶œ tool_args={tool_args}")

                try:
                    result = await self.mcp_client.call_tool(tool_name, tool_args)
                    tool_result = str(result)
                    logger.info(f"MCP ë„êµ¬ í˜¸ì¶œ ì„±ê³µ: {tool_result[:200]}...")
                except MCPClientError as e:
                    tool_result = f"ì—ëŸ¬: {e}"
                    logger.error(f"MCP ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                except Exception as e:
                    tool_result = f"ì˜ˆì™¸: {e}"
                    logger.error(f"MCP ë„êµ¬ í˜¸ì¶œ ì˜ˆì™¸: {e}")

                # ë„êµ¬ ê²°ê³¼ ì¶”ê°€
                self.conversation_history.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result,
                    }
                )

            tool_call_count += 1

        # ìµœëŒ€ í˜¸ì¶œ íšŸìˆ˜ ì´ˆê³¼
        logger.warning(f"ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜({max_tool_calls}) ì´ˆê³¼")
        return "ì‘ì—…ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•©ë‹ˆë‹¤."

    async def _get_mcp_tools_schema(self) -> List[Dict[str, Any]]:
        """
        MCP ë„êµ¬ ëª©ë¡ì„ OpenAI Function Calling ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜

        Returns:
            OpenAI tools ìŠ¤í‚¤ë§ˆ ë¦¬ìŠ¤íŠ¸
        """
        mcp_tools = await self.mcp_client.list_tools()

        openai_tools = []
        for tool in mcp_tools:
            openai_tools.append(
                {
                    "type": "function",
                    "function": {
                        "name": tool["name"],
                        "description": tool.get("description", ""),
                        "parameters": tool.get(
                            "parameters",
                            tool.get(
                                "inputSchema", {"type": "object", "properties": {}}
                            ),
                        ),
                    },
                }
            )

        return openai_tools

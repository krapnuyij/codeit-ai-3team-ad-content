# nanoCocoa AI Server - Docker ë°°í¬ ê°€ì´ë“œ

## ğŸ“¦ ì‚¬ì „ ì¤€ë¹„

### 1. Docker ë° NVIDIA Container Toolkit ì„¤ì¹˜

```bash
# Docker ì„¤ì¹˜ (Ubuntu)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# NVIDIA Container Toolkit ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# ì„¤ì¹˜ í™•ì¸
docker run --rm --gpus all nvidia/cuda:12.9.1-base-ubuntu22.04 nvidia-smi
```

### 2. HuggingFace ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±

```bash
# ì™¸ë¶€ ë³¼ë¥¨ ë””ë ‰í† ë¦¬ ìƒì„± (200GB ë””ìŠ¤í¬)
sudo mkdir -p /opt/huggingface
sudo chown -R $USER:$USER /opt/huggingface
```

---

## ğŸš€ ë¹Œë“œ ë° ì‹¤í–‰

### ë°©ë²• 1: docker-compose ì‚¬ìš© (ê¶Œì¥)

```bash
cd /home/spai0433/codeit-ai-3team-ad-content/src/nanoCocoa_aiserver

# ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d --build

# ë¡œê·¸ í™•ì¸
docker-compose logs -f

# ì¤‘ì§€
docker-compose down

# ì¬ì‹œì‘
docker-compose restart
```

### ë°©ë²• 2: Docker ëª…ë ¹ì–´ ì§ì ‘ ì‚¬ìš©

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t nanococoa-aiserver:latest .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name nanococoa-aiserver \
  --gpus all \
  -p 8000:8000 \
  -v /opt/huggingface:/root/.cache/huggingface \
  -v $(pwd)/static/uploads:/app/static/uploads \
  -v $(pwd)/static/results:/app/static/results \
  -v $(pwd)/logs:/app/logs \
  -e PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True \
  -e HF_HOME=/root/.cache/huggingface \
  --restart unless-stopped \
  nanococoa-aiserver:latest

# ë¡œê·¸ í™•ì¸
docker logs -f nanococoa-aiserver

# ì¤‘ì§€ ë° ì‚­ì œ
docker stop nanococoa-aiserver
docker rm nanococoa-aiserver
```

---

## ğŸ“ ë³¼ë¥¨ ë§¤í•‘

| í˜¸ìŠ¤íŠ¸ ê²½ë¡œ | ì»¨í…Œì´ë„ˆ ê²½ë¡œ | ìš©ë„ |
|------------|-------------|------|
| `/opt/huggingface` | `/root/.cache/huggingface` | HuggingFace ëª¨ë¸ ìºì‹œ (ì˜êµ¬) |
| `./static/uploads` | `/app/static/uploads` | ì—…ë¡œë“œëœ ì´ë¯¸ì§€ |
| `./static/results` | `/app/static/results` | ìƒì„±ëœ ê²°ê³¼ ì´ë¯¸ì§€ |
| `./logs` | `/app/logs` | ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ |

**ì¤‘ìš”**: `/opt/huggingface`ëŠ” 200GB ë””ìŠ¤í¬ì— ìƒì„±í•˜ì—¬ ëª¨ë¸ì„ ì˜êµ¬ ì €ì¥í•©ë‹ˆë‹¤.

---

## ğŸ” í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§

### í—¬ìŠ¤ì²´í¬ API

```bash
# ì„œë²„ ìƒíƒœ í™•ì¸
curl http://localhost:8000/health

# ì‘ë‹µ ì˜ˆì‹œ
{
  "status": "healthy",
  "uptime": 3600,
  "gpu_available": true,
  "models_loaded": 0
}
```

### ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸

```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ
docker ps

# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ (ì‹¤ì‹œê°„)
docker stats nanococoa-aiserver

# GPU ì‚¬ìš©ëŸ‰
nvidia-smi

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ì ‘ì†
docker exec -it nanococoa-aiserver bash
```

### ë¡œê·¸ í™•ì¸

```bash
# ì „ì²´ ë¡œê·¸
docker logs nanococoa-aiserver

# ì‹¤ì‹œê°„ ë¡œê·¸ (tail -f)
docker logs -f nanococoa-aiserver

# ìµœê·¼ 100ì¤„
docker logs --tail 100 nanococoa-aiserver

# íŠ¹ì • ì‹œê°„ ì´í›„ ë¡œê·¸
docker logs --since 10m nanococoa-aiserver
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. GPUê°€ ì¸ì‹ë˜ì§€ ì•ŠìŒ

```bash
# NVIDIA Container Toolkit ì¬ì‹œì‘
sudo systemctl restart docker

# GPU í…ŒìŠ¤íŠ¸
docker run --rm --gpus all nvidia/cuda:12.9.1-base-ubuntu22.04 nvidia-smi
```

### 2. í¬íŠ¸ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘

```bash
# 8000 í¬íŠ¸ ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
sudo lsof -i :8000
sudo netstat -tulpn | grep :8000

# ë‹¤ë¥¸ í¬íŠ¸ë¡œ ë³€ê²½ (ì˜ˆ: 8001)
docker run -p 8001:8000 ...
```

### 3. ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±

```bash
# ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” Docker ì´ë¯¸ì§€/ì»¨í…Œì´ë„ˆ ì •ë¦¬
docker system prune -a

# ë³¼ë¥¨ í™•ì¸
df -h /opt/huggingface

# ìºì‹œ ì •ë¦¬ (í•„ìš”ì‹œ)
rm -rf /opt/huggingface/hub/*
```

### 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼

```bash
# HuggingFace í† í° ì„¤ì • (ì„ íƒ)
docker run -e HF_TOKEN=your_token_here ...

# ë˜ëŠ” .env íŒŒì¼ ìƒì„±
echo "HF_TOKEN=your_token_here" > .env
docker-compose up -d
```

### 5. ì»¨í…Œì´ë„ˆê°€ ê³„ì† ì¬ì‹œì‘ë¨

```bash
# ì—ëŸ¬ ë¡œê·¸ í™•ì¸
docker logs nanococoa-aiserver

# í—¬ìŠ¤ì²´í¬ ë¹„í™œì„±í™” í›„ ì¬ì‹œì‘
docker run --no-healthcheck ...
```

---

## ğŸ”§ ì„±ëŠ¥ íŠœë‹

### 1. Worker ìˆ˜ ì¡°ì •

```yaml
# docker-compose.yml ìˆ˜ì •
command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2"]
```

### 2. ë©”ëª¨ë¦¬ ì œí•œ

```yaml
# docker-compose.ymlì— ì¶”ê°€
deploy:
  resources:
    limits:
      memory: 32G
    reservations:
      memory: 16G
```

### 3. CUDA ë©”ëª¨ë¦¬ ìµœì í™”

```bash
# í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€
-e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:True
```

---

## ğŸ“Š ìš´ì˜ ê°€ì´ë“œ

### 1. ë°±ì—…

```bash
# ëª¨ë¸ ìºì‹œ ë°±ì—…
tar -czf huggingface_cache_backup.tar.gz /opt/huggingface

# ê²°ê³¼ íŒŒì¼ ë°±ì—…
tar -czf results_backup.tar.gz ./static/results
```

### 2. ì—…ë°ì´íŠ¸

```bash
# ì½”ë“œ ì—…ë°ì´íŠ¸
git pull origin main

# ì´ë¯¸ì§€ ì¬ë¹Œë“œ
docker-compose up -d --build

# ë˜ëŠ”
docker-compose build --no-cache
docker-compose up -d
```

### 3. ìŠ¤ì¼€ì¼ë§ (ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤)

```yaml
# docker-compose.yml
services:
  nanococoa-aiserver:
    # ... (ê¸°ì¡´ ì„¤ì •)
    deploy:
      replicas: 2  # ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
```

---

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 1. ë°©í™”ë²½ ì„¤ì •

```bash
# UFW ì‚¬ìš© ì‹œ
sudo ufw allow 8000/tcp
sudo ufw enable
```

### 2. HTTPS ì„¤ì • (Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)

```nginx
server {
    listen 443 ssl;
    server_name your-domain.com;

    ssl_certificate /etc/ssl/certs/cert.pem;
    ssl_certificate_key /etc/ssl/private/key.pem;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### 3. API í‚¤ ì¸ì¦ (ì„ íƒ)

```python
# main.pyì— ì¶”ê°€
from fastapi import Security, HTTPException
from fastapi.security.api_key import APIKeyHeader

API_KEY = os.getenv("API_KEY", "your-secret-key")
api_key_header = APIKeyHeader(name="X-API-Key")

async def verify_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=403, detail="Invalid API Key")
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Docker ê³µì‹ ë¬¸ì„œ](https://docs.docker.com/)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [Docker Compose](https://docs.docker.com/compose/)
- [FastAPI Deployment](https://fastapi.tiangolo.com/deployment/)

---

## ğŸ’¡ ë¹ ë¥¸ ëª…ë ¹ì–´ ìš”ì•½

```bash
# ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d --build

# ë¡œê·¸ í™•ì¸
docker-compose logs -f

# ì¤‘ì§€
docker-compose down

# ì¬ì‹œì‘
docker-compose restart

# ìƒíƒœ í™•ì¸
curl http://localhost:8000/health

# GPU í™•ì¸
nvidia-smi

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ì ‘ì†
docker exec -it nanococoa-aiserver bash
```


import multiprocessing
import uuid
import time
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Response, status
from PIL import Image, ImageDraw, ImageFont

# ëª¨ë“ˆí™”ëœ íŒŒì¼ë“¤ì—ì„œ import
from .config import logger, TOTAL_ESTIMATED_TIME
from .utils import pil_to_base64, base64_to_pil, flush_gpu, get_system_metrics, pil_canny_edge, get_available_fonts, get_font_path
from .schemas import GenerateRequest, ResumeRequest
from .AIModelEngine import AIModelEngine

# ==========================================
# ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ (Background Worker)
# ==========================================
def worker_process(job_id: str, input_data: dict, shared_state: dict, stop_event: multiprocessing.Event):
    """
    Step ê¸°ë°˜(1->2->3) ìˆœì°¨ ì‹¤í–‰ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤.
    """
    
    # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    test_mode = input_data.get('test_mode', False)
    
    engine = AIModelEngine(dummy_mode=test_mode)
    
    try:
        shared_state['status'] = 'running'
        shared_state['start_time'] = time.time()
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê³„ì†)
        start_step = input_data.get('start_step', 1)
        
        bg_prompt = input_data.get('bg_prompt')
        text_model_prompt = input_data.get('text_model_prompt')
        negative_prompt = input_data.get('negative_prompt')
        text_content = input_data.get('text_content', "Special Sale")
        
        strength = input_data.get('strength', 0.6)
        guidance_scale = input_data.get('guidance_scale', 3.5)
        seed = input_data.get('seed') 

        # ë‹¨ê³„ë³„ ê²°ê³¼ë¬¼ ë³€ìˆ˜ (PIL Image)
        step1_result = None
        step2_result = None
        final_result = None

        # ==========================================
        # Step 1: ë°°ê²½ ìƒì„± (Background Generation)
        # ==========================================
        if start_step <= 1:
            if stop_event.is_set(): return

            shared_state['current_step'] = 'step1_background'
            shared_state['message'] = 'Step 1: Generating Background... (ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì¤‘)'
            
            # ì…ë ¥ í™•ì¸
            input_img_b64 = input_data.get('input_image')
            if not input_img_b64:
                raise ValueError("[Step 1 Error] 'input_image' is required to start from Step 1.")
            raw_img = base64_to_pil(input_img_b64)
            
            # [Logic]
            # 1. ëˆ„ë¼ (Segmentation)
            product_fg, mask = engine.run_segmentation(raw_img)
            
            # 2. ë°°ê²½ ìƒì„± (Flux Text-to-Image)
            bg_img = engine.run_flux_bg_gen(prompt=bg_prompt, guidance_scale=guidance_scale, seed=seed)
            
            # 3. ì´ˆì•ˆ í•©ì„± (Composite Draft)
            bg_w, bg_h = bg_img.size
            scale = 0.4
            fg_resized = product_fg.resize((int(product_fg.width*scale), int(product_fg.height*scale)), Image.LANCZOS)
            x = (bg_w - fg_resized.width) // 2
            y = int(bg_h * 0.55)
            
            base_comp = bg_img.convert("RGBA")
            fg_layer = Image.new("RGBA", bg_img.size)
            fg_layer.paste(fg_resized, (x, y))
            base_comp = Image.alpha_composite(base_comp, fg_layer)
            draft_final = base_comp.convert("RGB")
            
            # 4. ë¦¬íŒŒì¸ (Flux Img-to-Img)
            refined_base = engine.run_flux_refinement(
                draft_final, 
                strength=strength, 
                guidance_scale=guidance_scale, 
                seed=seed
            )
            
            step1_result = refined_base
            shared_state['images']['step1_result'] = pil_to_base64(step1_result)
            shared_state['progress_percent'] = 33
            
        else:
            # Step 1ì„ ê±´ë„ˆë›¸ ê²½ìš°, ì…ë ¥ë°›ì€ step1_image ì‚¬ìš©
            img_s1_b64 = input_data.get('step1_image')
            if img_s1_b64:
                # shared_state['message'] = 'Step 1 Skipped. Using provided image.'
                step1_result = base64_to_pil(img_s1_b64)
                shared_state['images']['step1_result'] = img_s1_b64
            else:
                # 2ë‹¨ê³„ ì´ìƒë¶€í„° ì‹œì‘í•˜ëŠ”ë° 1ë‹¨ê³„ ê²°ê³¼ë¬¼ì´ ì—†ìœ¼ë©´ ì¹˜ëª…ì ì¼ ìˆ˜ ìˆìŒ(3ë‹¨ê³„ì—ì„œ í•„ìš” ì‹œ)
                # ë‹¨, 2ë‹¨ê³„ë§Œ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ê²½ìš° ë“±ì—ëŠ” ì—†ì„ ìˆ˜ë„ ìˆìŒ.
                pass

        # ==========================================
        # Step 2: í…ìŠ¤íŠ¸ ì—ì…‹ ìƒì„± (Text Asset Gen)
        # ==========================================
        if start_step <= 2:
            if stop_event.is_set(): return

            shared_state['current_step'] = 'step2_text'
            shared_state['message'] = 'Step 2: Generating 3D Text... (3D í…ìŠ¤íŠ¸ ìƒì„± ì¤‘)'
            
            # [Logic]
            # 1. í°íŠ¸ ë° ìº”ë²„ìŠ¤ ì¤€ë¹„
            W, H = 1024, 1024 # ê¸°ë³¸ ìº”ë²„ìŠ¤ í¬ê¸°
            
            font_name = input_data.get('font_name')
            if not font_name:
                avail_fonts = get_available_fonts()
                font_name = avail_fonts[0] if avail_fonts else None
            
            try:
                font_path = get_font_path(font_name) if font_name else None
                font = ImageFont.truetype(font_path, 160) if font_path else ImageFont.load_default()
            except Exception as e:
                logger.warning(f"Font load failed: {e}")
                font = ImageFont.load_default()
            
            text_guide = Image.new("RGB", (W, H), "black")
            draw = ImageDraw.Draw(text_guide)
            
            bbox = draw.textbbox((0,0), text_content, font=font)
            tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]
            text_x, text_y = (W - tw) // 2, 100
            
            draw.text((text_x, text_y), text_content, font=font, fill="white")
            canny_map = pil_canny_edge(text_guide)
            
            # 2. SDXL ControlNet
            raw_3d_text = engine.run_sdxl_text_gen(
                canny_map, 
                prompt=text_model_prompt,
                negative_prompt=negative_prompt
            )
            
            # 3. ë°°ê²½ ì œê±° (Text Segmentation)
            transparent_text, _ = engine.run_segmentation(raw_3d_text)
            
            step2_result = transparent_text
            shared_state['images']['step2_result'] = pil_to_base64(step2_result)
            shared_state['progress_percent'] = 66
            
        else:
             # Step 2 ê±´ë„ˆë›¸ ê²½ìš°
            img_s2_b64 = input_data.get('step2_image')
            if img_s2_b64:
                step2_result = base64_to_pil(img_s2_b64)
                shared_state['images']['step2_result'] = img_s2_b64

        # ==========================================
        # Step 3: ìµœì¢… í•©ì„± (Final Composite)
        # ==========================================
        if start_step <= 3:
            if stop_event.is_set(): return

            shared_state['current_step'] = 'step3_composite'
            shared_state['message'] = 'Step 3: Final Compositing... (ìµœì¢… í•©ì„± ì¤‘)'
            
            # Step 1, Step 2 ê²°ê³¼ë¬¼ í™•ë³´ í™•ì¸
            if not step1_result and shared_state['images'].get('step1_result'):
                step1_result = base64_to_pil(shared_state['images']['step1_result'])
                
            if not step2_result and shared_state['images'].get('step2_result'):
                step2_result = base64_to_pil(shared_state['images']['step2_result'])
                
            if not step1_result:
                raise ValueError("[Step 3 Error] Missing 'step1_result'. Cannot composite.")
            if not step2_result:
                raise ValueError("[Step 3 Error] Missing 'step2_result'. Cannot composite.")
            
            # [Logic] í•©ì„±
            base_comp = step1_result.convert("RGBA")
            text_asset = step2_result.convert("RGBA")
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë“±ì€ í˜„ì¬ ê³ ì • (ì¶”í›„ íŒŒë¼ë¯¸í„°í™” ê°€ëŠ¥)
            # text_assetì€ 1024x1024 ì „ì²´ ìº”ë²„ìŠ¤ ê¸°ì¤€ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ê²¹ì¹˜ë©´ ë¨ (ìœ„ì¹˜ ì¡°ì •ì€ Step 2ì—ì„œ ì´ë¯¸ ê²°ì •ë¨)
            if base_comp.size != text_asset.size:
                text_asset = text_asset.resize(base_comp.size, Image.LANCZOS)
                
            final_comp = Image.alpha_composite(base_comp, text_asset)
            final_result = final_comp.convert("RGB")
            
            shared_state['images']['final_result'] = pil_to_base64(final_result)
            shared_state['progress_percent'] = 100

        # ì™„ë£Œ ì²˜ë¦¬
        if stop_event.is_set():
            shared_state['status'] = 'stopped'
            shared_state['message'] = 'Job stopped by user.'
        else:
            shared_state['status'] = 'completed'
            shared_state['message'] = 'All steps completed successfully.'

    finally:
        flush_gpu()

# ==========================================
# ğŸŒ FastAPI App & MCP Schemas
# ==========================================
app = FastAPI(
    title="L4 Optimized AI Ad Generator (Step-based)",
    description="""
    # L4 ìµœì í™” AI ê´‘ê³  ìƒì„± ì„œë²„ (AI Ad Generator Server)
    
    ì´ ì„œë²„ëŠ” ìƒí’ˆ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ë°°ê²½ì„ ìƒì„±í•˜ê³ , 3D í…ìŠ¤íŠ¸ íš¨ê³¼ë¥¼ í•©ì„±í•˜ì—¬ ì™„ì„±ëœ ê´‘ê³  ì´ë¯¸ì§€ë¥¼ ì œì‘í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.
    Nvidia L4 GPUì— ìµœì í™”ëœ ëª¨ë¸(BiRefNet, FLUX-schnell, SDXL ControlNet)ì„ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ## ì£¼ìš” ê¸°ëŠ¥
    - **ë™ì‹œì„± ì œì–´**: ë¦¬ì†ŒìŠ¤ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…(Job)ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - **Step-based ì‹¤í–‰**: ë°°ê²½ ìƒì„±(Step 1), í…ìŠ¤íŠ¸ ìƒì„±(Step 2), ìµœì¢… í•©ì„±(Step 3)ì„ ë‹¨ê³„ë³„ë¡œ ì œì–´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    - **ì¤‘ê°„ ê²°ê³¼ ì¬ì‚¬ìš©**: ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼ì„ í™œìš©í•˜ì—¬ ì¤‘ê°„ë¶€í„° ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """,
    version="2.0.0",
    contact={
        "name": "AI Team",
        "email": "support@codeit-ai.com",
    },
)

manager = multiprocessing.Manager()
JOBS = manager.dict()
PROCESSES = {}
STOP_EVENTS = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    metrics = get_system_metrics()
    logger.info(f"System Check: {metrics}")
    yield
    for pid, proc in PROCESSES.items():
        if proc.is_alive():
            proc.terminate()
    manager.shutdown()

app.router.lifespan_context = lifespan

@app.get(
    "/fonts", 
    summary="ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ëª©ë¡ ì¡°íšŒ (Get Font List)",
    response_description="ì„œë²„ì— ì €ì¥ëœ TTF/OTF í°íŠ¸ íŒŒì¼ ëª©ë¡"
)
async def get_fonts():
    """
    ì„œë²„ì˜ `fonts` ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í°íŠ¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    - **fonts**: í°íŠ¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: `["NanumGothic/NanumGothic.ttf", ...]`)
    
    ì´ ëª©ë¡ì˜ ê°’ì„ `/generate` ìš”ì²­ì˜ `font_name` í•„ë“œì— ì…ë ¥í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    return {"fonts": get_available_fonts()}

@app.post(
    "/generate", 
    summary="AI ê´‘ê³  ìƒì„± ì‘ì—… ì‹œì‘ (Start Generation Job)",
    response_description="ìƒì„±ëœ ì‘ì—…ì˜ IDì™€ ìƒíƒœ",
    status_code=status.HTTP_200_OK,
    responses={
        200: {
            "description": "ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ íì— ë“±ë¡ë˜ê³  ì‹œì‘ë¨",
            "content": {
                "application/json": {
                    "example": {"job_id": "550e8400-e29b-41d4-a716-446655440000", "status": "started"}
                }
            }
        },
        503: {
            "description": "ì„œë²„ê°€ ë‹¤ë¥¸ ì‘ì—…ì„ ì²˜ë¦¬ ì¤‘ì„ (Busy)",
            "content": {
                "application/json": {
                    "example": {
                        "status": "busy",
                        "message": "í˜„ì¬ ë‹¤ë¥¸ ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì•½ 25ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "retry_after": 25
                    }
                }
            }
        }
    }
)
async def generate_ad(req: GenerateRequest, response: Response):
    """
     **ìƒˆë¡œìš´ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.** (Non-blocking)
    
    í´ë¼ì´ì–¸íŠ¸ëŠ” `job_id`ë¥¼ ë°˜í™˜ë°›ì€ í›„, `/status/{job_id}`ë¥¼ í´ë§í•˜ì—¬ ì§„í–‰ ìƒí™©ê³¼ ê²°ê³¼ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
    
    ### Step êµ¬ì¡° ë° ì‹¤í–‰ ë°©ë²•
    1. **Step 1 (Background)**:
       - `start_step=1` (ê¸°ë³¸ê°’)
       - `input_image` (ëˆ„ë¼ ë”¸ ìƒí’ˆ ì´ë¯¸ì§€) í•„ìˆ˜
    2. **Step 2 (Text Asset)**:
       - `start_step=2`
       - `step1_image` (ë°°ê²½ í•©ì„±ëœ ì´ë¯¸ì§€) í•„ìˆ˜
       - í…ìŠ¤íŠ¸ë§Œ ë‹¤ì‹œ ìƒì„±í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
    3. **Step 3 (Composition)**:
       - `start_step=3`
       - `step1_image` (ë°°ê²½), `step2_image` (í…ìŠ¤íŠ¸) í•„ìˆ˜
       - ë‹¨ìˆœíˆ ë‘ ì´ë¯¸ì§€ë¥¼ í•©ì„±ë§Œ ë‹¤ì‹œ í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
       
    ### ë™ì‹œì„± ì •ì±…
    - ì´ ì„œë²„ëŠ” **ë‹¨ì¼ ì‘ì—…(Single Job)**ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - ì´ë¯¸ ì‘ì—…ì´ ëŒê³  ìˆì„ ê²½ìš° **503 Service Unavailable** ì‘ë‹µê³¼ í•¨ê»˜ `Retry-After` í—¤ë”ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    
    # ë™ì‹œì„± ì œì–´
    active_jobs = [j for j, s in JOBS.items() if s['status'] in ('running', 'pending')]
    if active_jobs:
        curr = JOBS[active_jobs[0]]
        elapsed = time.time() - (curr['start_time'] or time.time())
        remain = max(0, TOTAL_ESTIMATED_TIME - elapsed)
        response.status_code = status.HTTP_503_SERVICE_UNAVAILABLE
        response.headers["Retry-After"] = str(int(remain))
        return {"status": "busy", "message": f"Busy. Retry after {int(remain)}s", "retry_after": int(remain)}

    job_id = str(uuid.uuid4())
    stop_event = multiprocessing.Event()
    input_data = req.model_dump()
    
    JOBS[job_id] = manager.dict({
        "status": "pending",
        "progress_percent": 0,
        "current_step": "init",
        "message": "Initializing...",
        "error": None,
        "images": manager.dict(), 
        "start_time": None,
        "parameters": input_data
    })
    
    p = multiprocessing.Process(
        target=worker_process,
        args=(job_id, input_data, JOBS[job_id], stop_event)
    )
    p.start()
    PROCESSES[job_id] = p
    STOP_EVENTS[job_id] = stop_event
    
    return {"job_id": job_id, "status": "started"}

@app.get(
    "/status/{job_id}", 
    summary="ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ (Get Job Status)",
    response_description="ì§„í–‰ë¥ , í˜„ì¬ ë‹¨ê³„, ìƒì„±ëœ ì´ë¯¸ì§€(Base64) ë° íŒŒë¼ë¯¸í„°"
)
async def get_status(job_id: str):
    """
    íŠ¹ì • ì‘ì—…(Job)ì˜ í˜„ì¬ ì§„í–‰ ìƒí™©ê³¼ ì¤‘ê°„/ìµœì¢… ê²°ê³¼ë¬¼ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ### ë°˜í™˜ í•„ë“œ ì„¤ëª…
    - **status**: `pending`, `running`, `completed`, `failed`, `stopped`
    - **progress_percent**: 0 ~ 100 ì§„í–‰ë¥ 
    - **current_step**: í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ ë‹¨ê³„ (`step1_background` ë“±)
    - **parameters**: ì‘ì—… ìƒì„± ì‹œ ì‚¬ìš©ëœ ëª¨ë“  ì…ë ¥ íŒŒë¼ë¯¸í„° (ì¬ì‹œë„ ì‹œ ìœ ìš©)
    - **step1_result**: [Optional] 1ë‹¨ê³„ ê²°ê³¼ (Base64 ì´ë¯¸ì§€)
    - **step2_result**: [Optional] 2ë‹¨ê³„ ê²°ê³¼ (Base64 ì´ë¯¸ì§€)
    - **final_result**: [Optional] ìµœì¢… ê²°ê³¼ (Base64 ì´ë¯¸ì§€)
    """
    if job_id not in JOBS:
        raise HTTPException(status_code=404, detail="Job not found")
    
    state = JOBS[job_id]
    elapsed = time.time() - state['start_time'] if state['start_time'] else 0
    
    # ManagerDict -> dict copy needed before serializing
    images_snapshot = dict(state['images'])
    
    return {
        "job_id": job_id,
        "status": state['status'],
        "progress_percent": state['progress_percent'],
        "current_step": state['current_step'],
        "message": state['message'],
        "elapsed_sec": round(elapsed, 1),
        "parameters": state.get('parameters', {}),
        "step1_result": images_snapshot.get('step1_result'), # Base64 Data
        "step2_result": images_snapshot.get('step2_result'),
        "final_result": images_snapshot.get('final_result'),
        # "full_images" key removed as specific keys are now provided
    }

@app.post(
    "/stop/{job_id}", 
    summary="ì‘ì—… ê°•ì œ ì¤‘ë‹¨ (Stop Job)",
    response_description="ì¤‘ë‹¨ ìš”ì²­ ê²°ê³¼"
)
async def stop_job(job_id: str):
    """
    ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ì„ ì¦‰ì‹œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
    GPU ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•˜ê³  ì‘ì—…ì„ `stopped` ìƒíƒœë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
    """
    if job_id in STOP_EVENTS:
        STOP_EVENTS[job_id].set()
    
    if job_id in PROCESSES:
        p = PROCESSES[job_id]
        if p.is_alive():
            p.join(timeout=3)
            if p.is_alive(): p.terminate()
        
        if job_id in JOBS: JOBS[job_id]['status'] = 'stopped'
        return {"job_id": job_id, "status": "stopped"}
        
    raise HTTPException(status_code=404, detail="Job not found")
import sys
from pathlib import Path

project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

import multiprocessing
import uuid
import time
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Response, status
from fastapi.responses import HTMLResponse
import os

# ëª¨ë“ˆí™”ëœ íŒŒì¼ë“¤ì—ì„œ import
from config import logger, TOTAL_ESTIMATED_TIME
from utils import get_system_metrics, get_available_fonts
from schemas import GenerateRequest, StatusResponse, SystemMetrics, GPUMetric
from worker import worker_process

# ==========================================
# ğŸŒ FastAPI App & MCP Schemas
# ==========================================
app = FastAPI(
    title="L4 Optimized AI Ad Generator (Step-based)",
    description="""
    # L4 ìµœì í™” AI ê´‘ê³  ìƒì„± ì„œë²„ (AI Ad Generator Server)
    
    ì´ ì„œë²„ëŠ” ìƒí’ˆ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ë°°ê²½ì„ ìƒì„±í•˜ê³ , 3D í…ìŠ¤íŠ¸ íš¨ê³¼ë¥¼ í•©ì„±í•˜ì—¬ ì™„ì„±ëœ ê´‘ê³  ì´ë¯¸ì§€ë¥¼ ì œì‘í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.
    Nvidia L4 GPUì— ìµœì í™”ëœ ëª¨ë¸(BiRefNet, FLUX-schnell, SDXL ControlNet)ì„ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ## ì£¼ìš” ê¸°ëŠ¥
    - **ë™ì‹œì„± ì œì–´**: ë¦¬ì†ŒìŠ¤ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…(Job)ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - **Step-based ì‹¤í–‰**: ë°°ê²½ ìƒì„±(Step 1), í…ìŠ¤íŠ¸ ìƒì„±(Step 2), ìµœì¢… í•©ì„±(Step 3)ì„ ë‹¨ê³„ë³„ë¡œ ì œì–´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    - **ì¤‘ê°„ ê²°ê³¼ ì¬ì‚¬ìš©**: ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼ì„ í™œìš©í•˜ì—¬ ì¤‘ê°„ë¶€í„° ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """,
    version="2.0.0",
    contact={
        "name": "AI Team",
        "email": "c0z0c.dev@gmail.com",
    },
)

manager = multiprocessing.Manager()
JOBS = manager.dict()
PROCESSES = {}
STOP_EVENTS = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    metrics = get_system_metrics()
    logger.info(f"System Check: {metrics}")
    yield
    for pid, proc in PROCESSES.items():
        if proc.is_alive():
            proc.terminate()
    manager.shutdown()

app.router.lifespan_context = lifespan

from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse

# Static files mount
app.mount("/static", StaticFiles(directory=os.path.join(os.path.dirname(__file__), "static")), name="static")
app.mount("/fonts", StaticFiles(directory=os.path.join(os.path.dirname(__file__), "fonts")), name="fonts")

@app.get("/favicon.ico", include_in_schema=False)
async def favicon():
    return FileResponse(os.path.join(os.path.dirname(__file__), "static", "favicon.ico"))

@app.get("/test", response_class=HTMLResponse)
async def test_dashboard():
    """
    ê°œë°œ ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    with open(os.path.join(os.path.dirname(__file__), "templates", "test_dashboard.html"), "r", encoding="utf-8") as f:
        return f.read()

@app.get(
    "/fonts", 
    summary="ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ëª©ë¡ ì¡°íšŒ (Get Font List)",
    response_description="ì„œë²„ì— ì €ì¥ëœ TTF/OTF í°íŠ¸ íŒŒì¼ ëª©ë¡"
)
async def get_fonts():
    """
    ì„œë²„ì˜ `fonts` ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  í°íŠ¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    - **fonts**: í°íŠ¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: `["NanumGothic/NanumGothic.ttf", ...]`)
    
    ì´ ëª©ë¡ì˜ ê°’ì„ `/generate` ìš”ì²­ì˜ `font_name` í•„ë“œì— ì…ë ¥í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    return {"fonts": get_available_fonts()}

@app.post(
    "/generate", 
    summary="AI ê´‘ê³  ìƒì„± ì‘ì—… ì‹œì‘ (Start Generation Job)",
    response_description="ìƒì„±ëœ ì‘ì—…ì˜ IDì™€ ìƒíƒœ",
    status_code=status.HTTP_200_OK,
    responses={
        200: {
            "description": "ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ íì— ë“±ë¡ë˜ê³  ì‹œì‘ë¨",
            "content": {
                "application/json": {
                    "example": {"job_id": "550e8400-e29b-41d4-a716-446655440000", "status": "started"}
                }
            }
        },
        503: {
            "description": "ì„œë²„ê°€ ë‹¤ë¥¸ ì‘ì—…ì„ ì²˜ë¦¬ ì¤‘ì„ (Busy)",
            "content": {
                "application/json": {
                    "example": {
                        "status": "busy",
                        "message": "í˜„ì¬ ë‹¤ë¥¸ ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì•½ 25ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "retry_after": 25
                    }
                }
            }
        }
    }
)
async def generate_ad(req: GenerateRequest, response: Response):
    """
     **ìƒˆë¡œìš´ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.** (Non-blocking)
    
    í´ë¼ì´ì–¸íŠ¸ëŠ” `job_id`ë¥¼ ë°˜í™˜ë°›ì€ í›„, `/status/{job_id}`ë¥¼ í´ë§í•˜ì—¬ ì§„í–‰ ìƒí™©ê³¼ ê²°ê³¼ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
    
    ### Step êµ¬ì¡° ë° ì‹¤í–‰ ë°©ë²•
    1. **Step 1 (Background)**:
       - `start_step=1` (ê¸°ë³¸ê°’)
       - `input_image` (ëˆ„ë¼ ë”¸ ìƒí’ˆ ì´ë¯¸ì§€) í•„ìˆ˜
    2. **Step 2 (Text Asset)**:
       - `start_step=2`
       - `step1_image` (ë°°ê²½ í•©ì„±ëœ ì´ë¯¸ì§€) í•„ìˆ˜
       - í…ìŠ¤íŠ¸ë§Œ ë‹¤ì‹œ ìƒì„±í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
    3. **Step 3 (Composition)**:
       - `start_step=3`
       - `step1_image` (ë°°ê²½), `step2_image` (í…ìŠ¤íŠ¸) í•„ìˆ˜
       - ë‹¨ìˆœíˆ ë‘ ì´ë¯¸ì§€ë¥¼ í•©ì„±ë§Œ ë‹¤ì‹œ í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
       
    ### ë™ì‹œì„± ì •ì±…
    - ì´ ì„œë²„ëŠ” **ë‹¨ì¼ ì‘ì—…(Single Job)**ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - ì´ë¯¸ ì‘ì—…ì´ ëŒê³  ìˆì„ ê²½ìš° **503 Service Unavailable** ì‘ë‹µê³¼ í•¨ê»˜ `Retry-After` í—¤ë”ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    
    # ë™ì‹œì„± ì œì–´
    active_jobs = [j for j, s in JOBS.items() if s['status'] in ('running', 'pending')]
    if active_jobs:
        curr = JOBS[active_jobs[0]]
        elapsed = time.time() - (curr['start_time'] or time.time())
        remain = max(0, TOTAL_ESTIMATED_TIME - elapsed)
        response.status_code = status.HTTP_503_SERVICE_UNAVAILABLE
        response.headers["Retry-After"] = str(int(remain))
        return {"status": "busy", "message": f"Busy. Retry after {int(remain)}s", "retry_after": int(remain)}

    job_id = str(uuid.uuid4())
    stop_event = multiprocessing.Event()
    input_data = req.model_dump()
    
    JOBS[job_id] = manager.dict({
        "status": "pending",
        "progress_percent": 0,
        "current_step": "init",
        "message": "Initializing...",
        "error": None,
        "images": manager.dict(), 
        "start_time": None,
        "parameters": input_data
    })
    
    p = multiprocessing.Process(
        target=worker_process,
        args=(job_id, input_data, JOBS[job_id], stop_event)
    )
    p.start()
    PROCESSES[job_id] = p
    STOP_EVENTS[job_id] = stop_event
    
    return {"job_id": job_id, "status": "started"}

@app.get(
    "/status/{job_id}", 
    response_model=StatusResponse,
    summary="ì‘ì—… ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ (Get Job Status)",
    response_description="ì§„í–‰ë¥ , í˜„ì¬ ë‹¨ê³„, ìƒì„±ëœ ì´ë¯¸ì§€(Base64), ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë° íŒŒë¼ë¯¸í„°"
)
async def get_status(job_id: str):
    """
    íŠ¹ì • ì‘ì—…(Job)ì˜ í˜„ì¬ ì§„í–‰ ìƒí™©ê³¼ ì¤‘ê°„/ìµœì¢… ê²°ê³¼ë¬¼ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ CPU/GPU ì‚¬ìš©ë¥  ë° ì„œë¸ŒìŠ¤í… ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    
    ### ë°˜í™˜ í•„ë“œ ì„¤ëª…
    - **status**: `pending`, `running`, `completed`, `failed`, `stopped`
    - **progress_percent**: 0 ~ 100 ì§„í–‰ë¥ 
    - **current_step**: í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ ë‹¨ê³„ (`step1_background` ë“±)
    - **sub_step**: í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ ì„œë¸Œ ë‹¨ê³„ (`segmentation`, `flux_background_generation` ë“±)
    - **system_metrics**: ì‹¤ì‹œê°„ CPU/RAM/GPU ì‚¬ìš©ë¥ 
    - **parameters**: ì‘ì—… ìƒì„± ì‹œ ì‚¬ìš©ëœ ëª¨ë“  ì…ë ¥ íŒŒë¼ë¯¸í„° (ì¬ì‹œë„ ì‹œ ìœ ìš©)
    - **step1_result**: [Optional] 1ë‹¨ê³„ ê²°ê³¼ (Base64 ì´ë¯¸ì§€)
    - **step2_result**: [Optional] 2ë‹¨ê³„ ê²°ê³¼ (Base64 ì´ë¯¸ì§€)
    - **final_result**: [Optional] ìµœì¢… ê²°ê³¼ (Base64 ì´ë¯¸ì§€)
    """
    if job_id not in JOBS:
        raise HTTPException(status_code=404, detail="Job not found")
    
    state = JOBS[job_id]
    elapsed = time.time() - state['start_time'] if state['start_time'] else 0
    
    # ManagerDict -> dict copy needed before serializing
    images_snapshot = dict(state['images'])
    
    # ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
    current_metrics = get_system_metrics()
    system_metrics_model = SystemMetrics(
        cpu_percent=current_metrics['cpu_percent'],
        ram_used_gb=current_metrics['ram_used_gb'],
        ram_total_gb=current_metrics['ram_total_gb'],
        ram_percent=current_metrics['ram_percent'],
        gpu_info=[GPUMetric(**gpu) for gpu in current_metrics['gpu_info']]
    )
    
    return StatusResponse(
        job_id=job_id,
        status=state['status'],
        progress_percent=state['progress_percent'],
        current_step=state['current_step'],
        sub_step=state.get('sub_step'),
        message=state['message'],
        elapsed_sec=round(elapsed, 1),
        system_metrics=system_metrics_model,
        parameters=state.get('parameters', {}),
        step1_result=images_snapshot.get('step1_result'),
        step2_result=images_snapshot.get('step2_result'),
        final_result=images_snapshot.get('final_result')
    )

@app.post(
    "/stop/{job_id}", 
    summary="ì‘ì—… ê°•ì œ ì¤‘ë‹¨ (Stop Job)",
    response_description="ì¤‘ë‹¨ ìš”ì²­ ê²°ê³¼"
)
async def stop_job(job_id: str):
    """
    ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ì„ ì¦‰ì‹œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
    GPU ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•˜ê³  ì‘ì—…ì„ `stopped` ìƒíƒœë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
    """
    if job_id in STOP_EVENTS:
        STOP_EVENTS[job_id].set()
    
    if job_id in PROCESSES:
        p = PROCESSES[job_id]
        if p.is_alive():
            p.join(timeout=3)
            if p.is_alive(): p.terminate()
        
        if job_id in JOBS: JOBS[job_id]['status'] = 'stopped'
        return {"job_id": job_id, "status": "stopped"}
        
    raise HTTPException(status_code=404, detail="Job not found")
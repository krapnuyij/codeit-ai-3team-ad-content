import multiprocessing
import time
from PIL import Image, ImageDraw, ImageFont

from config import logger
from utils import pil_to_base64, base64_to_pil, flush_gpu, pil_canny_edge, get_available_fonts, get_font_path
from AIModelEngine import AIModelEngine

# ==========================================
# ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ (Background Worker)
# ==========================================
def worker_process(job_id: str, input_data: dict, shared_state: dict, stop_event: multiprocessing.Event):
    """
    Step ê¸°ë°˜(1->2->3) ìˆœì°¨ ì‹¤í–‰ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤.
    """
    
    # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    test_mode = input_data.get('test_mode', False)
    
    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜
    def update_progress(step_num, total_steps, sub_step_name):
        """
        ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ì˜ ì§„í–‰ë¥ ì„ shared_stateì— ë°˜ì˜í•©ë‹ˆë‹¤.
        
        Args:
            step_num: í˜„ì¬ ìŠ¤í… (1-based)
            total_steps: ì „ì²´ ìŠ¤í… ìˆ˜
            sub_step_name: ì„œë¸Œ ìŠ¤í… ì´ë¦„
        """
        # í˜„ì¬ ë©”ì¸ ìŠ¤í… í™•ì¸
        current_main_step = shared_state.get('current_step', 'step1_background')
        
        # ë©”ì¸ ìŠ¤í…ë³„ ì§„í–‰ë¥  ë²”ìœ„ ì •ì˜
        # Step 1: 0-33%, Step 2: 33-66%, Step 3: 66-100%
        if 'step1' in current_main_step:
            base_progress = 0
            step_range = 33
        elif 'step2' in current_main_step:
            base_progress = 33
            step_range = 33
        elif 'step3' in current_main_step:
            base_progress = 66
            step_range = 34
        else:
            base_progress = 0
            step_range = 33
        
        # ì„œë¸Œ ìŠ¤í… ë‚´ ì§„í–‰ë¥  ê³„ì‚° (0.0 ~ 1.0)
        sub_progress = step_num / total_steps
        
        # ìµœì¢… ì§„í–‰ë¥  = ë² ì´ìŠ¤ + (ì„œë¸Œ ì§„í–‰ë¥  * ìŠ¤í… ë²”ìœ„)
        final_progress = int(base_progress + (sub_progress * step_range))
        final_progress = min(100, max(0, final_progress))
        
        shared_state['progress_percent'] = final_progress
        shared_state['sub_step'] = f"{sub_step_name} ({step_num}/{total_steps})"
        from utils import get_system_metrics
        shared_state['system_metrics'] = get_system_metrics()
    
    engine = AIModelEngine(dummy_mode=test_mode, progress_callback=update_progress)
    
    try:
        shared_state['status'] = 'running'
        shared_state['start_time'] = time.time()
        shared_state['sub_step'] = None
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê³„ì†)
        start_step = input_data.get('start_step', 1)
        
        bg_prompt = input_data.get('bg_prompt')
        text_model_prompt = input_data.get('text_model_prompt')
        negative_prompt = input_data.get('negative_prompt')
        text_content = input_data.get('text_content', "Special Sale")
        
        strength = input_data.get('strength', 0.6)
        guidance_scale = input_data.get('guidance_scale', 3.5)
        seed = input_data.get('seed') 

        # ë‹¨ê³„ë³„ ê²°ê³¼ë¬¼ ë³€ìˆ˜ (PIL Image)
        step1_result = None
        step2_result = None
        final_result = None

        # ==========================================
        # Step 1: ë°°ê²½ ìƒì„± (Background Generation)
        # ==========================================
        if start_step <= 1:
            if stop_event.is_set(): return

            shared_state['current_step'] = 'step1_background'
            shared_state['message'] = 'Step 1: Generating Background... (ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì¤‘)'
            
            # ì…ë ¥ í™•ì¸
            input_img_b64 = input_data.get('input_image')
            if not input_img_b64:
                raise ValueError("[Step 1 Error] 'input_image' is required to start from Step 1.")
            raw_img = base64_to_pil(input_img_b64)
            
            # [Logic]
            # 1. ëˆ„ë¼ (Segmentation)
            shared_state['sub_step'] = 'segmentation'
            from utils import get_system_metrics
            shared_state['system_metrics'] = get_system_metrics()
            product_fg, mask = engine.run_segmentation(raw_img)
            
            # 2. ë°°ê²½ ìƒì„± (Flux Text-to-Image)
            shared_state['sub_step'] = 'flux_background_generation'
            shared_state['system_metrics'] = get_system_metrics()
            bg_negative_prompt = input_data.get('bg_negative_prompt')
            bg_img = engine.run_flux_bg_gen(prompt=bg_prompt, negative_prompt=bg_negative_prompt, guidance_scale=guidance_scale, seed=seed)
            
            # 3. ì´ˆì•ˆ í•©ì„± (Composite Draft)
            shared_state['sub_step'] = 'compositing_draft'
            shared_state['system_metrics'] = get_system_metrics()
            bg_w, bg_h = bg_img.size
            scale = 0.4
            fg_resized = product_fg.resize((int(product_fg.width*scale), int(product_fg.height*scale)), Image.LANCZOS)
            x = (bg_w - fg_resized.width) // 2
            y = int(bg_h * 0.55)
            
            base_comp = bg_img.convert("RGBA")
            fg_layer = Image.new("RGBA", bg_img.size)
            fg_layer.paste(fg_resized, (x, y))
            base_comp = Image.alpha_composite(base_comp, fg_layer)
            draft_final = base_comp.convert("RGB")
            
            # 4. ë¦¬íŒŒì¸ (Flux Img-to-Img)
            shared_state['sub_step'] = 'flux_refinement'
            shared_state['system_metrics'] = get_system_metrics()
            refined_base = engine.run_flux_refinement(
                draft_final, 
                strength=strength, 
                guidance_scale=guidance_scale, 
                seed=seed
            )
            
            step1_result = refined_base
            shared_state['images']['step1_result'] = pil_to_base64(step1_result)
            shared_state['progress_percent'] = 33
            
        else:
            # Step 1ì„ ê±´ë„ˆë›¸ ê²½ìš°, ì…ë ¥ë°›ì€ step1_image ì‚¬ìš©
            img_s1_b64 = input_data.get('step1_image')
            if img_s1_b64:
                # shared_state['message'] = 'Step 1 Skipped. Using provided image.'
                step1_result = base64_to_pil(img_s1_b64)
                shared_state['images']['step1_result'] = img_s1_b64
            else:
                # 2ë‹¨ê³„ ì´ìƒë¶€í„° ì‹œì‘í•˜ëŠ”ë° 1ë‹¨ê³„ ê²°ê³¼ë¬¼ì´ ì—†ìœ¼ë©´ ì¹˜ëª…ì ì¼ ìˆ˜ ìˆìŒ(3ë‹¨ê³„ì—ì„œ í•„ìš” ì‹œ)
                # ë‹¨, 2ë‹¨ê³„ë§Œ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ê²½ìš° ë“±ì—ëŠ” ì—†ì„ ìˆ˜ë„ ìˆìŒ.
                pass

        # ==========================================
        # Step 2: í…ìŠ¤íŠ¸ ì—ì…‹ ìƒì„± (Text Asset Gen)
        # ==========================================
        if start_step <= 2:
            if stop_event.is_set(): return

            shared_state['current_step'] = 'step2_text'
            shared_state['message'] = 'Step 2: Generating 3D Text... (3D í…ìŠ¤íŠ¸ ìƒì„± ì¤‘)'
            
            # [Logic]
            # 1. í°íŠ¸ ë° ìº”ë²„ìŠ¤ ì¤€ë¹„
            shared_state['sub_step'] = 'preparing_text_canvas'
            shared_state['system_metrics'] = get_system_metrics()
            W, H = 1024, 1024 # ê¸°ë³¸ ìº”ë²„ìŠ¤ í¬ê¸°
            
            font_name = input_data.get('font_name')
            if not font_name:
                avail_fonts = get_available_fonts()
                font_name = avail_fonts[0] if avail_fonts else None
            
            try:
                font_path = get_font_path(font_name) if font_name else None
                font = ImageFont.truetype(font_path, 160) if font_path else ImageFont.load_default()
            except Exception as e:
                logger.warning(f"Font load failed: {e}")
                font = ImageFont.load_default()
            
            text_guide = Image.new("RGB", (W, H), "black")
            draw = ImageDraw.Draw(text_guide)
            
            bbox = draw.textbbox((0,0), text_content, font=font)
            tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]
            text_x, text_y = (W - tw) // 2, 100
            
            draw.text((text_x, text_y), text_content, font=font, fill="white")
            canny_map = pil_canny_edge(text_guide)
            
            # 2. SDXL ControlNet
            shared_state['sub_step'] = 'sdxl_text_generation'
            shared_state['system_metrics'] = get_system_metrics()
            raw_3d_text = engine.run_sdxl_text_gen(
                canny_map, 
                prompt=text_model_prompt,
                negative_prompt=negative_prompt
            )
            
            # 3. ë°°ê²½ ì œê±° (Text Segmentation)
            shared_state['sub_step'] = 'text_segmentation'
            shared_state['system_metrics'] = get_system_metrics()
            transparent_text, _ = engine.run_segmentation(raw_3d_text)
            
            step2_result = transparent_text
            shared_state['images']['step2_result'] = pil_to_base64(step2_result)
            shared_state['progress_percent'] = 66
            
        else:
             # Step 2 ê±´ë„ˆë›¸ ê²½ìš°
            img_s2_b64 = input_data.get('step2_image')
            if img_s2_b64:
                step2_result = base64_to_pil(img_s2_b64)
                shared_state['images']['step2_result'] = img_s2_b64

        # ==========================================
        # Step 3: ìµœì¢… í•©ì„± (Final Composite)
        # ==========================================
        if start_step <= 3:
            if stop_event.is_set(): return

            shared_state['current_step'] = 'step3_composite'
            shared_state['message'] = 'Step 3: Final Compositing... (ìµœì¢… í•©ì„± ì¤‘)'
            shared_state['sub_step'] = 'final_composite'
            shared_state['system_metrics'] = get_system_metrics()
            
            # Step 1, Step 2 ê²°ê³¼ë¬¼ í™•ë³´ í™•ì¸
            if not step1_result and shared_state['images'].get('step1_result'):
                step1_result = base64_to_pil(shared_state['images']['step1_result'])
                
            if not step2_result and shared_state['images'].get('step2_result'):
                step2_result = base64_to_pil(shared_state['images']['step2_result'])
                
            if not step1_result:
                raise ValueError("[Step 3 Error] Missing 'step1_result'. Cannot composite.")
            if not step2_result:
                raise ValueError("[Step 3 Error] Missing 'step2_result'. Cannot composite.")
            
            # [Logic] í•©ì„±
            base_comp = step1_result.convert("RGBA")
            text_asset = step2_result.convert("RGBA")
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë“±ì€ í˜„ì¬ ê³ ì • (ì¶”í›„ íŒŒë¼ë¯¸í„°í™” ê°€ëŠ¥)
            # text_assetì€ 1024x1024 ì „ì²´ ìº”ë²„ìŠ¤ ê¸°ì¤€ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ê²¹ì¹˜ë©´ ë¨ (ìœ„ì¹˜ ì¡°ì •ì€ Step 2ì—ì„œ ì´ë¯¸ ê²°ì •ë¨)
            if base_comp.size != text_asset.size:
                text_asset = text_asset.resize(base_comp.size, Image.LANCZOS)
                
            final_comp = Image.alpha_composite(base_comp, text_asset)
            final_result = final_comp.convert("RGB")
            
            shared_state['images']['final_result'] = pil_to_base64(final_result)
            shared_state['progress_percent'] = 100

        # ì™„ë£Œ ì²˜ë¦¬
        if stop_event.is_set():
            shared_state['status'] = 'stopped'
            shared_state['message'] = 'Job stopped by user.'
        else:
            shared_state['status'] = 'completed'
            shared_state['message'] = 'All steps completed successfully.'

    finally:
        flush_gpu()

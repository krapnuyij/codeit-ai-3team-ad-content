import sys
from pathlib import Path

project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

import torch
import gc
from PIL import Image
from diffusers import (
    FluxPipeline,
    FluxImg2ImgPipeline,
    FluxInpaintPipeline,
    FluxTransformer2DModel,
)
from transformers import BitsAndBytesConfig
from config import MODEL_IDS, TORCH_DTYPE, logger
from utils import flush_gpu


class FluxGenerator:
    """
    FLUX ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ ìƒì„±, ì´ë¯¸ì§€ ë¦¬íŒŒì¸, ì§€ëŠ¥í˜• í•©ì„±ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    def generate_background(
        self,
        prompt: str,
        negative_prompt: str = None,
        guidance_scale: float = 3.5,
        seed: int = None,
        progress_callback=None,
    ) -> Image.Image:
        """
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            prompt (str): ë°°ê²½ ìƒì„± í”„ë¡¬í”„íŠ¸
            negative_prompt (str, optional): ë°°ì œí•  ìš”ì†Œë“¤ì— ëŒ€í•œ ë¶€ì • í”„ë¡¬í”„íŠ¸
            guidance_scale (float): í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê°•ë„
            seed (int, optional): ë‚œìˆ˜ ì‹œë“œ
            progress_callback (callable, optional): ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜

        Returns:
            Image.Image: ìƒì„±ëœ ì´ë¯¸ì§€
        """
        print(
            "[Engine] Loading FLUX (Text-to-Image)... (FLUX í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ ë¡œë”© ì¤‘)"
        )
        flush_gpu()

        quant_config = BitsAndBytesConfig(load_in_8bit=True)
        transformer = FluxTransformer2DModel.from_pretrained(
            MODEL_IDS["FLUX"],
            subfolder="transformer",
            quantization_config=quant_config,
            torch_dtype=TORCH_DTYPE,
        )
        pipe = FluxPipeline.from_pretrained(
            MODEL_IDS["FLUX"], transformer=transformer, torch_dtype=TORCH_DTYPE
        )
        pipe.enable_model_cpu_offload()

        generator = None
        if seed is not None:
            generator = torch.Generator("cpu").manual_seed(seed)

        num_steps = 25

        def callback_fn(pipe_obj, step_index, timestep, callback_kwargs):
            if progress_callback:
                progress_callback(step_index + 1, num_steps, "flux_bg_generation")
            return callback_kwargs

        image = pipe(
            prompt,
            negative_prompt=negative_prompt,
            height=1024,
            width=1024,
            num_inference_steps=num_steps,
            guidance_scale=guidance_scale,
            generator=generator,
            callback_on_step_end=callback_fn if progress_callback else None,
        ).images[0]

        del pipe, transformer
        flush_gpu()
        return image

    def unload(self) -> None:
        """
        ëª…ì‹œì ìœ¼ë¡œ Flux ëª¨ë¸ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.

        í˜„ì¬ FluxëŠ” ê° ë©”ì„œë“œ í˜¸ì¶œ ì‹œë§ˆë‹¤ ë¡œë“œ/ì–¸ë¡œë“œí•˜ë¯€ë¡œ
        ë³„ë„ ì •ë¦¬ ì‘ì—…ì´ ë¶ˆí•„ìš”í•˜ì§€ë§Œ, ì¸í„°í˜ì´ìŠ¤ í†µì¼ì„ ìœ„í•´ êµ¬í˜„í•©ë‹ˆë‹¤.
        """
        from services.monitor import log_gpu_memory

        log_gpu_memory("FluxGenerator unload (no-op)")
        flush_gpu()
        logger.info("ğŸ§¹ FluxGenerator unloaded")

    def refine_image(
        self,
        draft_image: Image.Image,
        prompt: str = None,
        negative_prompt: str = None,
        strength: float = 0.6,
        guidance_scale: float = 3.5,
        seed: int = None,
        progress_callback=None,
    ) -> Image.Image:
        """
        ì´ë¯¸ì§€ë¥¼ ë¦¬í„°ì¹­(Img2Img, ë°°ê²½ í•©ì„±)í•˜ì—¬ í’ˆì§ˆì„ ë†’ì…ë‹ˆë‹¤.

        Args:
            draft_image (Image.Image): ì´ˆì•ˆ ì´ë¯¸ì§€
            prompt (str): ë°°ê²½ í•©ì„± í”„ë¡¬í”„íŠ¸ (ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©)
            negative_prompt (str): ë°°ê²½ í•©ì„± ë¶€ì • í”„ë¡¬í”„íŠ¸ (ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©)
            strength (float): ë³€í™˜ ê°•ë„
            guidance_scale (float): í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê°•ë„
            seed (int, optional): ë‚œìˆ˜ ì‹œë“œ
            progress_callback (callable, optional): ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜

        Returns:
            Image.Image: ë¦¬í„°ì¹­ëœ ë°°ê²½ í•©ì„± ì´ë¯¸ì§€
        """
        print(
            "[Engine] Loading FLUX (Img-to-Img for Background Composition)... (FLUX ë°°ê²½ í•©ì„± ëª¨ë¸ ë¡œë”© ì¤‘)"
        )
        flush_gpu()

        quant_config = BitsAndBytesConfig(load_in_8bit=True)
        transformer = FluxTransformer2DModel.from_pretrained(
            MODEL_IDS["FLUX"],
            subfolder="transformer",
            quantization_config=quant_config,
            torch_dtype=TORCH_DTYPE,
        )
        pipe = FluxImg2ImgPipeline.from_pretrained(
            MODEL_IDS["FLUX"], transformer=transformer, torch_dtype=TORCH_DTYPE
        )
        pipe.enable_model_cpu_offload()

        default_prompt = (
            "A photorealistic close-up shot of a product lying naturally on a surface. "
            "Heavy contact shadows, ambient occlusion, texture reflection, "
            "warm sunlight, cinematic lighting, 8k, extremely detailed."
        )
        use_prompt = prompt if prompt else default_prompt

        default_negative = "floating, disconnected, unrealistic shadows, artificial lighting, cut out, sticker effect"
        use_negative = negative_prompt if negative_prompt else default_negative

        generator = None
        if seed is not None:
            generator = torch.Generator("cpu").manual_seed(seed)
        else:
            generator = torch.Generator("cpu").manual_seed(42)

        num_steps = 30

        def callback_fn(pipe_obj, step_index, timestep, callback_kwargs):
            if progress_callback:
                progress_callback(
                    step_index + 1, num_steps, "flux_bg_composition_refinement"
                )
            return callback_kwargs

        refined_image = pipe(
            use_prompt,
            negative_prompt=use_negative,
            image=draft_image,
            strength=strength,
            num_inference_steps=num_steps,
            guidance_scale=guidance_scale,
            generator=generator,
            callback_on_step_end=callback_fn if progress_callback else None,
        ).images[0]

        del pipe, transformer
        flush_gpu()
        return refined_image

    def inject_features_via_inpaint(
        self,
        background: Image.Image,
        product_foreground: Image.Image,
        product_mask: Image.Image,
        position: tuple,
        prompt: str,
        negative_prompt: str = None,
        strength: float = 0.5,
        guidance_scale: float = 3.5,
        num_inference_steps: int = 28,
        seed: int = None,
        progress_callback=None,
    ) -> Image.Image:
        """
        Flux Inpaintingì„ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆì˜ íŠ¹ì„±ì„ ë°°ê²½ì— ì£¼ì…í•©ë‹ˆë‹¤.

        í”„ë¡œì„¸ìŠ¤:
        1. ë°°ê²½ ì´ë¯¸ì§€ì— ìƒí’ˆ ìœ„ì¹˜ ë§ˆìŠ¤í‚¹
        2. ìƒí’ˆ ì˜ì—­ì— Inpaintingìœ¼ë¡œ íŠ¹ì„± ì£¼ì…
        3. ê²°ê³¼: ìƒí’ˆì´ ë°°ê²½ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©ëœ ì´ë¯¸ì§€

        Args:
            background (Image.Image): ë°°ê²½ ì´ë¯¸ì§€
            product_foreground (Image.Image): ìƒí’ˆ ì´ë¯¸ì§€ (íˆ¬ëª… ë°°ê²½, RGBA)
            product_mask (Image.Image): ìƒí’ˆ ë§ˆìŠ¤í¬ (L ëª¨ë“œ, 255=ìƒí’ˆ ì˜ì—­)
            position (tuple): ìƒí’ˆ ë°°ì¹˜ ìœ„ì¹˜ (x, y)
            prompt (str): íŠ¹ì„± ì£¼ì… í”„ë¡¬í”„íŠ¸
            negative_prompt (str, optional): ë¶€ì • í”„ë¡¬í”„íŠ¸
            strength (float): Inpainting ê°•ë„ (0.0~1.0)
            guidance_scale (float): í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê°•ë„
            num_inference_steps (int): ì¶”ë¡  ìŠ¤í… ìˆ˜
            seed (int, optional): ë‚œìˆ˜ ì‹œë“œ
            progress_callback (callable, optional): ì§„í–‰ë¥  ì½œë°±

        Returns:
            Image.Image: íŠ¹ì„±ì´ ì£¼ì…ëœ ìµœì¢… ì´ë¯¸ì§€
        """
        logger.info("[FluxGenerator] Loading FLUX Inpainting for feature injection...")
        flush_gpu()

        try:
            # Flux Inpainting íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            quant_config = BitsAndBytesConfig(load_in_8bit=True)
            transformer = FluxTransformer2DModel.from_pretrained(
                MODEL_IDS["FLUX"],
                subfolder="transformer",
                quantization_config=quant_config,
                torch_dtype=TORCH_DTYPE,
            )
            pipe = FluxInpaintPipeline.from_pretrained(
                MODEL_IDS["FLUX"], transformer=transformer, torch_dtype=TORCH_DTYPE
            )
            pipe.enable_model_cpu_offload()

            # ì´ˆì•ˆ ì´ë¯¸ì§€ ìƒì„± (ìƒí’ˆì„ ë°°ê²½ì— ì„ì‹œ ë°°ì¹˜)
            draft = background.copy().convert("RGBA")
            draft.paste(product_foreground, position, product_foreground)
            draft_rgb = draft.convert("RGB")

            # Generator ì„¤ì •
            generator = None
            if seed is not None:
                generator = torch.Generator("cpu").manual_seed(seed)
            else:
                generator = torch.Generator("cpu").manual_seed(42)

            # Progress callback
            def callback_fn(pipe_obj, step_index, timestep, callback_kwargs):
                if progress_callback:
                    progress_callback(
                        step_index + 1, num_inference_steps, "flux_feature_injection"
                    )
                return callback_kwargs

            logger.info(
                f"[FluxGenerator] Injecting features: prompt='{prompt[:50]}...', strength={strength}"
            )

            # Inpainting ì‹¤í–‰ (ìƒí’ˆ ì˜ì—­ë§Œ ì¬ìƒì„±í•˜ì—¬ íŠ¹ì„± ì£¼ì…)
            result = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                image=draft_rgb,
                mask_image=product_mask,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
                generator=generator,
                callback_on_step_end=callback_fn if progress_callback else None,
            ).images[0]

            logger.info("[FluxGenerator] Feature injection completed")

            del pipe, transformer
            flush_gpu()

            return result

        except Exception as e:
            logger.error(
                f"[FluxGenerator] Feature injection failed: {e}", exc_info=True
            )
            flush_gpu()
            raise

    def inpaint_composite(
        self,
        background: Image.Image,
        text_asset: Image.Image,
        mask: Image.Image,
        prompt: str,
        strength: float = 0.4,
        guidance_scale: float = 3.5,
        num_inference_steps: int = 28,
        seed: int = None,
        progress_callback=None,
    ) -> Image.Image:
        """
        Flux Inpaintingì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ê²½ê³¼ ë§¥ë½ì ìœ¼ë¡œ í•©ì„±í•©ë‹ˆë‹¤.

        Args:
            background (Image.Image): ë°°ê²½ ì´ë¯¸ì§€
            text_asset (Image.Image): í…ìŠ¤íŠ¸ ì—ì…‹ (RGBA)
            mask (Image.Image): í•©ì„± ì˜ì—­ ë§ˆìŠ¤í¬ (255=ì¸í˜ì¸íŒ…, 0=ë³´ì¡´)
            prompt (str): í•©ì„± í”„ë¡¬í”„íŠ¸
            strength (float): ë³€í™˜ ê°•ë„ (0.0~1.0)
            guidance_scale (float): í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê°•ë„
            num_inference_steps (int): ì¶”ë¡  ìŠ¤í… ìˆ˜ (í’ˆì§ˆ ìš°ì„ : 28~50)
            seed (int, optional): ë‚œìˆ˜ ì‹œë“œ
            progress_callback (callable, optional): ì§„í–‰ë¥  ì½œë°±

        Returns:
            Image.Image: í•©ì„±ëœ ìµœì¢… ì´ë¯¸ì§€
        """
        logger.info("[FluxGenerator] Loading FLUX Inpainting for composition...")
        flush_gpu()

        try:
            # Flux Inpainting íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            quant_config = BitsAndBytesConfig(load_in_8bit=True)
            transformer = FluxTransformer2DModel.from_pretrained(
                MODEL_IDS["FLUX"],
                subfolder="transformer",
                quantization_config=quant_config,
                torch_dtype=TORCH_DTYPE,
            )
            pipe = FluxInpaintPipeline.from_pretrained(
                MODEL_IDS["FLUX"], transformer=transformer, torch_dtype=TORCH_DTYPE
            )
            pipe.enable_model_cpu_offload()

            # ì´ˆì•ˆ í•©ì„± (í…ìŠ¤íŠ¸ë¥¼ ë°°ê²½ì— ë°°ì¹˜)
            draft = background.copy().convert("RGBA")
            text_resized = text_asset.resize(draft.size, Image.LANCZOS)
            draft.paste(text_resized, (0, 0), text_resized)
            draft_rgb = draft.convert("RGB")

            # Generator ì„¤ì •
            generator = None
            if seed is not None:
                generator = torch.Generator("cpu").manual_seed(seed)
            else:
                generator = torch.Generator("cpu").manual_seed(42)

            # Progress callback
            def callback_fn(pipe_obj, step_index, timestep, callback_kwargs):
                if progress_callback:
                    progress_callback(
                        step_index + 1, num_inference_steps, "flux_inpaint_composite"
                    )
                return callback_kwargs

            logger.info(
                f"[FluxGenerator] Running inpainting: prompt='{prompt[:50]}...', steps={num_inference_steps}"
            )

            # Inpainting ì‹¤í–‰
            result = pipe(
                prompt=prompt,
                image=draft_rgb,
                mask_image=mask,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
                generator=generator,
                callback_on_step_end=callback_fn if progress_callback else None,
            ).images[0]

            logger.info("[FluxGenerator] Inpainting composition completed")

            del pipe, transformer
            flush_gpu()

            return result

        except Exception as e:
            logger.error(f"[FluxGenerator] Inpainting failed: {e}", exc_info=True)
            flush_gpu()
            raise

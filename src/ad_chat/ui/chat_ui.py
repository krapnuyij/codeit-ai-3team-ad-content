"""
UI ì»´í¬ë„ŒíŠ¸: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

LLMAdapterë¥¼ í†µí•œ ìì—°ì–´ ê¸°ë°˜ ê´‘ê³  ê¸°íš ë° MCP ì„œë²„ ì‘ì—… ìš”ì²­
"""

import streamlit as st
import re
import json
import asyncio
import logging
from pathlib import Path
from typing import Any, Dict, Optional
from helper_streamlit_utils import *

from config import (
    OPENAI_MODEL,
    OPENAI_TEMPERATURE,
    OPENAI_MAX_COMPLETION_TOKENS,
    MCP_SERVER_URL,
    MCP_TIMEOUT,
    UPLOADS_DIR,
    RESULTS_DIR,
    JOB_TYPE_FULL,
    STATUS_PROCESSING,
    STATUS_COMPLETED,
    STATUS_FAILED,
    POLLING_INTERVAL,
)
from services import LLMAdapter, MongoManager, MCPClient, get_job_store
from utils.state_manager import (
    add_chat_message,
    get_session_value,
    set_page,
    logout,
    reset_for_new_ad,
)
import time
from PIL import Image as PILImage

logger = logging.getLogger(__name__)

# ì‘ì—… ì €ì¥ì†Œ (MongoDB ëŒ€ì•ˆ)
job_store = get_job_store()


async def _get_current_time_async():
    """í˜„ì¬ ì‹œê°„ ë°˜í™˜ (ë¹„ë™ê¸° ë˜í¼)"""
    from datetime import datetime

    return datetime.now().isoformat()


async def reset_chat_and_server() -> None:
    """
    ìƒˆë¡œìš´ ê´‘ê³ ë¥¼ ìœ„í•œ ì±„íŒ… ë° ì„œë²„ ì´ˆê¸°í™”

    1. MCP ì„œë²„ ìƒíƒœ ì´ˆê¸°í™” (ëª¨ë“  ì‘ì—… ì¤‘ë‹¨ ë° ì‚­ì œ)
    2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì±„íŒ… íˆìŠ¤í† ë¦¬, ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ë“±)
    """
    try:
        # 1. MCP ì„œë²„ ì´ˆê¸°í™” (REST API í˜¸ì¶œ)
        async with MCPClient(base_url=MCP_SERVER_URL, timeout=MCP_TIMEOUT) as client:
            result = await client.server_reset()
            logger.info(f"ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ: {result}")

        # 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        reset_for_new_ad()

        logger.info("ìƒˆë¡œìš´ ê´‘ê³ ë¥¼ ìœ„í•œ ì´ˆê¸°í™” ì™„ë£Œ")

    except Exception as e:
        logger.error(f"ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


async def load_fonts_async() -> Optional[list]:
    """
    MCP ì„œë²„ì—ì„œ í°íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ

    Returns:
        í°íŠ¸ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (JSON) ë˜ëŠ” None (ë¡œë“œ ì‹¤íŒ¨ ì‹œ)
    """
    max_retries = 2
    retry_delay = 2  # ì´ˆ

    for attempt in range(max_retries):
        try:
            logger.info(f"í°íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹œë„ {attempt + 1}/{max_retries}")
            logger.info(f"MCP ì„œë²„ URL: {MCP_SERVER_URL}, íƒ€ì„ì•„ì›ƒ: {MCP_TIMEOUT}ì´ˆ")

            # íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ì¦ê°€ (í°íŠ¸ ë©”íƒ€ë°ì´í„°ëŠ” í•œ ë²ˆë§Œ ë¡œë“œ)
            async with MCPClient(base_url=MCP_SERVER_URL, timeout=60) as client:
                result = await client.call_tool("get_fonts_metadata", {})

                logger.info(f"í°íŠ¸ ë©”íƒ€ë°ì´í„° ì‘ë‹µ ìˆ˜ì‹ : íƒ€ì…={type(result)}")

                # ê²°ê³¼ íŒŒì‹±
                if isinstance(result, str):
                    fonts = json.loads(result)
                else:
                    fonts = result

                if not fonts:
                    logger.warning("í°íŠ¸ ë©”íƒ€ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")
                    return []

                logger.info(f"âœ“ í°íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(fonts)}ê°œ")
                return fonts

        except json.JSONDecodeError as e:
            logger.error(
                f"í°íŠ¸ ë©”íƒ€ë°ì´í„° JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}",
                exc_info=True,
            )
        except Exception as e:
            logger.error(
                f"í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {type(e).__name__}: {e}",
                exc_info=True,
            )

        # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„ ëŒ€ê¸°
        if attempt < max_retries - 1:
            logger.info(f"{retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
            await asyncio.sleep(retry_delay)

    logger.error(f"ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ({max_retries}íšŒ). None ë°˜í™˜")
    return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜í•˜ì—¬ ì—ëŸ¬ ìƒíƒœ ëª…í™•íˆ êµ¬ë¶„


def render_chat_ui() -> None:
    """
    ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§

    LLMAdapterë¥¼ í†µí•œ ëŒ€í™”í˜• ê´‘ê³  ê¸°íš ë° MCP ì„œë²„ ì‘ì—… ìš”ì²­
    """
    # í°íŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ (1íšŒë§Œ)
    if st.session_state.font_metadata is None:
        with st.spinner("í°íŠ¸ ëª©ë¡ ë¡œë”© ì¤‘..."):
            st.session_state.font_metadata = asyncio.run(load_fonts_async())

    # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ê²½ê³  (Noneì¸ ê²½ìš°ì—ë§Œ, ë¹ˆ ë¦¬ìŠ¤íŠ¸ëŠ” ì •ìƒ)
    if st.session_state.font_metadata is None:
        st.error("âŒ í°íŠ¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    elif len(st.session_state.font_metadata) == 0:
        st.info("â„¹ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    # ìƒë‹¨ ë©”ë‰´
    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
    with col1:
        st.subheader("ğŸ’¬ AI ê´‘ê³  ê¸°íš ì±„íŒ…")

    with col2:
        if st.button("â• ìƒˆë¡œìš´ ê´‘ê³ ", width="content"):
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ í™•ì¸ íŒì—…
            if st.session_state.chat_history:
                st.session_state.show_reset_confirm = True
            else:
                # íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ì´ˆê¸°í™”
                asyncio.run(reset_chat_and_server())
            st.rerun()

    with col3:
        if st.button("ğŸ“ íˆìŠ¤í† ë¦¬", width="content"):
            set_page("history")
            st.rerun()
    with col4:
        if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ", width="content"):
            logout()
            st.rerun()

    # ì´ˆê¸°í™” í™•ì¸ íŒì—…
    if get_session_value("show_reset_confirm", False):
        with st.container():
            st.warning(
                "âš ï¸ í˜„ì¬ ëŒ€í™” ë‚´ìš©ê³¼ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì´ ëª¨ë‘ ì´ˆê¸°í™”ë©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
            )
            col_yes, col_no, col_spacer = st.columns([1, 1, 3])
            with col_yes:
                if st.button("âœ… ì˜ˆ", key="confirm_reset"):
                    st.session_state.show_reset_confirm = False
                    asyncio.run(reset_chat_and_server())
                    st.rerun()
            with col_no:
                if st.button("âŒ ì•„ë‹ˆì˜¤", key="cancel_reset"):
                    st.session_state.show_reset_confirm = False
                    st.rerun()

    st_div_divider()

    # ëª¨ë‹ˆí„°ë§ ì¤‘ì¸ ì‘ì—… í™•ì¸ ë° ì™„ë£Œ ì•Œë¦¼
    check_and_display_completed_jobs()

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    chat_container = st.container()
    with chat_container:
        for msg in st.session_state.chat_history:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ê´‘ê³  ì•„ì´ë””ì–´ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”...")

    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        add_chat_message("user", user_input)
        with st.chat_message("user"):
            st.write(user_input)

        # AI ì‘ë‹µ ìƒì„± (LLMAdapter - ìë™ MCP ë„êµ¬ í˜¸ì¶œ)
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                response, job_id, tool_params = asyncio.run(
                    generate_ai_response_async(user_input)
                )
                st.write(response)
                add_chat_message("assistant", response)

                # job_idê°€ ìˆìœ¼ë©´ MongoDBì— ì €ì¥ ë° ì•ˆë‚´
                if job_id:
                    handle_job_creation(job_id, user_input, tool_params)

        st.rerun()


async def generate_ai_response_async(user_message: str):
    """
    LLMAdapterë¥¼ í†µí•œ AI ì‘ë‹µ ìƒì„± ë° ìë™ MCP ë„êµ¬ í˜¸ì¶œ

    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€

    Returns:
        (AI ì‘ë‹µ í…ìŠ¤íŠ¸, job_id ë˜ëŠ” None, ë„êµ¬ íŒŒë¼ë¯¸í„° ë˜ëŠ” None)
    """
    api_key = get_session_value("openai_key")

    # ì œí’ˆ ì´ë¯¸ì§€ ìë™ ìƒì„± (ì—†ì„ ê²½ìš°)
    product_image = UPLOADS_DIR / "test_product.png"
    if not product_image.exists():
        create_test_product_image(product_image)

    # í°íŠ¸ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    font_metadata = st.session_state.get("font_metadata", [])
    font_info_section = ""

    if font_metadata:
        # í°íŠ¸ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ í¬ë§·íŒ…
        font_list = []
        for font in font_metadata[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ (í† í° ì ˆì•½)
            name = font.get("name", "Unknown")
            style = font.get("style", "")
            weight = font.get("weight", "")
            usage = ", ".join(font.get("usage", [])[:3])  # ìš©ë„ 3ê°œë§Œ
            font_list.append(f"  - {name} ({style}, {weight}) - ìš©ë„: {usage}")

        font_info_section = f"""

**ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ (ìƒìœ„ 10ê°œ):**
{chr(10).join(font_list)}

ë” ë§ì€ í°íŠ¸ê°€ í•„ìš”í•˜ë©´ `list_fonts_with_metadata` ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜,
ê´‘ê³  ìœ í˜•ì— ë§ëŠ” í°íŠ¸ ì¶”ì²œì´ í•„ìš”í•˜ë©´ `recommend_font` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- recommend_font íŒŒë¼ë¯¸í„°: text_content, ad_type (sale/premium/casual/promotion), tone (energetic/elegant/friendly), weight (light/bold/heavy)
"""
    else:
        font_info_section = """

**ê²½ê³ :** í°íŠ¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

    # í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ í™•ì¸
    current_job_context = st.session_state.get("current_job_context")
    context_info = ""
    if current_job_context:
        context_info = f"""

**í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸:**
- ì‘ì—… ID: {current_job_context.get('job_id', 'N/A')}
- ìƒíƒœ: {current_job_context.get('status', 'N/A')}
- í”„ë¡¬í”„íŠ¸: {current_job_context.get('prompt', 'N/A')[:100]}...

ì´ ì‘ì—…ì— ëŒ€í•œ ì¶”ê°€ ë…¼ì˜ë‚˜ ìˆ˜ì • ìš”ì²­ì¸ ê²½ìš°, ìƒˆë¡œìš´ ê´‘ê³ ë¥¼ ìƒì„±í•˜ì§€ ë§ê³  ì˜ê²¬ë§Œ ì œì‹œí•˜ì„¸ìš”.
ìƒˆë¡œìš´ ê´‘ê³ ë¥¼ ìƒì„±í•˜ë ¤ë©´ ì‚¬ìš©ìê°€ ëª…í™•íˆ "ìƒˆ ê´‘ê³  ìƒì„±", "ë‹¤ì‹œ ë§Œë“¤ì–´ì¤˜" ë“±ì„ í‘œí˜„í•´ì•¼ í•©ë‹ˆë‹¤.
"""

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤: ê¸°íš â†’ í™•ì¸ â†’ ìƒì„±)
    system_prompt = f"""ë‹¹ì‹ ì€ ë‚˜ë…¸ì½”ì½”ì•„(nanoCocoa) AI ê´‘ê³  ìƒì„± ì‹œìŠ¤í…œì˜ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì—­í• :**
1. ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©° íš¨ê³¼ì ì¸ ê´‘ê³  ì»¨ì…‰ ì œì•ˆ (ê¸°íš ë‹¨ê³„)
2. ìµœì¢… í™•ì¸ í›„ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± (ì‹¤í–‰ ë‹¨ê³„)
{context_info}

**ê´‘ê³  ìƒì„± 2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤:**

### 1ë‹¨ê³„: ê¸°íš ë° ì˜ê²¬ êµí™˜ (ë„êµ¬ í˜¸ì¶œ ì—†ìŒ)
- ì œí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´ íŒŒì•…
- íƒ€ê²Ÿ ê³ ê°ì¸µ í™•ì¸
- ê´‘ê³  í†¤ì•¤ë§¤ë„ˆ ê²°ì • (ì„¸ì¼/í”„ë¦¬ë¯¸ì—„/ìºì£¼ì–¼)
- í•µì‹¬ ë©”ì‹œì§€ ë° ì¹´í”¼ ì œì•ˆ
- ë¹„ì£¼ì–¼ ì»¨ì…‰ ì œì•ˆ
- í°íŠ¸ ì¶”ì²œ (í•„ìš” ì‹œ `recommend_font` ë„êµ¬ ì‚¬ìš©)

### 2ë‹¨ê³„: ìµœì¢… í™•ì¸ ë° ìƒì„± ì‹¤í–‰
- **ì¤‘ìš”:** ì‚¬ìš©ìê°€ ë‹¤ìŒ í‘œí˜„ì„ **ëª…í™•íˆ** ì‚¬ìš©í•  ë•Œë§Œ `generate_ad_image` ë„êµ¬ í˜¸ì¶œ:
  - "ìƒì„±í•´ì¤˜", "ë§Œë“¤ì–´ì¤˜", "ê´‘ê³  ìƒì„±", "ì‹œì‘", "ì‹¤í–‰"
  - "ì§€ê¸ˆ ë§Œë“¤ì–´", "ì´ì œ ìƒì„±", "OK ìƒì„±", "í™•ì¸ ìƒì„±"
  - ì˜ì–´: "generate", "create now", "start generation"

- **ë„êµ¬ í˜¸ì¶œ ì „ í™•ì¸ ê¸ˆì§€ í‘œí˜„:**
  - "ì–´ë–¤ê°€ìš”?", "ê´œì°®ë‚˜ìš”?", "ì˜ê²¬ ìˆìœ¼ì„¸ìš”?", "ìˆ˜ì •í•  ë¶€ë¶„?"
  - ì´ëŸ° ì§ˆë¬¸ì€ **ê¸°íš ë‹¨ê³„**ì´ë¯€ë¡œ ë„êµ¬ í˜¸ì¶œí•˜ì§€ ë§ ê²ƒ

- **ìƒì„± í›„ ì¶”ê°€ ëŒ€í™”:**
  - ê´‘ê³ ê°€ ì´ë¯¸ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì¶”ê°€ ì˜ê²¬ êµí™˜ ì‹œ **ìƒˆë¡œìš´ ê´‘ê³  ìƒì„±í•˜ì§€ ë§ ê²ƒ**
  - "ìƒˆ ê´‘ê³ ", "ë‹¤ì‹œ ìƒì„±", "another one" ë“± ëª…ì‹œì  ìš”ì²­ ì‹œì—ë§Œ ì¬ìƒì„±
{font_info_section}

**MCP ë„êµ¬ í˜¸ì¶œ ê·œì¹™:**
- `generate_ad_image` í•„ìˆ˜ íŒŒë¼ë¯¸í„°:
  - background_prompt: ì˜ë¬¸ ë°°ê²½ ì„¤ëª… (15-30ë‹¨ì–´)
    * **ì¤‘ìš”**: ì œí’ˆ ì´ë¯¸ì§€(product_image_path)ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ” ê²½ìš°, 
      background_promptì— ì œí’ˆ ìƒì„¸ ì„¤ëª…ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•¨
    * ì œí’ˆ ì´ë¯¸ì§€ ìˆìŒ: "Elegant marble surface with soft lighting, luxury background"
    * ì œí’ˆ ì´ë¯¸ì§€ ì—†ìŒ: "Premium red apples on golden traditional Korean bojagi cloth, 
      juicy and fresh, photorealistic, Korean ink painting style background 
      with magpie and yut game elements"
  - text_content: ê´‘ê³  í…ìŠ¤íŠ¸ (ì›ë¬¸ ì–¸ì–´ ìœ ì§€)
  - text_prompt: 3D í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ (10-20ë‹¨ì–´, '3D render' í•„ìˆ˜)
  
- ì„ íƒ íŒŒë¼ë¯¸í„°:
  - product_image_path: ì œí’ˆ ì´ë¯¸ì§€ ê²½ë¡œ (ì œê³µ ì•ˆ í•˜ë©´ ë°°ê²½ì— ì œí’ˆ í¬í•¨í•˜ì—¬ ìƒì„±)
  - composition_mode: "overlay" (ê¸°ë³¸ê°’)
  - wait_for_completion: false (ë¹„ë™ê¸° ì²˜ë¦¬)

- **ì œí’ˆ ì´ë¯¸ì§€ ì œê³µ ì—¬ë¶€ì— ë”°ë¥¸ ì²˜ë¦¬**:
  1. **ì œí’ˆ ì´ë¯¸ì§€ ìˆìŒ**: product_image_path ì œê³µ + background_promptëŠ” ë°°ê²½ë§Œ ì„¤ëª…
  2. **ì œí’ˆ ì´ë¯¸ì§€ ì—†ìŒ**: product_image_path ìƒëµ + background_promptì— ì œí’ˆ+ë°°ê²½ ëª¨ë‘ ì„¤ëª…

**ì‘ë‹µ ê°€ì´ë“œ:**
- ê¸°íš ë‹¨ê³„: ì»¨ì…‰ ì œì•ˆ í›„ "ìƒì„±ì„ ì›í•˜ì‹œë©´ 'ìƒì„±í•´ì¤˜'ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”" ì•ˆë‚´
- ë„êµ¬ í˜¸ì¶œ í›„: "ê´‘ê³  ìƒì„± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ì—… ID: [job_id]" í˜•ì‹ìœ¼ë¡œ ì•ˆë‚´
- ì‘ì—…ì€ 15~30ë¶„ ì†Œìš”ë˜ë©°, íˆìŠ¤í† ë¦¬ í˜ì´ì§€ì—ì„œ ì§„í–‰ ìƒí™© í™•ì¸ ê°€ëŠ¥í•¨ì„ ì•ˆë‚´
- **ì¤‘ìš”:** text_contentëŠ” ì›ë¬¸ ì–¸ì–´(ì˜ì–´ëŠ” ì˜ì–´, í•œê¸€ì€ í•œê¸€)ë¥¼ ìœ ì§€
- background_prompt, text_prompt ë“± ì´ë¯¸ì§€ ìƒì„± promptë§Œ ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±
"""

    try:
        async with LLMAdapter(
            openai_api_key=api_key,
            mcp_server_url=MCP_SERVER_URL,
            model=OPENAI_MODEL,
            temperature=OPENAI_TEMPERATURE,
            max_completion_tokens=OPENAI_MAX_COMPLETION_TOKENS,
        ) as adapter:

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ LLMAdapterì— ì „ë‹¬
            for msg in st.session_state.chat_history[:-1]:  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
                if msg["role"] == "user":
                    adapter.conversation_history.append(
                        {"role": "user", "content": msg["content"]}
                    )
                elif msg["role"] == "assistant":
                    adapter.conversation_history.append(
                        {"role": "assistant", "content": msg["content"]}
                    )

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì£¼ì…
            adapter.conversation_history.insert(
                0, {"role": "system", "content": system_prompt}
            )

            # LLM ì‘ë‹µ ìƒì„± (í•„ìš” ì‹œ ìë™ìœ¼ë¡œ MCP ë„êµ¬ í˜¸ì¶œ)
            response, tool_params = await adapter.chat(user_message, max_tool_calls=3)

            # job_id ì¶”ì¶œ (ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ì—ì„œ)
            job_id = None
            for msg in reversed(adapter.conversation_history):
                if msg.get("role") == "tool":
                    tool_response = msg.get("content", "")
                    job_id = extract_job_id(tool_response)
                    if job_id:
                        logger.info(f"job_id ì¶”ì¶œ ì„±ê³µ: {job_id}")
                        break

            return response, job_id, tool_params

    except Exception as e:
        logger.error(f"LLMAdapter ì˜¤ë¥˜: {e}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", None, None


def extract_job_id(tool_response: str):
    """
    ë„êµ¬ ì‘ë‹µì—ì„œ job_id ì¶”ì¶œ

    Args:
        tool_response: MCP ë„êµ¬ í˜¸ì¶œ ê²°ê³¼

    Returns:
        job_id ë˜ëŠ” None
    """
    if not tool_response:
        return None

    # 1. JSON íŒŒì‹± ì‹œë„
    try:
        data = json.loads(tool_response)
        if "job_id" in data:
            return data["job_id"]
    except json.JSONDecodeError:
        pass

    # 2. UUID íŒ¨í„´ ê²€ìƒ‰
    uuid_pattern = r"[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}"
    matches = re.findall(uuid_pattern, tool_response, re.IGNORECASE)
    if matches:
        return matches[0]

    return None


def handle_job_creation(
    job_id: str, user_message: str, tool_params: Optional[Dict[str, Any]] = None
) -> None:
    """
    ì‘ì—… ìƒì„± í›„ ì €ì¥, ì‚¬ìš©ì ì•ˆë‚´ ë° ëª¨ë‹ˆí„°ë§ ì‹œì‘

    Args:
        job_id: ì‘ì—… ID
        user_message: ì‚¬ìš©ì ìš”ì²­ ë©”ì‹œì§€
        tool_params: ì‹¤ì œ ì‚¬ìš©ëœ ë„êµ¬ íŒŒë¼ë¯¸í„° (ì¬í˜„ì„±)
    """
    # í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì‘ì—… IDë³„ ëŒ€í™” ì¶”ì )
    st.session_state.current_job_context = {
        "job_id": job_id,
        "status": "processing",
        "prompt": user_message,
        "created_at": asyncio.run(_get_current_time_async()),
    }
    logger.info(f"ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸: {job_id}")

    # ì¬í˜„ì„±ì„ ìœ„í•´ ì‹¤ì œ ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„° ì €ì¥
    if tool_params and tool_params.get("parameters"):
        generation_params = tool_params["parameters"].copy()
        # ì‚¬ìš©ì ì›ë¬¸ ë©”ì‹œì§€ë„ ì¶”ê°€
        generation_params["user_message"] = user_message
        generation_params["model"] = OPENAI_MODEL
        generation_params["mcp_server_url"] = MCP_SERVER_URL
        logger.info(f"ì‹¤ì œ ë„êµ¬ íŒŒë¼ë¯¸í„° ì €ì¥: {list(generation_params.keys())}")
    else:
        # fallback: ê¸°ë³¸ íŒŒë¼ë¯¸í„°
        product_image = UPLOADS_DIR / "test_product.png"
        generation_params = {
            "user_message": user_message,
            "text_content": user_message,
            "product_image_path": str(product_image),
            "composition_mode": "overlay",
            "model": OPENAI_MODEL,
            "mcp_server_url": MCP_SERVER_URL,
        }
        logger.warning("ë„êµ¬ íŒŒë¼ë¯¸í„° ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")

    try:
        # ì‘ì—… ì €ì¥ (íŒŒì¼ ê¸°ë°˜)
        job_store.create_job(
            job_id=job_id,
            prompt=user_message,
            metadata=generation_params,
        )
        logger.info(f"ì‘ì—… ì €ì¥ ì™„ë£Œ: {job_id}")
        history_msg = "\n\nğŸ“ **íˆìŠ¤í† ë¦¬ í˜ì´ì§€**ì—ì„œ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."

        # ì‘ì—… ëª¨ë‹ˆí„°ë§ ì‹œì‘
        monitor_job_in_background(job_id)

        st.success(
            f"""
âœ… ê´‘ê³  ìƒì„± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!

**ì‘ì—… ID:** `{job_id}`

ì‘ì—…ì€ 15~30ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.{history_msg}

â±ï¸ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
"""
        )

    except Exception as e:
        st.warning(f"ì‘ì—… ì €ì¥ ì‹¤íŒ¨ (ì‘ì—…ì€ ì§„í–‰ ì¤‘): {e}")


def monitor_job_in_background(job_id: str) -> None:
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‘ì—… ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì™„ë£Œ ì‹œ ê²°ê³¼ ì €ì¥

    Args:
        job_id: ì‘ì—… ID
    """
    # Session stateì— ëª¨ë‹ˆí„°ë§ ì‘ì—… ì¶”ê°€
    if "monitoring_jobs" not in st.session_state:
        st.session_state.monitoring_jobs = []

    if job_id not in st.session_state.monitoring_jobs:
        st.session_state.monitoring_jobs.append(job_id)
        logger.info(f"ì‘ì—… ëª¨ë‹ˆí„°ë§ ì‹œì‘: {job_id}")


async def check_job_status_and_update(job_id: str) -> dict:
    """
    MCP ì„œë²„ì—ì„œ ì‘ì—… ìƒíƒœ í™•ì¸ ë° ì €ì¥ì†Œ ì—…ë°ì´íŠ¸

    Args:
        job_id: ì‘ì—… ID

    Returns:
        ì‘ì—… ìƒíƒœ ì •ë³´
    """
    try:
        # ë¡œì»¬ ì €ì¥ ê²½ë¡œ ìƒì„±
        save_result_path = RESULTS_DIR / f"{job_id}.png"

        async with MCPClient(base_url=MCP_SERVER_URL, timeout=MCP_TIMEOUT) as client:
            # MCP ì„œë²„ì—ì„œ ìƒíƒœ í™•ì¸ (save_result_path ì „ë‹¬í•˜ì—¬ ì™„ë£Œ ì‹œ ì´ë¯¸ì§€ ì €ì¥)
            status_params = {
                "job_id": job_id,
                "save_result_path": str(save_result_path),
            }

            result = await client.call_tool("check_generation_status", status_params)

            # ê²°ê³¼ íŒŒì‹±
            if isinstance(result, str):
                status_data = json.loads(result)
            else:
                status_data = result

            status = status_data.get("status")
            progress = status_data.get("progress_percent", 0)

            # ì‘ì—… ì €ì¥ì†Œ ì—…ë°ì´íŠ¸
            if status == "completed":
                logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: {job_id}")
                logger.info(f"   ì´ë¯¸ì§€ ì €ì¥ë¨: {save_result_path}")

                # íŒŒì¼ ì¡´ì¬ í™•ì¸
                if save_result_path.exists():
                    logger.info(
                        f"   íŒŒì¼ í¬ê¸°: {save_result_path.stat().st_size:,} bytes"
                    )
                else:
                    logger.warning(
                        f"   âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {save_result_path}"
                    )

                job_store.update_job(
                    job_id=job_id,
                    status="completed",
                    progress_percent=100,
                    result_image_path=str(save_result_path),
                )
            elif status == "failed":
                error_msg = status_data.get("message", "Unknown error")
                job_store.update_job(
                    job_id=job_id,
                    status="failed",
                    error_message=error_msg,
                )
                logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨: {job_id} - {error_msg}")
            elif status == "processing":
                job_store.update_job(
                    job_id=job_id,
                    status="processing",
                    progress_percent=progress,
                )
                logger.debug(f"â³ ì‘ì—… ì§„í–‰ ì¤‘: {job_id} ({progress}%)")

            return status_data

    except Exception as e:
        logger.error(f"ì‘ì—… ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {"status": "unknown", "error": str(e)}


def create_test_product_image(output_path: Path) -> None:
    """
    í…ŒìŠ¤íŠ¸ìš© ì œí’ˆ ì´ë¯¸ì§€ ìƒì„±

    Args:
        output_path: ì €ì¥ ê²½ë¡œ
    """
    from PIL import Image, ImageDraw
    import stat

    try:
        logger.info(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘: {output_path}")
    except:
        pass  # logger ì—†ì„ ê²½ìš° ë¬´ì‹œ

    # ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •
    output_dir = output_path.parent
    if output_dir.exists():
        current_mode = output_dir.stat().st_mode
        try:
            logger.info(f"ë””ë ‰í† ë¦¬ ê¶Œí•œ: {oct(stat.S_IMODE(current_mode))}")
        except:
            pass

        # ì“°ê¸° ê¶Œí•œ ë¶€ì—¬ (755)
        try:
            output_dir.chmod(0o755)
            try:
                logger.info("ë””ë ‰í† ë¦¬ ê¶Œí•œ ìˆ˜ì • ì™„ë£Œ (755)")
            except:
                pass
        except Exception as e:
            try:
                logger.warning(f"ê¶Œí•œ ìˆ˜ì • ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
            except:
                pass
    else:
        output_dir.mkdir(parents=True, exist_ok=True)
        try:
            logger.info(f"ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
        except:
            pass

    # 512x512 ë°”ë‚˜ë‚˜ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new("RGB", (512, 512), color="white")
    draw = ImageDraw.Draw(img)

    # ë°”ë‚˜ë‚˜ ëª¨ì–‘
    draw.ellipse([150, 100, 450, 200], fill="#FFD700", outline="#FFA500", width=3)
    draw.ellipse([100, 200, 400, 300], fill="#FFD700", outline="#FFA500", width=3)
    draw.ellipse([120, 280, 380, 400], fill="#FFD700", outline="#FFA500", width=3)

    try:
        img.save(output_path)
        try:
            logger.info(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {output_path}")
            logger.info(f"  í¬ê¸°: {output_path.stat().st_size:,} bytes")
        except:
            pass
    except PermissionError as e:
        try:
            logger.error(f"ì €ì¥ ì‹¤íŒ¨ (ê¶Œí•œ ì˜¤ë¥˜): {e}")
            logger.info("í•´ê²° ë°©ë²•:")
            logger.info(f"  í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰: chmod 755 {output_dir}")
        except:
            pass
        raise


def check_and_display_completed_jobs() -> None:
    """
    ëª¨ë‹ˆí„°ë§ ì¤‘ì¸ ì‘ì—…ì˜ ì™„ë£Œ ì—¬ë¶€ í™•ì¸ ë° ê²°ê³¼ í‘œì‹œ
    """
    if (
        "monitoring_jobs" not in st.session_state
        or not st.session_state.monitoring_jobs
    ):
        return

    try:
        completed_jobs = []

        for job_id in st.session_state.monitoring_jobs[:]:
            # MCP ì„œë²„ì—ì„œ ìµœì‹  ìƒíƒœ í™•ì¸ í›„ ì—…ë°ì´íŠ¸
            asyncio.run(check_job_status_and_update(job_id))

            # ì—…ë°ì´íŠ¸ëœ ì‘ì—… ì •ë³´ ì¡°íšŒ
            job = job_store.get_job(job_id)

            if not job:
                logger.warning(f"ì‘ì—… {job_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                continue

            status = job.get("status")

            if status == "completed":
                # ì™„ë£Œëœ ì‘ì—… í‘œì‹œ
                display_completed_job_result(job)
                completed_jobs.append(job_id)

                # ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                if (
                    st.session_state.current_job_context
                    and st.session_state.current_job_context.get("job_id") == job_id
                ):
                    st.session_state.current_job_context["status"] = "completed"

            elif status == "failed":
                st.error(
                    f"âŒ ì‘ì—… ì‹¤íŒ¨: {job_id}\n{job.get('error_message', 'Unknown error')}"
                )
                completed_jobs.append(job_id)

                # ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì œê±°
                if (
                    st.session_state.current_job_context
                    and st.session_state.current_job_context.get("job_id") == job_id
                ):
                    st.session_state.current_job_context = None

        # ì™„ë£Œëœ ì‘ì—…ì„ ëª¨ë‹ˆí„°ë§ ëª©ë¡ì—ì„œ ì œê±°
        for job_id in completed_jobs:
            st.session_state.monitoring_jobs.remove(job_id)

        # ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì´ ìˆìœ¼ë©´ ìë™ ìƒˆë¡œê³ ì¹¨
        if st.session_state.monitoring_jobs:
            with st.spinner(
                f"â³ {len(st.session_state.monitoring_jobs)}ê°œ ì‘ì—… ì§„í–‰ ì¤‘... {POLLING_INTERVAL}ì´ˆ í›„ ìë™ ê°±ì‹ "
            ):
                time.sleep(POLLING_INTERVAL)
                st.rerun()

    except Exception as e:
        logger.error(f"ì‘ì—… í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")


def display_completed_job_result(job: dict) -> None:
    """
    ì™„ë£Œëœ ì‘ì—…ì˜ ê²°ê³¼ í‘œì‹œ

    Args:
        job: ì‘ì—… ë¬¸ì„œ
    """
    st.success(f"âœ… ê´‘ê³  ìƒì„± ì™„ë£Œ! (ì‘ì—… ID: {job['job_id'][:16]}...)")

    # ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
    result_path = job.get("result_image_path")
    if result_path:
        result_file = Path(result_path)
        if result_file.exists():
            st.image(str(result_file), caption="ìƒì„±ëœ ê´‘ê³  ì´ë¯¸ì§€", width="content")
        else:
            st.warning(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_path}")

    # ìƒì„± íŒŒë¼ë¯¸í„° í‘œì‹œ (ì¬í˜„ì„±)
    with st.expander("ğŸ“‹ ìƒì„± íŒŒë¼ë¯¸í„° (ì¬í˜„ ê°€ëŠ¥)"):
        metadata = job.get("metadata", {})
        st.json(metadata)

    # íˆìŠ¤í† ë¦¬ í˜ì´ì§€ ë§í¬
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“ íˆìŠ¤í† ë¦¬ì—ì„œ ìì„¸íˆ ë³´ê¸°", key=f"view_{job['job_id']}"):
            set_page("history")
            st.rerun()
    with col2:
        if st.button("ğŸ”„ ìƒˆë¡œìš´ ê´‘ê³  ìƒì„±", key=f"new_{job['job_id']}"):
            st.rerun()

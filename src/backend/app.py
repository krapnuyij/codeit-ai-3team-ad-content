import numpy as np
import cv2
from FastAPI import FastAPI, UploadFile, File, Depends, HTTPException, Request
from FastAPI.responses import JSONResponse
from contextlib import asynccontextmanager
import onnxruntime
from openai import OpenAI
from dotenv import load_dotenv
import os
import base64
from pydantic import BaseModel
from typing import Union

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# Pydantic ëª¨ë¸
class AdPrompt(BaseModel):
    positive_prompt: str
    negative_prompt: str


# ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜ë“¤
def get_client(request: Request):
    """í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return request.app.state.client


def get_use_openai(request: Request):
    """OpenAI ì‚¬ìš© ì—¬ë¶€ ë°˜í™˜"""
    return request.app.state.use_openai


# Lifespan ì´ë²¤íŠ¸
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ë¡œì§"""
    print("ğŸš€ ì•± ì‹œì‘")

    api_key = os.getenv("OPENAI_API_KEY")
    app.state.use_openai = False

    # OpenAI ì´ˆê¸°í™” ì‹œë„
    if api_key:
        try:
            app.state.client = OpenAI(api_key=api_key)
            app.state.use_openai = True
            print("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ONNX ëª¨ë¸ë¡œ fallback
    if not app.state.use_openai:
        print("ğŸ”„ OpenAI ì‹¤íŒ¨ â†’ ONNXë¡œ fallback")
        try:
            onnx_path = "model.onnx"
            app.state.client = onnxruntime.InferenceSession(onnx_path)
            print("ONNX ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"ONNX ë¡œë”© ì‹¤íŒ¨: {e}")
            raise RuntimeError("ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨") from e

    yield

    # ì•± ì¢…ë£Œ ì‹œ cleanup
    print("ğŸ›‘ ì•± ì¢…ë£Œ")


# FastAPI ì•± ìƒì„±
app = FastAPI(title="AI Image Prompt Generator", lifespan=lifespan)


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def to_base64(image_bytes: bytes) -> str:
    """ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    encoded = base64.b64encode(image_bytes).decode("utf-8")
    return f"data:image/png;base64,{encoded}"


def process_with_openai(image_data: bytes, client: OpenAI) -> AdPrompt:
    """OpenAI Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        encoded_image = to_base64(image_data)
        response = client.chat.completions.create()
        # Responses APIì˜ parse ë©”ì„œë“œ ì‚¬ìš©
        response = client.responses.parse(
            model="gpt-5-mini",  # ë˜ëŠ” "gpt-4o-2024-08-06"
            input=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•´ì„œ ê´‘ê³ ìš© ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜.",
                        },
                        {"type": "image_url", "image_url": {"url": encoded_image}},
                    ],
                },
            ],
            text_format=AdPrompt,  # Pydantic ëª¨ë¸ë¡œ ìë™ íŒŒì‹±
        )

        # íŒŒì‹±ëœ ê²°ê³¼ ë°˜í™˜
        return response.output_parsed

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"OpenAI Responses API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
        )


def process_with_onnx(image_data: bytes, ort_session) -> AdPrompt:
    """ONNX ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        # ì´ë¯¸ì§€ ë””ì½”ë”©
        img = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)

        if img is None:
            raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

        # ì „ì²˜ë¦¬ (ëª¨ë¸ì— ë§ê²Œ ì¡°ì • í•„ìš”)
        img = cv2.resize(img, (224, 224))
        img = img.astype(np.float32) / 255.0
        img = np.transpose(img, (2, 0, 1))  # HWC -> CHW
        img = np.expand_dims(img, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

        # ONNX ì¶”ë¡ 
        input_name = ort_session.get_inputs()[0].name
        output = ort_session.run(None, {input_name: img})

        # ê²°ê³¼ ì²˜ë¦¬ (ëª¨ë¸ ì¶œë ¥ì— ë§ê²Œ ì¡°ì • í•„ìš”)
        positive_prompt = f"ONNX ëª¨ë¸ ì¶œë ¥ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸: {output[0]}"
        negative_prompt = "low quality, blurry"

        return AdPrompt(
            positive_prompt=positive_prompt, negative_prompt=negative_prompt
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ONNX ëª¨ë¸ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")


# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/", response_class=JSONResponse)
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "AI Image Prompt Generator API",
        "endpoints": {"generate_prompt": "/generate-prompt (POST)"},
    }


@app.post("/generate-prompt", response_model=AdPrompt)
async def generate_image_prompt(
    file: UploadFile = File(...),
    client: Union[OpenAI, onnxruntime.InferenceSession] = Depends(get_client),
    use_openai: bool = Depends(get_use_openai),
):
    """
    ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¡œë¶€í„° ê´‘ê³ ìš© ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        file: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼
        client: OpenAI ë˜ëŠ” ONNX í´ë¼ì´ì–¸íŠ¸ (ìë™ ì£¼ì…)
        use_openai: OpenAI ì‚¬ìš© ì—¬ë¶€ (ìë™ ì£¼ì…)

    Returns:
        AdPrompt: positive_promptì™€ negative_prompt í¬í•¨
    """
    try:
        # ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸°
        image_data = await file.read()

        if not image_data:
            raise HTTPException(status_code=400, detail="ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤")

        # OpenAI ë˜ëŠ” ONNXë¡œ ì²˜ë¦¬
        if use_openai:
            print("ğŸ¤– OpenAI Responses APIë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            result = process_with_openai(image_data, client)
        else:
            print("ğŸ”§ ONNX ëª¨ë¸ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            result = process_with_onnx(image_data, client)

        return result

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


@app.get("/health")
async def health_check(request: Request):
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "using_openai": request.app.state.use_openai,
        "client_type": "OpenAI" if request.app.state.use_openai else "ONNX",
    }


# ê°œë°œ ì„œë²„ ì‹¤í–‰ (ì˜µì…˜)
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)

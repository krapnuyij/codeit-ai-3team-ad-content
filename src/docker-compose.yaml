services:
  backend:
    build: ./backend
    container_name: SaaS_backend
    env_file:
      - .env
    ports:
      - "8890:8890"
    depends_on:
      - customer_db
      - homepage_generator
      - nanococoa_aiserver
    environment:
      - DATABASE_URL=postgresql://owner:owner1234@customer_db:5432/customer_db
      - HOMEPAGE_GENERATOR_URL=http://homepage_generator:8891
      - NANOCOCOA_URL=http://nanococoa_aiserver:8892
    command: uvicorn app:app --host 0.0.0.0 --port 8890 --reload
    restart: on-failure

  customer_db:
    image: postgres:15
    container_name: customer_db
    environment:
      POSTGRES_USER: owner
      POSTGRES_PASSWORD: owner1234
      POSTGRES_DB: customer_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/customer_data

  homepage_generator:
    build: ./homepage_generator
    container_name: homepage_generator
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - DATABASE_URL=postgresql://owner:owner1234@customer_db:5432/customer_db
    ports:
      - "8891:8891"
    command: uvicorn api:app --host 0.0.0.0 --port 8891
    volumes:
      - generated_sites:/app/generated_ad

  nanococoa_aiserver:
    build: ./nanoCocoa_aiserver
    container_name: nanococoa_aiserver
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - PYTORCH_ALLOC_CONF=expandable_segments:True
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface/transformers
      - HF_HUB_CACHE=/root/.cache/huggingface/hub
      - HF_TOKEN=${HF_TOKEN}
    ports:
      - "8892:8892"
    volumes:
      - /opt/huggingface:/root/.cache/huggingface
      - nanococoa_results:/app/static/results
      - nanococoa_uploads:/app/static/uploads
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: uvicorn main:app --host 0.0.0.0 --port 8892 --workers 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://34.44.205.198:8892/health"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3
    restart: unless-stopped

  nanococoa_mcpserver:
    build:
      context: ./nanoCocoa_mcpserver
      dockerfile: Dockerfile
    container_name: nanococoa_mcpserver
    env_file:
      - .env
    ports:
      - "3000:3000"
    volumes:
      - nanococoa_results:/app/static/results
      - nanococoa_uploads:/app/static/uploads
    environment:
      - MCP_TRANSPORT=sse
      - MCP_PORT=3000
      - MCP_HOST=0.0.0.0
      - AISERVER_BASE_URL=http://nanococoa_aiserver:8892
      - LOG_LEVEL=INFO
    depends_on:
      nanococoa_aiserver:
        condition: service_healthy
    command: python server.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      start_period: 5s
      retries: 3
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    container_name: saas_nginx
    volumes:
      - generated_sites:/usr/share/nginx/html/sites
    ports:
      - "8893:80"

volumes:
  postgres_data:
  generated_sites:
  huggingface_cache:
  nanococoa_results:
  nanococoa_uploads:
services:
  backend:
    build: ./backend
    container_name: SaaS_backend
    env_file:
      - .env
    ports:
      - "8890:8890"
    depends_on:
      - customer_db
      - homepage_generator
      - nanococoa_aiserver
    environment:
      - DATABASE_URL=postgresql://owner:owner1234@customer_db:5432/customer_db
      - HOMEPAGE_GENERATOR_URL=http://homepage_generator:8891
      - NANOCOCOA_URL=http://nanococoa_aiserver:8000
    volumes:
      - ./backend/generated_sites:/app/sites
    command: uvicorn app:app --host 0.0.0.0 --port 8890 --reload
    restart: on-failure

  customer_db:
    image: postgres:15
    container_name: customer_db
    environment:
      POSTGRES_USER: owner
      POSTGRES_PASSWORD: owner1234
      POSTGRES_DB: customer_db
    ports:
      - "5432:5432"
    volumes:
      - ./backend/postgres_data:/var/lib/postgresql/data

  homepage_generator:
    build: ./homepage_generator
    container_name: homepage_generator
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - DATABASE_URL=postgresql://owner:owner1234@customer_db:5432/customer_db
    ports:
      - "8891:8891"
    command: uvicorn api:app --host 0.0.0.0 --port 8891
    volumes:
      - ./backend/generated_sites:/app/generated_ad

  nanococoa_aiserver:
    build: ./nanoCocoa_aiserver
    container_name: nanococoa_aiserver
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - PYTORCH_ALLOC_CONF=expandable_segments:True
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface/transformers
      - HF_HUB_CACHE=/root/.cache/huggingface/hub
      - HF_TOKEN=${HF_TOKEN}
    ports:
      - "8000:8000"
    volumes:
      - /opt/huggingface:/root/.cache/huggingface
      - nanococoa_results:/app/static/results
      - nanococoa_uploads:/app/static/uploads
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://34.44.205.198:8000/health"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3
    restart: unless-stopped

  nanococoa_mcpserver:
    build:
      context: ./nanoCocoa_mcpserver
      dockerfile: Dockerfile
    container_name: nanococoa_mcpserver
    env_file:
      - .env
    ports:
      - "3000:3000"
    volumes:
      - nanococoa_results:/app/static/results
      - nanococoa_uploads:/app/static/uploads
    environment:
      - MCP_TRANSPORT=sse
      - MCP_PORT=3000
      - MCP_HOST=0.0.0.0
      - AISERVER_BASE_URL=http://nanococoa_aiserver:8000
      - LOG_LEVEL=INFO
    depends_on:
      nanococoa_aiserver:
        condition: service_healthy
    command: python server.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      start_period: 5s
      retries: 3
    restart: unless-stopped

  ad_chat:
    build:
      context: ../
      dockerfile: ./src/ad_chat/Dockerfile
    container_name: ad_chat
    env_file:
      - .env
    ports:
      - "8501:8501"
    volumes:
      - nanococoa_results:/app/static/results
      - nanococoa_uploads:/app/static/uploads
      - ad_chat_data:/app/src/ad_chat/data
    environment:
      - RUNTIME_ENV=docker
      - STATIC_BASE_PATH=/app/static
      - MCP_SERVER_URL=http://nanococoa_mcpserver:3000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-5-mini}
    depends_on:
      nanococoa_mcpserver:
        condition: service_healthy
    command: streamlit run app.py --server.port=8501 --server.address=0.0.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      start_period: 30s
      retries: 3
    restart: on-failure

  nginx:
    image: nginx:alpine
    container_name: saas_nginx
    volumes:
      - ./backend/generated_sites:/usr/share/nginx/html/sites
    ports:
      - "8893:80"

volumes:
  huggingface_cache:
  nanococoa_results:
  nanococoa_uploads:
  ad_chat_data: